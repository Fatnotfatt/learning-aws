[{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan Workshop","tags":[],"description":"","content":"Giới thiệu Workshop này hướng dẫn bạn triển khai một ứng dụng phân tích DNA full-stack trên AWS. Ứng dụng cho phép người dùng phân tích chuỗi DNA, quản lý kết quả, và trực quan hóa dữ liệu sinh học.\nKiến trúc Ứng dụng Frontend (React + Vite) Framework: React 18 với TypeScript UI Libraries: Material-UI, TailwindCSS, Recharts State Management: React Context API Routing: React Router v6 Form Handling: React Hook Form với Zod validation HTTP Client: Axios Hosting: S3 + CloudFront CDN Backend (Spring Boot) Framework: Spring Boot 3.x Language: Java 17 Database: MySQL 8.0 với Spring Data JPA Security: Spring Security với JWT authentication API: RESTful API với proper error handling Hosting: EC2 instances với Auto Scaling Database (RDS MySQL) Engine: MySQL 8.0.40 Instance: db.t3.micro (có thể scale up) Storage: 20GB gp3 với encryption Backup: Automated backups với 3-7 days retention High Availability: Multi-AZ deployment (optional) Kiến trúc AWS Network Layer VPC (10.0.0.0/16)\r├── Public Subnets (10.0.1.0/24, 10.0.3.0/24)\r│ ├── Internet Gateway\r│ ├── NAT Gateway\r│ └── Application Load Balancer\r│\r└── Private Subnets (10.0.2.0/24, 10.0.4.0/24)\r├── EC2 Instances (Auto Scaling Group)\r├── RDS MySQL (Multi-AZ)\r└── VPC Endpoints (S3, CloudWatch, SSM, Cognito) Application Flow User Browser\r│\r├─── HTTPS ──\u0026gt; CloudFront ──\u0026gt; S3 (Static Frontend)\r│\r└─── HTTPS ──\u0026gt; API Gateway ──\u0026gt; ALB ──\u0026gt; EC2 (Backend API)\r│\r└──\u0026gt; RDS MySQL Security Architecture Internet\r│\r├─── CloudFront (HTTPS only)\r│ └─── S3 Bucket Policy (CloudFront OAI)\r│\r└─── API Gateway (Resource Policy)\r└─── ALB Security Group (Port 80/443)\r└─── EC2 Security Group (Port 8080 from ALB only)\r└─── RDS Security Group (Port 3306 from EC2 only) Các Tính năng Chính 1. User Authentication Đăng ký và đăng nhập người dùng JWT token-based authentication AWS Cognito integration (optional) Session management 2. DNA Analysis Upload và phân tích chuỗi DNA Hỗ trợ nhiều định dạng file Xử lý batch processing Lưu trữ kết quả phân tích 3. Data Visualization Biểu đồ phân tích DNA Dashboard với metrics Export kết quả dưới nhiều định dạng 4. User Management Quản lý profile người dùng Lịch sử phân tích Role-based access control Infrastructure as Code CloudFormation Template Template infrastructure.yaml bao gồm:\nNetworking (Lines 1-400)\nVPC với DNS support 2 Public Subnets (Multi-AZ) 2 Private Subnets (Multi-AZ) Internet Gateway NAT Gateway (có thể tắt để tiết kiệm chi phí) Route Tables VPC Endpoints (S3, CloudWatch, SSM, Cognito) Compute (Lines 400-700)\nLaunch Template với User Data script Auto Scaling Group (1-4 instances) Application Load Balancer Target Group với health checks Scaling Policies (CPU-based) Storage \u0026amp; CDN (Lines 700-900)\nS3 Bucket cho Frontend S3 Bucket Policy CloudFront Distribution CloudFront Origin Access Identity Database (Lines 900-1000)\nRDS MySQL Instance DB Subnet Group Automated Backups Encryption at rest Security (Lines 1000-1200)\nSecurity Groups (ALB, EC2, RDS, VPC Endpoints) IAM Roles (EC2, CloudWatch, S3) IAM Instance Profile Cognito User Pool (optional) Secrets Manager (optional) Monitoring (Lines 1200-1393)\nCloudWatch Log Groups CloudWatch Alarms (CPU, Memory) SNS Topic cho alerts API Gateway với CORS Tối ưu Chi phí 1. VPC Endpoints thay vì NAT Gateway Tiết kiệm: ~$20-25/tháng\nS3 Gateway Endpoint: FREE Interface Endpoints: $7.20/endpoint/tháng Tổng: ~$28/tháng vs NAT Gateway $32/tháng + data transfer 2. Instance Sizing Development: t3.micro ($7-10/tháng) Production: t3.small hoặc t3.medium\n3. RDS Optimization Single-AZ cho development Multi-AZ cho production Automated backups với retention phù hợp 4. CloudFront Caching Giảm requests đến S3 Giảm latency cho users Free tier: 1TB data transfer/tháng Best Practices được áp dụng 1. Security ✅ Private subnets cho EC2 và RDS ✅ Security Groups với least privilege ✅ IAM Roles thay vì hardcoded credentials ✅ Encryption at rest và in transit ✅ VPC Endpoints cho private connectivity ✅ CloudTrail cho audit logging (optional)\n2. High Availability ✅ Multi-AZ deployment ✅ Auto Scaling Group ✅ Application Load Balancer ✅ RDS automated backups ✅ CloudFront global CDN\n3. Monitoring \u0026amp; Logging ✅ CloudWatch Logs cho application logs ✅ CloudWatch Alarms cho metrics ✅ SNS notifications ✅ Health checks trên ALB và ASG\n4. Automation ✅ Infrastructure as Code với CloudFormation ✅ User Data scripts cho EC2 initialization ✅ Systemd service cho application management ✅ Automated deployments với scripts\nCác Bước Triển khai Chuẩn bị (10 phút)\nCài đặt AWS CLI Tạo EC2 Key Pair Cấu hình parameters Deploy Infrastructure (15-20 phút)\nValidate CloudFormation template Create stack Đợi resources được tạo Deploy Backend (20-30 phút)\nBuild JAR file Upload lên S3 Deploy lên EC2 Cấu hình database connection Deploy Frontend (10-15 phút)\nBuild React application Upload lên S3 Invalidate CloudFront cache Testing (15-30 phút)\nTest authentication Test DNA analysis features Verify monitoring Cleanup (5-10 phút)\nDelete CloudFormation stack Verify all resources deleted Kết quả Mong đợi Sau khi hoàn thành workshop, bạn sẽ có:\n✅ Một ứng dụng full-stack hoạt động trên AWS ✅ Hiểu biết sâu về AWS networking và security ✅ Kinh nghiệm với Infrastructure as Code ✅ Kiến thức về cost optimization ✅ Best practices cho production deployment\nTài nguyên Tham khảo AWS CloudFormation Documentation AWS VPC Best Practices AWS Well-Architected Framework Spring Boot on AWS React Deployment Best Practices "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;Building Agentic AI: Context Optimization with Amazon Bedrock\u0026rdquo; Mục Đích Của Sự Kiện Giới thiệu về Building Agentic AI và Context Optimization với Amazon Bedrock Xây dựng autonomous AI agents với Amazon Bedrock thông qua hands-on techniques Chia sẻ real-world use cases về agentic workflows Giới thiệu CloudThinker và giải pháp Agentic Orchestration Cung cấp hands-on workshop với môi trường AWS thực tế Kết nối với các chuyên gia AWS và AI practitioners Chi Tiết Sự Kiện Ngày: Thứ Sáu, 05 tháng 12 năm 2025 Thời gian: 9:00 – 12:00 (Check-in từ 8:15) Địa điểm: Tầng 26, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh Thời lượng: 3 giờ (bao gồm tea break, networking và lunch buffet) Chương Trình 9:00 – 9:10 | Khai mạc (10 phút) Nguyen Gia Hung, Head of Solutions Architect, AWS\nChào mừng và giới thiệu sự kiện Tổng quan về Building Agentic AI Context Optimization với Amazon Bedrock 9:10 – 9:40 | AWS Bedrock Agent Core (30 phút) Kien Nguyen, Solutions Architect, AWS\nGiới thiệu AWS Bedrock Agent Kiến trúc và các thành phần chính Cách thức hoạt động của Bedrock Agent Context management và optimization Tích hợp với các dịch vụ AWS khác Demo: Tạo và cấu hình Bedrock Agent cơ bản 9:40 – 10:00 | [Use Case] Building Agentic Workflow on AWS (20 phút) Viet Pham, Founder \u0026amp; CEO, Diaflow\nUse case thực tế về building agentic workflow Kiến trúc và best practices Challenges và solutions Context optimization trong production Demo: Agentic workflow trong thực tế 10:00 – 10:10 | CloudThinker Introduction (10 phút) Thang Ton, Co-founder \u0026amp; COO, CloudThinker\nGiới thiệu về CloudThinker Giải pháp Agentic Orchestration Tầm nhìn và roadmap Integration với Amazon Bedrock 10:10 – 10:40 | CloudThinker Agentic Orchestration, Context Optimization on Amazon Bedrock (L300) (30 phút) Henry Bui, Head of Engineering, CloudThinker\nAgentic orchestration patterns Context optimization techniques nâng cao Tích hợp với Amazon Bedrock Advanced use cases và best practices Performance optimization Cost optimization strategies Demo: CloudThinker platform 10:40 – 11:00 | Tea Break \u0026amp; Networking (20 phút) Nghỉ giải lao Networking với các chuyên gia và participants Q\u0026amp;A không chính thức Complimentary refreshments 11:00 – 12:00 | CloudThinker Hack: Hands-on Workshop (60 phút) Kha Van, Community Leader, AWS\nHands-on workshop với môi trường AWS thực tế Xây dựng Bedrock Agent từ đầu Thực hành context optimization Agentic orchestration patterns Troubleshooting và best practices Q\u0026amp;A và hỗ trợ trực tiếp 12:00 Onwards | Networking \u0026amp; Lunch Buffet Networking mở rộng Lunch buffet Gặp gỡ các chuyên gia Chia sẻ experiences và learnings Meet Our Experts Nguyen Gia Hung Head of Solutions Architect, AWS\nChuyên gia hàng đầu về AWS architecture và solutions Kinh nghiệm sâu rộng trong việc tư vấn và triển khai giải pháp cloud Người dẫn dắt các chương trình AWS tại Việt Nam Kien Nguyen Solutions Architect, AWS\nChuyên gia về AWS Bedrock và AI services Kinh nghiệm trong việc xây dựng AI/ML solutions Expert về agentic AI và context optimization Viet Pham Founder \u0026amp; CEO, Diaflow\nEntrepreneur với kinh nghiệm trong AI và cloud computing Chuyên gia về agentic workflows và automation Founder của Diaflow - giải pháp AI workflow Kha Van Community Leader, AWS\nAWS Community Leader Chuyên gia về hands-on training và workshops Mentor cho AWS community Thang Ton Co-Founder \u0026amp; COO, CloudThinker\nCo-founder của CloudThinker Chuyên gia về cloud orchestration và automation Expert về agentic orchestration platforms Henry Bui Head of Engineering, CloudThinker\nChuyên gia về agentic orchestration Kinh nghiệm trong việc tối ưu hóa context và performance Expert về L300 technical deep-dive sessions Nội Dung Nổi Bật Building Agentic AI Giới thiệu Agentic AI:\nAgentic AI là gì và tại sao quan trọng Autonomous AI agents vs traditional AI Use cases và applications Future of AI với agentic systems Context Optimization:\nTại sao context optimization quan trọng Techniques để optimize context Cost reduction strategies Performance improvement Best practices AWS Bedrock Agent Core Kiến trúc Bedrock Agent:\nAgent: Entity chính thực hiện các tác vụ Knowledge Base: Nguồn thông tin cho agent Action Groups: Các hành động agent có thể thực hiện Orchestration: Quản lý flow và context Context Management: Tối ưu hóa context Tính năng chính:\nNatural language understanding Context management và optimization Multi-step reasoning Integration với AWS services Custom actions và workflows Agentic Workflow Use Case Building Agentic Workflow:\nThiết kế workflow phức tạp với nhiều agents Orchestration và coordination giữa các agents Context optimization trong workflows Error handling và retry logic Monitoring và observability Best Practices:\nDesign patterns cho agentic workflows Context management strategies Performance optimization Cost optimization Security và compliance CloudThinker Agentic Orchestration Agentic Orchestration Patterns:\nSequential workflows Parallel execution Conditional branching Error recovery và fallback Context sharing giữa agents Context Optimization Techniques:\nContext compression và summarization Relevant information extraction Memory management Cost optimization strategies Performance tuning Integration với Amazon Bedrock:\nSeamless integration với Bedrock models Custom model selection Prompt engineering và optimization Response formatting và validation Context optimization APIs Những Gì Học Được Hiểu về Building Agentic AI Agentic AI là gì: Autonomous AI agents có khả năng thực hiện tasks độc lập Context Optimization: Techniques để optimize context và giảm costs Use cases: Các trường hợp sử dụng thực tế cho agentic AI Architecture: Kiến trúc và design patterns AWS Bedrock Agent Bedrock Agent Core: Hiểu cách agent hoạt động và tương tác Context Management: Quản lý và optimize context Integration: Cách tích hợp với các AWS services khác Best Practices: Best practices từ AWS experts Agentic Workflow Design Workflow patterns: Các pattern phổ biến cho agentic workflows Orchestration: Cách quản lý và điều phối nhiều agents Context Optimization: Strategies cho context optimization Error handling: Strategies cho xử lý lỗi và recovery CloudThinker Platform Agentic orchestration: Cách CloudThinker giải quyết orchestration challenges Context optimization: Advanced techniques để optimize context Platform capabilities: Các tính năng và khả năng của CloudThinker Integration patterns: Cách tích hợp CloudThinker vào existing systems Hands-on Experience Practical skills: Kỹ năng thực tế trong việc xây dựng Bedrock Agents Context optimization: Thực hành context optimization techniques Troubleshooting: Cách debug và troubleshoot common issues Real-world scenarios: Làm việc với các scenarios thực tế Ứng Dụng Vào Công Việc Xây dựng Agentic AI: Sử dụng AWS Bedrock Agent để xây dựng autonomous AI agents Context Optimization: Áp dụng context optimization techniques để giảm costs và improve performance Thiết kế Workflows: Áp dụng agentic workflow patterns vào các dự án Tích hợp CloudThinker: Đánh giá và tích hợp CloudThinker vào existing solutions Best Practices: Áp dụng best practices từ workshop vào production systems Trải nghiệm trong event Tham gia workshop \u0026ldquo;Building Agentic AI: Context Optimization with Amazon Bedrock\u0026rdquo; là một trải nghiệm học tập chuyên sâu về agentic AI và context optimization. Sự kiện cung cấp cả kiến thức lý thuyết và hands-on practice, giúp em hiểu rõ về cách xây dựng và tối ưu hóa autonomous AI agents.\nOpening và giới thiệu Opening session của Nguyen Gia Hung tạo không khí chuyên nghiệp và inspiring. Em hiểu về tầm quan trọng của Building Agentic AI và Context Optimization. Overview về event agenda giúp em hình dung rõ hành trình học tập. AWS Bedrock Agent Core Session của Kien Nguyen cung cấp foundation vững chắc về Bedrock Agent. Em học về kiến trúc, components, và cách thức hoạt động của Bedrock Agent. Context management là điểm nhấn quan trọng trong session này. Demo tạo Bedrock Agent cho thấy quy trình thực tế từ đầu đến cuối. Use Case thực tế Use case presentation của Viet Pham minh họa cách agentic workflows được sử dụng trong production. Học về challenges thực tế và cách giải quyết chúng. Context optimization trong production rất practical và insightful. Demo agentic workflow cho thấy performance và capabilities trong thực tế. CloudThinker Platform CloudThinker introduction của Thang Ton giới thiệu về platform và giải pháp. L300 session của Henry Bui đi sâu vào technical details và advanced patterns. Học về context optimization techniques nâng cao để improve performance và reduce costs. Demo CloudThinker platform cho thấy capabilities và ease of use. Hands-on Workshop Hands-on workshop của Kha Van cung cấp cơ hội thực hành trực tiếp. Xây dựng Bedrock Agent từ đầu với guidance từ expert. Thực hành context optimization và agentic orchestration. Troubleshooting session giúp em hiểu cách giải quyết common issues. Q\u0026amp;A trực tiếp cung cấp answers cho specific questions. Networking và kết nối Networking sessions cho phép kết nối với các AWS experts và AI practitioners. Chia sẻ experiences và learnings với other participants. Lunch buffet tạo cơ hội cho informal discussions và connections. Gặp gỡ các chuyên gia và nhận advice về career development. Bài học rút ra Agentic AI là tương lai: Autonomous AI agents sẽ thay đổi cách chúng ta xây dựng AI applications. Context Optimization là key: Optimizing context có thể significantly reduce costs và improve performance. Hands-on practice is essential: Practical experience là crucial để truly understand và apply concepts. Platform solutions matter: CloudThinker và các platforms tương tự simplify việc xây dựng agentic systems. Community is valuable: Networking với experts và practitioners cung cấp valuable insights và opportunities. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop này cung cấp cho em kiến thức toàn diện về Building Agentic AI và Context Optimization với Amazon Bedrock. Sự kết hợp giữa lý thuyết, use cases thực tế, và hands-on practice cho em tự tin để bắt đầu xây dựng autonomous AI agents trên AWS. Đặc biệt, phần về context optimization và hands-on workshop cung cấp practical skills có thể áp dụng ngay vào công việc. Workshop này là essential cho bất kỳ ai muốn hiểu sâu về agentic AI và cách optimize context để giảm costs và improve performance.\nWhat\u0026rsquo;s Included: ✓ Technical deep-dive sessions (L300)\n✓ Live demos and use case presentations\n✓ Hands-on workshop with real AWS environments\n✓ Networking with AWS experts and AI practitioners\n✓ Complimentary refreshments and lunch buffet\nIMPORTANT: Please bring your laptop to participate in the hands-on exercises\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; Mục Đích Của Sự Kiện Giới thiệu AWS Well-Architected Framework Security Pillar Trình diễn 5 pillars chính của Security: IAM, Detection, Infrastructure Protection, Data Protection, và Incident Response Chia sẻ best practices và nguyên tắc cốt lõi về cloud security Cung cấp kiến thức thực tế về các threats và cách phòng chống tại Việt Nam Hướng dẫn xây dựng security architecture theo chuẩn AWS Well-Architected Kết nối với các chuyên gia security và cloud practitioners Chi Tiết Sự Kiện Ngày: Thứ Bảy, 29 tháng 11 năm 2025 Thời gian: 08:30 – 12:00 Địa điểm: AWS Vietnam Office, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh Thời lượng: 3.5 giờ (bao gồm coffee break) Chương Trình 8:30 – 8:50 | Khai mạc \u0026amp; Security Foundation (20 phút) Vai trò Security Pillar trong Well-Architected Framework Nguyên tắc cốt lõi: Least Privilege: Cấp quyền tối thiểu cần thiết Zero Trust: Không tin tưởng mặc định, luôn xác minh Defense in Depth: Bảo vệ nhiều lớp Shared Responsibility Model: Trách nhiệm của AWS và khách hàng Top threats trong môi trường cloud tại Việt Nam Q\u0026amp;A ⭐ Pillar 1 — Identity \u0026amp; Access Management 8:50 – 9:30 | Modern IAM Architecture (40 phút) IAM Fundamentals:\nUsers, Roles, Policies – tránh long-term credentials Best practices cho IAM setup Temporary credentials và session management IAM Identity Center:\nSingle Sign-On (SSO) configuration Permission sets và assignment Multi-account management Advanced IAM:\nService Control Policies (SCP) cho multi-account Permission boundaries để giới hạn quyền MFA (Multi-Factor Authentication) requirements Credential rotation strategies Access Analyzer để phát hiện external access Mini Demo: Validate IAM Policy + simulate access\nKiểm tra policy syntax và permissions Mô phỏng access scenarios Troubleshooting common IAM issues ⭐ Pillar 2 — Detection 9:30 – 9:55 | Detection \u0026amp; Continuous Monitoring (25 phút) AWS Security Services:\nCloudTrail: Organization-level logging và audit GuardDuty: Threat detection và intelligent security Security Hub: Centralized security findings Comprehensive Logging:\nVPC Flow Logs: Network traffic monitoring ALB Access Logs: Application layer monitoring S3 Access Logs: Object access tracking Logging tại mọi tầng của infrastructure Alerting \u0026amp; Automation:\nEventBridge rules cho security events Automated response workflows Integration với notification systems Detection-as-Code:\nInfrastructure as Code cho security rules Version control cho detection rules Automated deployment và testing 9:55 – 10:10 | Coffee Break (15 phút) Nghỉ giải lao Networking với các participants Q\u0026amp;A không chính thức ⭐ Pillar 3 — Infrastructure Protection 10:10 – 10:40 | Network \u0026amp; Workload Security (30 phút) Network Security:\nVPC Segmentation: Tách biệt network segments Private vs Public placement strategies Network isolation và security zones Security Groups vs NACLs:\nKhi nào sử dụng Security Groups Khi nào sử dụng NACLs Mô hình áp dụng thực tế Best practices và common mistakes Advanced Network Protection:\nAWS WAF: Web Application Firewall AWS Shield: DDoS protection Network Firewall: Managed network firewall service Workload Protection:\nEC2 Security: Instance hardening, patch management ECS Security: Container security best practices EKS Security: Kubernetes security fundamentals Security baselines và compliance ⭐ Pillar 4 — Data Protection 10:40 – 11:10 | Encryption, Keys \u0026amp; Secrets (30 phút) AWS KMS (Key Management Service):\nKey policies và access control Grants và delegation Key rotation strategies Multi-region key management Encryption at Rest:\nS3: Server-side encryption (SSE-S3, SSE-KMS, SSE-C) EBS: Volume encryption và snapshots RDS: Database encryption DynamoDB: Table encryption Encryption in Transit:\nTLS/SSL best practices Certificate management End-to-end encryption Secrets Management:\nSecrets Manager: Automated rotation patterns Parameter Store: Secure parameter storage Rotation patterns và best practices Integration với applications Data Classification \u0026amp; Access Guardrails:\nData classification frameworks Access controls based on classification Compliance và regulatory requirements ⭐ Pillar 5 — Incident Response 11:10 – 11:40 | IR Playbook \u0026amp; Automation (30 phút) IR Lifecycle theo AWS:\nPrepare: Chuẩn bị và planning Detect: Phát hiện incidents Respond: Phản ứng và containment Recover: Khôi phục và lessons learned IR Playbooks cho Common Scenarios:\n1. Compromised IAM Key:\nPhát hiện compromised credentials Immediate response steps Key rotation và access revocation Investigation và forensics 2. S3 Public Exposure:\nPhát hiện public buckets Immediate remediation Access review và audit Prevention strategies 3. EC2 Malware Detection:\nPhát hiện malware và suspicious activity Isolation procedures Evidence collection Cleanup và recovery Automated Response:\nLambda functions cho automated response Step Functions cho complex workflows Integration với security services Playbook automation patterns Evidence Collection:\nSnapshot creation cho forensics Log preservation Chain of custody Compliance với legal requirements 11:40 – 12:00 | Wrap-Up \u0026amp; Q\u0026amp;A (20 phút) Tổng kết 5 pillars của Security Common pitfalls và mistakes thường gặp Thực tế doanh nghiệp Việt Nam: Security challenges tại Việt Nam Compliance requirements Best practices cho local context Roadmap security learning: AWS Certified Security – Specialty AWS Certified Solutions Architect – Professional Security training paths Q\u0026amp;A session Chụp ảnh lưu niệm Nội Dung Nổi Bật Security Foundation Principles Least Privilege:\nChỉ cấp quyền tối thiểu cần thiết để thực hiện công việc Regular review và audit permissions Sử dụng temporary credentials thay vì long-term keys Principle of least privilege trong mọi layer Zero Trust:\nKhông tin tưởng mặc định, luôn xác minh Verify identity và authorization cho mọi request Network segmentation và micro-segmentation Continuous verification và monitoring Defense in Depth:\nBảo vệ nhiều lớp: Network, Application, Data, Identity Không phụ thuộc vào một lớp bảo vệ duy nhất Layered security controls Fail-safe defaults Shared Responsibility Model:\nAWS: Security OF the cloud (infrastructure) Customer: Security IN the cloud (data, applications, configurations) Hiểu rõ trách nhiệm của mỗi bên Best practices cho customer responsibilities Pillar 1: Identity \u0026amp; Access Management Modern IAM Architecture:\nSử dụng IAM Roles thay vì Users khi có thể Temporary credentials với STS IAM Identity Center cho SSO Permission boundaries và SCPs Best Practices:\nEnable MFA cho tất cả users Regular credential rotation Use Access Analyzer để phát hiện external access Least privilege policies Regular access reviews Pillar 2: Detection Comprehensive Monitoring:\nCloudTrail cho audit trail GuardDuty cho threat detection Security Hub cho centralized view VPC Flow Logs cho network monitoring Detection-as-Code:\nVersion control cho detection rules Automated testing CI/CD cho security rules Infrastructure as Code approach Pillar 3: Infrastructure Protection Network Security:\nVPC segmentation Security Groups và NACLs WAF, Shield, Network Firewall Private subnets và NAT gateways Workload Security:\nEC2 hardening Container security Kubernetes security Patch management Pillar 4: Data Protection Encryption:\nEncryption at rest với KMS Encryption in transit với TLS Key management best practices Secrets management Data Classification:\nClassify data by sensitivity Apply appropriate controls Access guardrails Compliance requirements Pillar 5: Incident Response IR Lifecycle:\nPrepare: Planning và tools Detect: Monitoring và alerting Respond: Containment và investigation Recover: Restoration và lessons learned Automation:\nAutomated response với Lambda Step Functions cho workflows Integration với security services Playbook automation Những Gì Học Được Security Foundation Well-Architected Framework: Hiểu về Security Pillar và vai trò Core Principles: Least Privilege, Zero Trust, Defense in Depth Shared Responsibility: Trách nhiệm của AWS và customer Threat Landscape: Top threats tại Việt Nam và cách phòng chống IAM Best Practices Modern IAM: Sử dụng roles, temporary credentials IAM Identity Center: SSO và permission management Advanced Features: SCPs, permission boundaries, Access Analyzer Security: MFA, credential rotation, least privilege Detection \u0026amp; Monitoring Security Services: CloudTrail, GuardDuty, Security Hub Comprehensive Logging: VPC Flow Logs, ALB logs, S3 logs Alerting: EventBridge và automation Detection-as-Code: Infrastructure as Code cho security Infrastructure Protection Network Security: VPC segmentation, Security Groups, NACLs Advanced Protection: WAF, Shield, Network Firewall Workload Security: EC2, ECS, EKS security Best Practices: Hardening và patch management Data Protection Encryption: At rest và in transit KMS: Key management và rotation Secrets Management: Secrets Manager và Parameter Store Data Classification: Access guardrails và compliance Incident Response IR Lifecycle: Prepare, Detect, Respond, Recover Playbooks: Common scenarios và response procedures Automation: Lambda và Step Functions Forensics: Evidence collection và preservation Ứng Dụng Vào Công Việc Thiết kế Security Architecture: Áp dụng 5 pillars vào architecture design Implement IAM Best Practices: Sử dụng modern IAM patterns Setup Detection: Triển khai comprehensive monitoring Protect Infrastructure: Áp dụng network và workload security Protect Data: Implement encryption và secrets management Prepare IR: Xây dựng incident response playbooks và automation Security Reviews: Regular security assessments và improvements Trải nghiệm trong event Tham gia workshop \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; là một trải nghiệm học tập chuyên sâu về cloud security. Sự kiện cung cấp kiến thức toàn diện về 5 pillars của Security và best practices thực tế, giúp em hiểu rõ cách xây dựng secure cloud architecture.\nSecurity Foundation Opening session giới thiệu về Security Pillar trong Well-Architected Framework. Em học về các nguyên tắc cốt lõi: Least Privilege, Zero Trust, Defense in Depth. Shared Responsibility Model giúp em hiểu rõ trách nhiệm của AWS và customer. Top threats tại Việt Nam cung cấp context thực tế cho security challenges. Modern IAM Architecture IAM session đi sâu vào modern IAM patterns và best practices. Học về IAM Identity Center cho SSO và multi-account management. Advanced features như SCPs và permission boundaries rất hữu ích. Demo validate IAM policy cho thấy practical approach để test policies. Detection \u0026amp; Continuous Monitoring Detection session bao phủ comprehensive monitoring strategy. CloudTrail, GuardDuty, và Security Hub tạo thành security monitoring stack mạnh mẽ. Logging tại mọi tầng giúp em hiểu về defense in depth. Detection-as-Code approach rất innovative và practical. Network \u0026amp; Workload Security Infrastructure Protection session đi sâu vào network security. Hiểu rõ khi nào sử dụng Security Groups vs NACLs. Advanced protection với WAF, Shield, Network Firewall. Workload security cho EC2, ECS, EKS cung cấp practical guidance. Data Protection Data Protection session bao phủ encryption và secrets management. KMS key management và rotation strategies rất quan trọng. Encryption at rest và in transit cho tất cả services. Secrets Manager patterns cho automated rotation. Incident Response IR session cung cấp practical playbooks cho common scenarios. Học về IR lifecycle và best practices. Automated response với Lambda và Step Functions rất powerful. Evidence collection procedures cho forensics và compliance. Wrap-up và Q\u0026amp;A Wrap-up session tổng kết 5 pillars một cách comprehensive. Common pitfalls giúp em tránh những mistakes thường gặp. Thực tế doanh nghiệp Việt Nam cung cấp local context. Roadmap learning cho security certifications rất hữu ích. Bài học rút ra Security là foundation: Phải thiết kế security từ đầu, không phải add-on sau. Defense in Depth: Không phụ thuộc vào một lớp bảo vệ duy nhất. Automation is key: Automated detection và response giảm response time. Continuous improvement: Security là ongoing process, không phải one-time setup. Compliance matters: Hiểu về regulatory requirements và best practices. Practice makes perfect: Cần thực hành và review thường xuyên. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop này cung cấp cho em kiến thức toàn diện về AWS Well-Architected Security Pillar. Sự kết hợp giữa lý thuyết, best practices, và practical demos cho em foundation vững chắc để xây dựng secure cloud architecture. Đặc biệt, phần về incident response và automation cung cấp practical skills có thể áp dụng ngay vào công việc. Workshop này là essential cho bất kỳ ai muốn hiểu sâu về cloud security trên AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Thiết lập CI/CD Pipeline: Kết nối GitLab repository với AWS CodePipeline cho automated deployments. Cấu hình AWS CodeBuild cho frontend và backend builds với automatic S3 upload và CloudFront invalidation. Triển khai SSH-less deployment cho backend sử dụng AWS Systems Manager hoặc CodeDeploy. Thiết lập monitoring toàn diện với CloudWatch logs, metrics, và enhanced monitoring cho EC2 và RDS. Cấu hình AWS CloudTrail cho audit logging và security compliance. Thiết lập SNS Alerts với CloudWatch alarms cho critical metrics (EC2 CPU, RDS connections, API 5xx errors). Thực hiện end-to-end testing và tạo final project documentation với complete architecture diagram. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 19 - Tích hợp GitLab với CodePipeline: + Tạo GitLab repository cho dự án (nếu chưa tạo). + Thiết lập AWS CodePipeline với source stage kết nối với GitLab repository. + Cấu hình webhook hoặc polling cho automatic pipeline triggers trên code commits. + Tạo S3 bucket cho pipeline artifacts storage. + Kiểm tra pipeline trigger bằng cách tạo test commit vào GitLab repository. + Xác minh CodePipeline có thể kết nối thành công với GitLab và retrieve source code. 16/11/2025 16/11/2025 Tài liệu CodePipeline 20 - CodeBuild cho Frontend: + Tạo CodeBuild project cho frontend build process. + Cấu hình buildspec.yml file cho frontend build steps (install dependencies, build assets, optimize). + Thiết lập CodeBuild environment với Docker image phù hợp (Node.js, npm, v.v.). + Cấu hình build output để upload built files lên S3 bucket (FE Bucket). + Thiết lập automatic CloudFront invalidation sau khi upload S3 (invalidate cache cho updated files). + Kiểm tra frontend build process và xác minh files được upload lên S3 và CloudFront cache được invalidate. 17/11/2025 17/11/2025 Tài liệu CodeBuild 21 - CodeBuild cho Backend \u0026amp; SSH-less Deployment: + Tạo CodeBuild project cho backend build process. + Cấu hình buildspec.yml cho backend build steps (compile, test, package artifacts). + Thiết lập CodeBuild environment cho backend (Java/Python/Node.js dựa trên application). + Cấu hình artifact upload lên S3 hoặc CodeDeploy. + Triển khai SSH-less deployment sử dụng AWS Systems Manager (SSM) hoặc CodeDeploy: - Option 1: Sử dụng SSM Run Command để deploy lên EC2 instances mà không cần SSH. - Option 2: Sử dụng CodeDeploy để deploy application lên Auto Scaling Group. + Kiểm tra backend build và deployment process end-to-end. 18/11/2025 18/11/2025 Tài liệu CodeDeploy / SSM 22 - Thiết lập CloudWatch Logs \u0026amp; Metrics: + Tạo CloudWatch log groups cho EC2 application logs. + Cấu hình CloudWatch agent trên EC2 instances để gửi logs và custom metrics. + Thiết lập CloudWatch metrics cho EC2: CPU utilization, memory, disk I/O, network. + Bật RDS Enhanced Monitoring cho detailed database metrics. + Cấu hình API Gateway access logs vào CloudWatch Logs. + Tạo CloudWatch dashboards cho monitoring application health và performance. + Cấu hình log retention policies cho cost optimization. 19/11/2025 19/11/2025 Tài liệu CloudWatch 23 - CloudTrail \u0026amp; Audit Dashboard: + Bật AWS CloudTrail cho API call logging trên tất cả AWS services. + Tạo CloudTrail trail với S3 bucket cho log storage. + Cấu hình CloudTrail log file validation và encryption. + Thiết lập CloudWatch Logs integration cho CloudTrail events (tùy chọn). + Tạo CloudWatch dashboard cho audit và security monitoring. + Xem xét CloudTrail logs để xác minh API call logging hoạt động đúng. + Tài liệu hóa CloudTrail configuration và log retention policies. 20/11/2025 20/11/2025 Tài liệu CloudTrail 24 - SNS Alerts \u0026amp; CloudWatch Alarms: + Tạo SNS topic cho alarm notifications. + Subscribe email/SMS endpoints vào SNS topic. + Tạo CloudWatch alarm cho EC2 CPU utilization (threshold: \u0026gt;80% trong 5 phút). + Tạo CloudWatch alarm cho RDS database connections (threshold: \u0026gt;80% của max connections). + Tạo CloudWatch alarm cho API Gateway 5xx errors (threshold: \u0026gt;10 errors trong 5 phút). + Cấu hình alarm actions để gửi notifications qua SNS. + Kiểm tra alarms bằng cách trigger conditions và xác minh email/SMS notifications được nhận. 21/11/2025 21/11/2025 CloudWatch Alarms \u0026amp; SNS 25 - End-to-End Testing \u0026amp; Tài liệu Cuối cùng: + Thực hiện comprehensive end-to-end testing: Users → Route 53 → CloudFront → WAF → API Gateway → EC2 → RDS. + Kiểm tra CI/CD pipeline với code changes: xác minh automated frontend và backend deployments. + Kiểm tra monitoring và alerting: trigger alarms và xác minh SNS notifications được nhận. + Kiểm tra security: xác minh IAM permissions, Cognito authentication, Secrets Manager access, WAF protection. + Kiểm tra scalability: xác minh Auto Scaling Group phản hồi với load changes. + Tạo final architecture diagram với tất cả components, data flows, và resource relationships. + Viết comprehensive project documentation: deployment procedures, troubleshooting guides, runbooks, và architecture overview. + Chuẩn bị Worklog summary cho tất cả 4 tuần (Tuần 8-11). - Tóm tắt tuần 11: Complete AWS web application architecture được triển khai với CI/CD, monitoring, security, và automation. Dự án sẵn sàng cho production use. 22/11/2025 22/11/2025 Tài liệu dự án Kết quả đạt được trong tuần 11: Thiết lập thành công CI/CD Pipeline:\nKết nối GitLab repository với AWS CodePipeline cho automated deployments. Cấu hình automatic pipeline triggers trên code commits (webhook hoặc polling). Tạo S3 bucket cho pipeline artifacts storage. Xác minh end-to-end pipeline connectivity và source code retrieval. Cấu hình CodeBuild cho Frontend:\nTạo CodeBuild project với buildspec.yml cho frontend build automation. Cấu hình build environment với Docker image và dependencies phù hợp. Thiết lập automatic S3 upload của built frontend files. Triển khai automatic CloudFront cache invalidation sau deployments. Xác minh frontend build và deployment process hoạt động đúng. Triển khai CodeBuild cho Backend với SSH-less Deployment:\nTạo CodeBuild project cho backend build automation. Cấu hình buildspec.yml cho backend compilation, testing, và packaging. Triển khai SSH-less deployment sử dụng AWS Systems Manager (SSM) hoặc CodeDeploy. Loại bỏ nhu cầu SSH keys và cải thiện security posture. Xác minh backend build và deployment process hoạt động end-to-end. Thiết lập CloudWatch Monitoring toàn diện:\nTạo CloudWatch log groups cho EC2 application logs. Cấu hình CloudWatch agent trên EC2 instances cho logs và custom metrics. Thiết lập CloudWatch metrics cho EC2 (CPU, memory, disk, network). Bật RDS Enhanced Monitoring cho detailed database insights. Cấu hình API Gateway access logs vào CloudWatch Logs. Tạo CloudWatch dashboards cho real-time monitoring. Cấu hình log retention policies cho cost optimization. Cấu hình CloudTrail cho Audit và Compliance:\nBật CloudTrail cho comprehensive API call logging. Tạo CloudTrail trail với S3 bucket cho secure log storage. Cấu hình log file validation và encryption. Thiết lập CloudWatch dashboard cho audit monitoring. Thiết lập audit trail cho security và compliance requirements. Triển khai SNS Alerts và CloudWatch Alarms:\nTạo SNS topic cho alarm notifications với email/SMS subscriptions. Tạo CloudWatch alarm cho EC2 CPU utilization monitoring. Tạo CloudWatch alarm cho RDS database connection monitoring. Tạo CloudWatch alarm cho API Gateway 5xx error detection. Cấu hình alarm actions để gửi notifications qua SNS. Kiểm tra alarms và xác minh notification delivery. Thực hiện comprehensive end-to-end testing:\nXác minh complete application flow: Users → Route 53 → CloudFront → WAF → API Gateway → EC2 → RDS. Kiểm tra CI/CD pipeline với code changes và xác minh automated deployments. Kiểm tra monitoring và alerting: trigger alarms và xác minh SNS notifications. Kiểm tra security: xác minh IAM permissions, Cognito authentication, Secrets Manager, WAF protection. Kiểm tra scalability: xác minh Auto Scaling Group phản hồi với load changes. Tạo final project documentation:\nTạo comprehensive architecture diagram với tất cả components, data flows, và resource relationships. Tài liệu hóa deployment procedures, troubleshooting guides, và runbooks. Chuẩn bị architecture overview và system design documentation. Hoàn tất Worklog summary cho tất cả 4 tuần (Tuần 8-11). Sau tuần 11, complete AWS web application architecture đã được triển khai đầy đủ, monitored, secured, và automated:\nEdge Layer: Route 53, CloudFront, AWS WAF, ACM Certificate, S3 (Frontend). Networking Layer: VPC, public/private subnets, Internet Gateway, NAT Gateway, Security Groups, VPC Flow Logs. Compute \u0026amp; Database Layer: EC2 (với Auto Scaling), RDS, API Gateway, Cognito. CI/CD Pipeline: GitLab, CodePipeline, CodeBuild (Frontend \u0026amp; Backend), SSH-less deployment. Monitoring \u0026amp; Security: CloudWatch (Logs, Metrics, Dashboards, Alarms), CloudTrail, SNS Alerts, IAM, Secrets Manager. Dự án thể hiện một AWS architecture production-ready, scalable, secure, và well-monitored theo best practices với complete automation và observability.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Triển khai Backend Layer: EC2 instances trong private subnet với application runtime và cấu hình Auto Scaling. Thiết lập Amazon RDS database trong private subnet với cấu hình và parameter groups phù hợp. Deploy backend application và thiết lập kết nối giữa EC2 và RDS sử dụng Secrets Manager. Cấu hình API Gateway REST API với tích hợp EC2 backend. Tích hợp Amazon Cognito User Pool với API Gateway cho authentication và authorization. Cấu hình Auto Scaling Group cho EC2 instances với Launch Template cho scalability. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 13 - Thiết lập RDS Database: + Tạo RDS subnet group bao phủ private subnet (10.0.2.0/24). + Launch RDS instance (MySQL/PostgreSQL) trong private subnet với instance class phù hợp. + Cấu hình RDS parameter group với database-specific settings (character set, timezone, v.v.). + Thiết lập automated backups, encryption at rest, và Multi-AZ deployment (tùy chọn cho cost optimization). + Cấu hình RDS security group để chỉ cho phép kết nối từ EC2 Security Group. + Lưu trữ database credentials ban đầu trong AWS Secrets Manager. 09/11/2025 09/11/2025 Tài liệu RDS 14 - Thiết lập EC2 Backend Instance: + Launch EC2 instance trong private subnet (10.0.2.0/24) với instance type phù hợp. + Cài đặt application runtime environment: Java/Python/Node.js dựa trên yêu cầu application. + Cài đặt và cấu hình application dependencies và libraries. + Cấu hình EC2 instance với IAM role (đã tạo trong tuần 9) cho AWS service access. + Tạo base AMI từ EC2 instance đã cấu hình cho Auto Scaling Group (sẽ sử dụng ở Ngày 18). + Tài liệu hóa cấu hình EC2 và application setup steps. 10/11/2025 10/11/2025 Tài liệu EC2 15 - Deployment Backend Application: + Deploy backend application code lên EC2 instance (manual deployment cho initial setup). + Cấu hình application để kết nối với RDS database sử dụng credentials từ Secrets Manager. + Kiểm tra database connectivity từ EC2 instance (xác minh connection string, credentials retrieval). + Cấu hình application environment variables và configuration files. + Kiểm tra basic application functionality và database operations (CRUD operations). + Tài liệu hóa deployment process và application configuration. 11/11/2025 11/11/2025 Hướng dẫn deployment 16 - Cấu hình API Gateway REST API: + Tạo REST API trong API Gateway với tên và mô tả phù hợp. + Định nghĩa API resources và methods (GET, POST, PUT, DELETE) dựa trên yêu cầu application. + Cấu hình API Gateway integration với EC2 backend (HTTP/HTTPS integration hoặc VPC Link cho private resources). + Thiết lập API Gateway VPC Link để kết nối với private subnet resources (EC2). + Bật CORS cho frontend access (cấu hình CORS headers: Access-Control-Allow-Origin, v.v.). + Kiểm tra API endpoints và xác minh tích hợp với EC2 backend. 12/11/2025 12/11/2025 Tài liệu API Gateway 17 - Tích hợp Amazon Cognito: + Tạo Cognito User Pool cho user authentication với tên phù hợp. + Cấu hình user pool settings: password policies (minimum length, complexity), MFA (tùy chọn), email verification. + Tạo Cognito User Pool App Client cho application integration. + Cấu hình Cognito Authorizer trong API Gateway cho authenticated API access. + Kiểm tra user registration flow: tạo test user trong Cognito User Pool. + Kiểm tra login flow: authenticate user và obtain JWT tokens. + Kiểm tra authenticated API access: sử dụng JWT token để truy cập protected API endpoints. 13/11/2025 13/11/2025 Tài liệu Cognito 18 - Cấu hình Auto Scaling Group: + Tạo Launch Template dựa trên base AMI đã tạo ở Ngày 14. + Cấu hình Launch Template với instance type, security groups, IAM role, và user data scripts. + Tạo Auto Scaling Group với Launch Template trong private subnet. + Cấu hình Auto Scaling policies: target tracking (CPU utilization, network in/out), step scaling, hoặc scheduled scaling. + Thiết lập minimum, desired, và maximum capacity cho Auto Scaling Group. + Kiểm tra scale-out: trigger scaling bằng cách tăng load (hoặc manually adjust desired capacity). + Kiểm tra scale-in: giảm load và xác minh instances được terminate tự động. - Tóm tắt tuần 10: Backend và database layer hoàn tất, sẵn sàng cho CI/CD và monitoring setup trong tuần 11. 14/11/2025 14/11/2025 Tài liệu Auto Scaling Kết quả đạt được trong tuần 10: Triển khai thành công Amazon RDS database:\nTạo RDS subnet group trong private subnet để cô lập database. Launch RDS instance (MySQL/PostgreSQL) với instance class và cấu hình phù hợp. Cấu hình RDS parameter group với database-specific settings. Thiết lập automated backups, encryption at rest, và monitoring. Cấu hình RDS security group để chỉ cho phép kết nối từ EC2 Security Group. Lưu trữ database credentials an toàn trong AWS Secrets Manager. Thiết lập EC2 backend infrastructure:\nLaunch EC2 instance trong private subnet với instance type phù hợp. Cài đặt và cấu hình application runtime environment (Java/Python/Node.js). Cấu hình EC2 instance với IAM role cho AWS service access. Tạo base AMI từ EC2 instance đã cấu hình cho Auto Scaling Group. Tài liệu hóa cấu hình EC2 và application setup procedures. Deploy backend application:\nDeploy backend application code lên EC2 instance. Cấu hình application để kết nối với RDS sử dụng credentials từ Secrets Manager. Kiểm tra database connectivity và xác minh connection functionality. Kiểm tra basic application functionality và database operations (CRUD). Tài liệu hóa deployment process và application configuration. Cấu hình API Gateway REST API:\nTạo REST API với resources, methods, và integration points. Thiết lập API Gateway VPC Link để kết nối với private subnet resources (EC2). Cấu hình API Gateway integration với EC2 backend sử dụng HTTP/HTTPS. Bật CORS cho frontend access với proper headers. Kiểm tra API endpoints và xác minh tích hợp với EC2 backend. Tích hợp Amazon Cognito cho authentication:\nTạo Cognito User Pool với password policies, MFA, và email verification. Tạo Cognito User Pool App Client cho application integration. Cấu hình Cognito Authorizer trong API Gateway cho authenticated API access. Kiểm tra user registration, login, và authenticated API access flows. Thiết lập secure user authentication và authorization. Cấu hình Auto Scaling Group cho scalability:\nTạo Launch Template dựa trên base AMI cho consistent instance configuration. Tạo Auto Scaling Group với Launch Template trong private subnet. Cấu hình Auto Scaling policies (target tracking, step scaling) cho automatic scaling. Thiết lập capacity limits phù hợp (minimum, desired, maximum). Kiểm tra scale-out và scale-in functionality để xác minh automatic scaling. Sau tuần 10, backend và database layer đã hoạt động với scalable infrastructure. Application sẵn sàng cho CI/CD automation và comprehensive monitoring trong tuần 11.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Xây dựng VPC và Networking Core: Tạo VPC với public và private subnets, Internet Gateway, và NAT Gateway. Thiết lập ranh giới mạng an toàn với routing và subnet segmentation phù hợp. Cấu hình Security Groups cho EC2, RDS, và ALB theo nguyên tắc least-privilege. Thiết lập IAM roles và policies cho EC2 instances với custom permissions. Bật VPC Flow Logs cho network traffic monitoring và auditing. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 7 - Tạo VPC \u0026amp; Cấu hình Subnet: + Tạo VPC với CIDR block 10.0.0.0/16 trong AWS region đã chọn. + Tạo public subnet (10.0.1.0/24) trong một Availability Zone với tags phù hợp. + Tạo private subnet (10.0.2.0/24) trong cùng Availability Zone với tags phù hợp. + Áp dụng tagging strategy nhất quán (Name, Environment, Project, v.v.) cho tất cả resources. + Tài liệu hóa subnet allocation và IP addressing scheme. 02/11/2025 02/11/2025 Tài liệu AWS VPC 8 - Thiết lập Internet Gateway: + Tạo và gắn Internet Gateway vào VPC. + Cấu hình public subnet route table để route internet-bound traffic (0.0.0.0/0) đến Internet Gateway. + Xác minh cấu hình public subnet route table. + Kiểm tra internet connectivity từ public subnet (launch test EC2 instance nếu cần). + Tài liệu hóa routing configuration và gateway associations. 03/11/2025 03/11/2025 Hướng dẫn Internet Gateway 9 - Cấu hình NAT Gateway: + Cấp phát Elastic IP address cho NAT Gateway. + Tạo NAT Gateway trong public subnet (10.0.1.0/24). + Cấu hình private subnet route table để route internet-bound traffic (0.0.0.0/0) qua NAT Gateway. + Xác minh cấu hình private subnet route table. + Kiểm tra outbound internet connectivity từ private subnet (launch test EC2 instance trong private subnet). + Xác minh private subnet instances có thể truy cập internet trong khi vẫn bị cô lập khỏi inbound connections. 04/11/2025 04/11/2025 Tài liệu NAT Gateway 10 - Thiết kế \u0026amp; Triển khai Security Groups: + Tạo Security Group cho EC2 instances: cho phép inbound từ API Gateway/ALB, outbound đến RDS và internet qua NAT. + Tạo Security Group cho RDS: chỉ cho phép inbound từ EC2 Security Group trên database port (3306/5432). + Tạo Security Group cho ALB (nếu sử dụng): cho phép inbound HTTP/HTTPS từ internet, outbound đến EC2 Security Group. + Áp dụng nguyên tắc least-privilege: cấp minimum permissions cần thiết. + Tài liệu hóa security group rules và relationships. 05/11/2025 05/11/2025 Hướng dẫn Security Groups 11 - IAM Roles \u0026amp; Policies cho EC2: + Tạo IAM role cho EC2 instances với tên mô tả. + Tạo custom IAM policy cho EC2 để truy cập các AWS services cần thiết (S3, Secrets Manager, CloudWatch, v.v.). + Gắn IAM role vào EC2 instance profile. + Kiểm tra IAM role permissions từ EC2 instance (sử dụng AWS CLI hoặc SDK). + Xác minh EC2 có thể truy cập Secrets Manager để retrieve database credentials. + Tài liệu hóa IAM roles và permissions của chúng. 06/11/2025 06/11/2025 IAM best practices 12 - Network ACLs \u0026amp; VPC Flow Logs: + Xem xét và cấu hình Network ACLs (tùy chọn, default ACLs thường đủ). + Kiểm tra Network ACL rules nếu custom rules được triển khai. + Bật VPC Flow Logs để capture IP traffic flow information. + Cấu hình Flow Logs destination (CloudWatch Logs hoặc S3 bucket). + Xem xét Flow Logs để audit network traffic patterns. + Audit và tài liệu hóa tất cả cấu hình mạng cho security review. - Tóm tắt tuần 9: VPC và networking core hoàn tất, sẵn sàng cho backend và database deployment trong tuần 10. 07/11/2025 07/11/2025 Tài liệu VPC Flow Logs Kết quả đạt được trong tuần 9: Tạo thành công VPC và subnet infrastructure:\nTạo VPC với CIDR block 10.0.0.0/16 trong AWS region đã chọn. Cấu hình public subnet (10.0.1.0/24) cho internet-facing resources với tagging phù hợp. Cấu hình private subnet (10.0.2.0/24) cho application servers với tagging phù hợp. Áp dụng tagging strategy nhất quán trên tất cả network resources để quản lý tốt hơn. Thiết lập Internet Gateway cho public subnet connectivity:\nTạo và gắn Internet Gateway vào VPC. Cấu hình public subnet route table để route internet traffic (0.0.0.0/0) đến Internet Gateway. Xác minh public subnet instances có thể truy cập internet trực tiếp. Tài liệu hóa routing configuration và gateway associations. Cấu hình NAT Gateway cho private subnet outbound access:\nCấp phát Elastic IP address và tạo NAT Gateway trong public subnet. Cấu hình private subnet route table để route internet traffic qua NAT Gateway. Xác minh private subnet instances có thể truy cập internet cho outbound connections (updates, downloads, API calls). Xác nhận private subnet vẫn bị cô lập khỏi inbound internet connections (security best practice). Triển khai Security Groups theo nguyên tắc least-privilege:\nTạo Security Group cho EC2: cho phép inbound từ API Gateway/ALB, outbound đến RDS và internet. Tạo Security Group cho RDS: chỉ cho phép inbound từ EC2 Security Group trên database port. Tạo Security Group cho ALB (nếu sử dụng): cho phép inbound HTTP/HTTPS, outbound đến EC2. Áp dụng nguyên tắc least-privilege: cấp minimum permissions cần thiết cho mỗi component. Tài liệu hóa security group rules và relationships cho maintainability. Cấu hình IAM roles và policies cho EC2:\nTạo IAM role cho EC2 instances với naming mô tả. Tạo custom IAM policy cho EC2 để truy cập các AWS services cần thiết (S3, Secrets Manager, CloudWatch). Gắn IAM role vào EC2 instance profile. Kiểm tra IAM permissions từ EC2 instance và xác minh truy cập Secrets Manager. Tài liệu hóa IAM roles và permissions cho security audit. Bật VPC Flow Logs cho network monitoring:\nBật VPC Flow Logs để capture IP traffic flow information. Cấu hình Flow Logs destination (CloudWatch Logs hoặc S3 bucket). Xem xét Flow Logs để audit network traffic patterns và xác định anomalies. Audit tất cả cấu hình mạng cho security compliance. Sau tuần 9, VPC và networking core infrastructure đã hoàn tất với secure network boundaries, proper routing, và monitoring capabilities. Hệ thống sẵn sàng cho backend và database deployment trong tuần 10.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Hoàn thiện Edge Layer và Frontend Storage: Route 53, S3, CloudFront, AWS WAF, và ACM Certificate. Thiết lập quản lý DNS với Route 53 hosted zone và cấu hình domain. Cấu hình S3 bucket cho static frontend hosting với access policies phù hợp. Triển khai CloudFront distribution cho global content delivery với Origin Access Control. Triển khai AWS WAF protection với các quy tắc bảo mật (SQL injection, XSS, bot control). Thiết lập ACM Certificate và bật HTTPS cho secure content delivery. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Phân tích Yêu cầu Hệ thống \u0026amp; Thiết kế Kiến trúc: + Phân tích yêu cầu hệ thống và xem xét sơ đồ kiến trúc hoàn chỉnh. + Xác định tất cả các thành phần: Route 53, S3, CloudFront, WAF, ACM, VPC, EC2, RDS, API Gateway. + Tạo tài liệu High-Level Design (HLD) với tổng quan kiến trúc. + Tài liệu hóa data flow: Users → Route 53 → CloudFront → WAF → S3 (Frontend). + Lập kế hoạch IP addressing scheme và resource naming conventions. 26/10/2025 26/10/2025 Sơ đồ kiến trúc 2 - Thiết lập Route 53: + Tạo Route 53 hosted zone cho quản lý domain. + Tạo A record trỏ đến CloudFront distribution (dự kiến cho Ngày 4). + Tạo CNAME records cho subdomains nếu cần. + Cấu hình DNS settings và xác minh domain ownership. + Tài liệu hóa cấu hình DNS và record types. 27/10/2025 27/10/2025 Tài liệu Route 53 3 - Cấu hình S3 Frontend Bucket: + Tạo S3 bucket cho frontend static assets (FE Bucket) với tên phù hợp. + Bật static website hosting trên S3 bucket. + Cấu hình public access policy cho CloudFront access (block public access, allow CloudFront via OAC). + Upload test frontend files (HTML, CSS, JS, images) lên S3 bucket. + Kiểm tra static website hosting endpoint và xác minh file accessibility. 28/10/2025 28/10/2025 Tài liệu S3 4 - Thiết lập CloudFront Distribution: + Tạo CloudFront distribution với S3 bucket làm origin. + Cấu hình Origin Access Control (OAC) cho secure S3 access (thay thế OAI). + Thiết lập cache policies (CachingOptimized, CachingDisabled, v.v.). + Cấu hình default root object (index.html). + Map Route 53 domain vào CloudFront distribution (cập nhật A record từ Ngày 2). + Kiểm tra CloudFront distribution và xác minh content delivery. 29/10/2025 29/10/2025 Tài liệu CloudFront 5 - Tích hợp AWS WAF: + Tạo AWS WAF WebACL cho CloudFront protection. + Thêm managed rules: AWS Managed Rules cho SQL injection protection. + Thêm managed rules: AWS Managed Rules cho XSS (Cross-Site Scripting) protection. + Cấu hình bot control rules để chặn common bots và scrapers. + Liên kết WAF WebACL với CloudFront distribution. + Kiểm tra WAF rules bằng cách thử các mẫu tấn công phổ biến và xác minh blocking. 30/10/2025 30/10/2025 Tài liệu AWS WAF 6 - Cấu hình ACM Certificate \u0026amp; HTTPS: + Request ACM Certificate trong us-east-1 region (bắt buộc cho CloudFront). + Validate certificate sử dụng DNS validation method (thêm CNAME records vào Route 53). + Chờ certificate validation và issuance. + Bind ACM certificate vào CloudFront distribution. + Cấu hình CloudFront để sử dụng HTTPS only (redirect HTTP to HTTPS). + Kiểm tra HTTPS connection và xác minh SSL/TLS certificate hoạt động đúng. - Tóm tắt tuần 8: Edge layer và frontend storage hoàn tất, sẵn sàng cho VPC và networking setup trong tuần 9. 31/10/2025 31/10/2025 Tài liệu ACM Kết quả đạt được trong tuần 8: Hoàn thành thành công phân tích hệ thống và thiết kế kiến trúc:\nPhân tích yêu cầu hệ thống và xem xét sơ đồ kiến trúc hoàn chỉnh. Tạo tài liệu High-Level Design (HLD) với tổng quan kiến trúc và mối quan hệ các thành phần. Tài liệu hóa data flow từ users qua edge services đến frontend storage. Thiết lập resource naming conventions và planning documentation. Thiết lập quản lý DNS Route 53:\nTạo Route 53 hosted zone cho quản lý domain. Cấu hình A và CNAME records cho domain routing. Thiết lập nền tảng DNS để kết nối domain với CloudFront distribution. Cấu hình S3 cho static frontend hosting:\nTạo S3 bucket cho frontend static assets với naming conventions phù hợp. Bật static website hosting trên S3 bucket. Cấu hình public access policies: block public access, allow CloudFront access qua Origin Access Control. Upload test frontend files và xác minh static website hosting functionality. Triển khai CloudFront distribution:\nTạo CloudFront distribution với S3 bucket làm origin. Cấu hình Origin Access Control (OAC) cho secure S3 access (thay thế hiện đại cho OAI). Thiết lập cache policies cho optimized content delivery. Map Route 53 domain vào CloudFront distribution. Xác minh content delivery qua CloudFront CDN globally. Triển khai AWS WAF protection:\nTạo AWS WAF WebACL với các quy tắc bảo mật toàn diện. Thêm AWS Managed Rules cho SQL injection protection. Thêm AWS Managed Rules cho XSS (Cross-Site Scripting) protection. Cấu hình bot control rules để chặn malicious bots và scrapers. Liên kết WAF WebACL với CloudFront distribution. Kiểm tra WAF rules và xác minh protection chống lại các mẫu tấn công phổ biến. Bật HTTPS với ACM Certificate:\nRequest và validate ACM Certificate trong us-east-1 region (bắt buộc cho CloudFront). Sử dụng DNS validation method với CNAME records trong Route 53. Bind ACM certificate vào CloudFront distribution. Cấu hình CloudFront để enforce HTTPS (redirect HTTP to HTTPS). Xác minh SSL/TLS certificate hoạt động đúng và secure connections được thiết lập. Sau tuần 8, edge layer và frontend storage đã hoàn tất với secure, global content delivery. Hệ thống sẵn sàng cho VPC và networking core setup trong tuần 9.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Hiểu Amazon DynamoDB như một dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn: mô hình dữ liệu key-value và document, partition keys, sort keys, global secondary indexes (GSI), và các chế độ dung lượng on-demand vs provisioned. Học cách xây dựng và quản lý Data Lakes trên AWS sử dụng các dịch vụ như Amazon S3, AWS Glue, Amazon Athena, và Amazon QuickSight cho các workload phân tích. Khám phá các dịch vụ Analytics của AWS: Amazon Athena cho truy vấn SQL serverless trên S3, AWS Glue cho các thao tác ETL, và Amazon QuickSight cho business intelligence và visualization. Thực hành các quy trình ingestion, transformation, và phân tích dữ liệu trong môi trường đám mây AWS. Hiểu các chiến lược tối ưu hóa chi phí và hiệu năng cho analytics workloads trên AWS. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành Lab: Data Lake on AWS. + Hiểu kiến trúc data lake trên AWS sử dụng S3 làm lớp lưu trữ data lake. + Học về các mẫu ingestion, cataloging, và querying dữ liệu. + Khám phá tích hợp giữa S3, Glue, và Athena cho analytics. 20/10/2025 20/10/2025 https://000035.awsstudygroup.com/ 3 - Thực hành Lab: Amazon DynamoDB Immersion Day. + Đi sâu vào các khái niệm cốt lõi của DynamoDB: tables, items, attributes, primary keys, và indexes. + Thực hành tạo tables, chèn dữ liệu, và query với partition keys và sort keys. + Hiểu các chế độ dung lượng DynamoDB (on-demand vs provisioned) và mô hình định giá. 21/10/2025 21/10/2025 https://000039.awsstudygroup.com/ 4 - Thực hành Lab: Cost and performance analysis with AWS Glue and Amazon Athena. + Sử dụng AWS Glue để catalog dữ liệu lưu trữ trong S3 và tạo data catalogs. + Chạy các truy vấn SQL trên dữ liệu S3 sử dụng Amazon Athena. + Phân tích tác động chi phí và tối ưu hóa hiệu năng truy vấn. + Hiểu các chiến lược phân vùng cho analytics hiệu quả về chi phí. 22/10/2025 22/10/2025 https://000040.awsstudygroup.com/ 5 - Thực hành Lab: Work with Amazon DynamoDB. + Tạo DynamoDB tables với key schemas phù hợp. + Thực hiện các thao tác CRUD (Create, Read, Update, Delete) trên DynamoDB items. + Làm việc với Global Secondary Indexes (GSI) và Local Secondary Indexes (LSI). + Thực hành các thao tác querying và scanning, hiểu sự khác biệt. 23/10/2025 23/10/2025 https://000060.awsstudygroup.com/ 6 - Thực hành Lab: Building a Datalake with Your Data. + Xây dựng giải pháp data lake hoàn chỉnh sử dụng các dịch vụ AWS. + Triển khai các pipeline ingestion dữ liệu. + Thiết lập các workflow transformation dữ liệu với AWS Glue. + Tạo datasets sẵn sàng cho analytics để tiêu thụ downstream. 24/10/2025 24/10/2025 https://000070.awsstudygroup.com/ 7 - Thực hành Lab: Analytics on AWS workshop. + Workshop toàn diện bao gồm toàn bộ analytics stack trên AWS. + Tích hợp nhiều dịch vụ: S3, Glue, Athena, và các công cụ visualization. + Xây dựng các giải pháp analytics end-to-end từ dữ liệu thô đến insights. 25/10/2025 25/10/2025 https://000072.awsstudygroup.com/ 8 - Thực hành Lab: Get started with QuickSight. + Tạo visualizations và dashboards sử dụng Amazon QuickSight. + Kết nối QuickSight với các nguồn dữ liệu khác nhau (S3, Athena, RDS, v.v.). + Xây dựng các báo cáo tương tác và chia sẻ insights với các bên liên quan. - Tóm tắt và ôn tập tất cả AWS Analytics and Data Lake Services đã học trong tuần 7. 26/10/2025 26/10/2025 https://000073.awsstudygroup.com/ Kết quả đạt được trong tuần 7: Hiểu toàn diện về Amazon DynamoDB:\nDynamoDB như một dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn, serverless với độ trễ millisecond đơn lẻ. Các khái niệm chính: tables, items, attributes, primary keys (partition key + sort key tùy chọn), và best practices về data modeling. Global Secondary Indexes (GSI) và Local Secondary Indexes (LSI) cho các mẫu truy vấn linh hoạt. Chế độ dung lượng: on-demand (trả theo yêu cầu) vs provisioned (dung lượng dự trữ) và khi nào sử dụng mỗi loại. DynamoDB Streams cho xử lý dữ liệu real-time và change data capture. Xây dựng kinh nghiệm thực tế với kiến trúc Data Lake trên AWS:\nAmazon S3 làm nền tảng cho lưu trữ data lake với lifecycle policies, versioning, và encryption. Các mẫu kiến trúc data lake: raw zone, processed zone, và curated zone. Chiến lược ingestion dữ liệu: batch uploads, streaming data, và tích hợp với các nguồn dữ liệu khác nhau. Best practices cho tổ chức dữ liệu trong S3: partitioning, naming conventions, và cấu trúc thư mục. Thành thạo các dịch vụ Analytics của AWS:\nAWS Glue: Dịch vụ ETL serverless để khám phá, catalog, và transform dữ liệu. Glue Data Catalog như một kho lưu trữ metadata tập trung. Glue ETL jobs cho data transformation sử dụng Apache Spark. Glue Crawlers cho automatic schema discovery. Amazon Athena: Dịch vụ truy vấn SQL tương tác serverless để phân tích dữ liệu trong S3. Mô hình định giá trả theo truy vấn và chiến lược tối ưu hóa chi phí. Tích hợp với Glue Data Catalog cho schema-on-read queries. Tối ưu hóa hiệu năng truy vấn thông qua partitioning và định dạng cột (Parquet, ORC). Amazon QuickSight: Dịch vụ business intelligence và visualization cloud-native. Tạo dashboards, visualizations, và reports. Kết nối với các nguồn dữ liệu khác nhau (S3, Athena, RDS, Redshift, v.v.). Chia sẻ insights với teams và embedding analytics trong applications. Hoàn thành các phiên thực hành lab toàn diện:\nData Lake on AWS (Lab 35): Xây dựng hiểu biết nền tảng về kiến trúc data lake và các mẫu lưu trữ dựa trên S3. Amazon DynamoDB Immersion Day (Lab 39): Đi sâu vào các thao tác DynamoDB, data modeling, và best practices. Cost and performance analysis with AWS Glue and Amazon Athena (Lab 40): Học cách tối ưu hóa analytics workloads cho chi phí và hiệu năng. Work with Amazon DynamoDB (Lab 60): Thực hành các thao tác CRUD, chiến lược indexing, và query patterns. Building a Datalake with Your Data (Lab 70): Triển khai giải pháp data lake end-to-end với ingestion và transformation pipelines. Analytics on AWS workshop (Lab 72): Workshop toàn diện tích hợp nhiều dịch vụ analytics. Get started with QuickSight (Lab 73): Tạo visualizations và dashboards cho business intelligence. Sau tuần 7, thiết lập hiểu biết hoàn chỉnh về hệ sinh thái AWS Analytics và Data Lake:\nTừ NoSQL databases (DynamoDB) → Data Lake storage (S3) → ETL và cataloging (Glue) → Query và analysis (Athena) → Visualization (QuickSight), sẵn sàng thiết kế và triển khai các giải pháp analytics hiện đại trên AWS. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Ôn tập lại các khái niệm cơ bản về Database: mô hình quan hệ, khóa chính/khóa ngoại, ACID, chuẩn hóa, OLTP vs OLAP. Hiểu Amazon RDS như một dịch vụ quản lý cơ sở dữ liệu quan hệ trên AWS: engines, Multi-AZ, read replicas, backup, và scaling. Tìm hiểu lợi ích của Amazon Aurora so với các engine RDS tiêu chuẩn: hiệu năng, tính sẵn sàng cao, tự động mở rộng storage, tương thích MySQL/PostgreSQL. Làm quen với Amazon Redshift như một data warehouse quy mô petabyte cho phân tích, và phân biệt nó với RDS (OLTP workloads). Học cách Amazon ElastiCache (Redis / Memcached) cung cấp lớp cache trong bộ nhớ để giảm độ trễ và giảm tải cho cơ sở dữ liệu backend. Thực hành Database Schema Conversion \u0026amp; Migration sử dụng AWS DMS và AWS Schema Conversion Tool (SCT) để di chuyển cơ sở dữ liệu lên AWS. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Ôn tập Database Concepts (Module 06-01): mô hình quan hệ, ACID, transactions, indexing, normalization, OLTP vs OLAP. - Ánh xạ khái niệm cơ sở dữ liệu on-premises truyền thống sang dịch vụ đám mây AWS. 13/10/2025 13/10/2025 Tài liệu lớp học – Module 06-01 3 - Học lý thuyết về Amazon RDS \u0026amp; Amazon Aurora (Module 06-02). - Tìm hiểu về các engines được hỗ trợ, Multi-AZ, automated backups, snapshots, read replicas, và scaling. - So sánh RDS vs Aurora về hiệu năng, tính sẵn sàng, và chi phí. 14/10/2025 14/10/2025 https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html, https://aws.amazon.com/rds/aurora/ 4 - Học về Amazon Redshift \u0026amp; Amazon ElastiCache (Module 06-03). - Phân biệt OLTP (RDS/Aurora) vs OLAP (Redshift) và lớp cache trong bộ nhớ (ElastiCache). - Khám phá các use case phổ biến: data warehouse \u0026amp; BI, caching sessions, leaderboard, rate limiting, v.v. 15/10/2025 15/10/2025 https://aws.amazon.com/redshift/, https://aws.amazon.com/elasticache/ 5 - Thực hành Lab: Module 06-Lab 5 – Amazon Relational Database Service (Amazon RDS). + Tạo RDS instance, cấu hình security group, parameter group, backups. + Kết nối từ client, chạy queries, và kiểm tra behavior (ví dụ: failover/Multi-AZ nếu có trong lab). 16/10/2025 16/10/2025 https://000005.awsstudygroup.com/ 6 - Thực hành Lab: Module 06-Lab 43 – Database Schema Conversion \u0026amp; Migration. + Sử dụng AWS Schema Conversion Tool (SCT) để phân tích và chuyển đổi schema từ source DB sang target RDS/Aurora/Redshift. + Sử dụng AWS Database Migration Service (DMS) để di chuyển dữ liệu (full load và change data capture nếu được hỗ trợ trong lab). - Tóm tắt và ôn tập tất cả AWS Database Services đã học trong tuần 6. 17/10/2025 17/10/2025 https://000043.awsstudygroup.com/ Kết quả đạt được trong tuần 6: Củng cố hiểu biết về các khái niệm cơ sở dữ liệu cốt lõi:\nBảng quan hệ, khóa chính/khóa ngoại, tính toàn vẹn quan hệ, và indexing cơ bản. Các thuộc tính ACID của transactions và tại sao chúng quan trọng trong OLTP workloads. Phân biệt rõ ràng giữa OLTP vs OLAP và cách ánh xạ này sang các dịch vụ AWS. Làm quen thực tế với Amazon RDS:\nTạo và quản lý RDS instances qua AWS Management Console. Xem xét các engines được hỗ trợ (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, Aurora) và các use case điển hình của chúng. Thực hành cấu hình Multi-AZ, automated backups, snapshots, monitoring, và các tùy chọn scaling cơ bản. Hiểu điểm mạnh của Amazon Aurora:\nAurora như một cơ sở dữ liệu cloud-native, tương thích MySQL/PostgreSQL với hiệu năng cải thiện đáng kể so với các engine tiêu chuẩn. Kiến trúc Aurora DB cluster, với lớp storage phân tán trên nhiều AZs. Reader và writer endpoints, tự động mở rộng storage, và thiết kế tính sẵn sàng cao. Xây dựng bức tranh tổng thể về Amazon Redshift \u0026amp; ElastiCache:\nRedshift như một data warehouse cột, quy mô petabyte được tối ưu cho analytics và BI workloads. Cách Redshift khác với RDS/Aurora: được tối ưu cho các truy vấn phức tạp trên dataset lớn thay vì transactional workloads. ElastiCache (Redis/Memcached) như một lớp cache trong bộ nhớ được quản lý đầy đủ, độ trễ thấp để tăng throughput và giảm tải cho cơ sở dữ liệu backend. Hoàn thành các lab chính của tuần:\nModule 06-Lab 5 – Amazon RDS: Triển khai RDS instance, kết nối từ client, thực thi các SQL queries cơ bản. Quan sát tác động của các thay đổi cấu hình (instance class, storage, backup settings) lên behavior và quản lý. Module 06-Lab 43 – Database Schema Conversion \u0026amp; Migration: Sử dụng AWS Schema Conversion Tool (SCT) để đánh giá và chuyển đổi schemas, xác định những gì có thể tự động chuyển đổi vs những gì cần điều chỉnh thủ công. Sử dụng AWS Database Migration Service (DMS) để di chuyển dữ liệu từ source database sang các target RDS/Aurora/Redshift theo kịch bản lab. Sau tuần 6, thiết lập mô hình tinh thần rõ ràng về hệ sinh thái cơ sở dữ liệu AWS:\nTừ các khái niệm cơ sở dữ liệu truyền thống → RDS/Aurora cho OLTP → Redshift cho OLAP → ElastiCache cho caching → DMS/SCT cho migration, sẵn sàng áp dụng trong các kiến trúc thực tế. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Trong tuần này, mục tiêu chính của tôi là nắm vững các khái niệm và dịch vụ bảo mật trong AWS, bao gồm các mô hình chia sẻ trách nhiệm, quản lý truy cập, mã hóa và bảo mật tài nguyên. Tôi cũng đã làm quen với các công cụ và dịch vụ của AWS, từ đó có thể áp dụng vào các bài thực hành cụ thể.\nCác mục tiêu cụ thể bao gồm:\nHiểu mô hình Share Responsibility của AWS. Nắm vững các dịch vụ bảo mật chủ chốt của AWS: IAM, Cognito, Security Hub, KMS, Identity Center. Cải thiện kỹ năng quản lý tài nguyên và bảo mật qua IAM Permissions Boundary, Resource Tags, và các kỹ thuật mã hóa. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu lý thuyết về Share Responsibility Model và các nguyên lý bảo mật của AWS. - Đọc tài liệu về các dịch vụ bảo mật của AWS: + Amazon IAM + Amazon Cognito + AWS Identity Center + AWS KMS + AWS Security Hub 04/10/2025 04/10/2025 AWS Study Group 3 - Thực hành: + Cấu hình và sử dụng AWS Security Hub để theo dõi và phát hiện các vấn đề bảo mật. + Tạo và quản lý IAM Users, Roles và Policies cho các tài khoản trong AWS. + Tạo IAM Groups và quản lý quyền truy cập cho các nhóm người dùng. 05/10/2025 05/10/2025 AWS Study Group 4 - Thực hành: + Tối ưu hóa chi phí EC2 với Lambda để tự động hóa các thao tác dừng hoặc khởi động EC2 instances. + Quản lý quyền truy cập EC2 qua Resource Tags thông qua IAM. + Cấu hình IAM Permission Boundaries để giới hạn quyền người dùng. + Mã hóa dữ liệu sử dụng AWS KMS. 06/10/2025 06/10/2025 AWS Study Group 5 - Thực hành nâng cao: + Tìm hiểu và áp dụng các phương pháp bảo mật trong AWS Organizations để quản lý nhiều tài khoản AWS. + Nâng cao khả năng sử dụng AWS Identity Center để quản lý và đồng bộ người dùng và nhóm trên nhiều dịch vụ AWS. 07/10/2025 07/10/2025 AWS Study Group Kết quả đạt được tuần 5: Tuần này, tôi đã đạt được những kết quả quan trọng trong việc nắm bắt các dịch vụ bảo mật của AWS và áp dụng lý thuyết vào thực tế. Cụ thể:\nHiểu và áp dụng mô hình Share Responsibility của AWS:\nTôi đã nắm rõ mô hình này, trong đó AWS chịu trách nhiệm bảo mật hạ tầng và nền tảng, còn người dùng chịu trách nhiệm bảo mật dữ liệu và ứng dụng của mình. Điều này giúp tôi hiểu rõ vai trò của mình khi triển khai các dịch vụ trên AWS. Lý thuyết về các dịch vụ bảo mật chủ chốt của AWS:\nAmazon IAM: Học cách tạo và quản lý IAM Users, Roles, và Policies, giúp tôi kiểm soát quyền truy cập cho người dùng và nhóm. Amazon Cognito: Tìm hiểu cách quản lý người dùng và xác thực trong các ứng dụng của AWS. AWS Identity Center: Khám phá cách kết nối người dùng với các dịch vụ AWS qua Identity Center. AWS Security Hub: Cấu hình và sử dụng để giám sát bảo mật và phát hiện các mối đe dọa. AWS KMS: Thực hành mã hóa dữ liệu khi lưu trữ (at rest) và bảo vệ dữ liệu quan trọng với các khóa mã hóa. Thực hành và áp dụng các dịch vụ AWS bảo mật:\nĐã hoàn thành việc cài đặt và cấu hình AWS Security Hub để giám sát các vấn đề bảo mật, giúp phát hiện sớm các lỗ hổng bảo mật. IAM Permissions Boundary: Cấu hình để hạn chế quyền của người dùng, đảm bảo quyền truy cập chỉ được cấp trong phạm vi cần thiết. Optimizing EC2 Costs with Lambda: Tối ưu hóa chi phí EC2 bằng cách sử dụng Lambda để tự động tắt các instances không sử dụng, giảm chi phí cho tổ chức. Quản lý quyền truy cập EC2 với IAM và Resource Tags: Thiết lập các IAM Policies để kiểm soát quyền truy cập vào các tài nguyên EC2 thông qua việc gắn Tags. Nâng cao kỹ năng quản lý tài nguyên AWS:\nTạo và quản lý IAM Groups, Policies, giúp tôi quản lý quyền truy cập của các nhóm người dùng một cách hiệu quả. Học cách sử dụng AWS Organizations để quản lý nhiều tài khoản và đảm bảo rằng các chính sách bảo mật được áp dụng một cách nhất quán trong toàn bộ tổ chức. LAB PRACTICE Mục lục Lab 18 Lab 22 VPC EC2 Slack Lambda + EventBridge Kết quả kiểm thử (Test Result) Lab 27 Lab 28 Vùng (Regions) \u0026amp; EC2 Thẻ (Tags) Lab 30 Lab 33 Lab 18 Hình minh họa:\nLab 22 VPC Hình minh họa cấu hình VPC:\nEC2 Hình minh họa cấu hình EC2:\nSlack Lưu ý (UI mới): Cần chọn lại kênh (channel) trong phần cấu hình để lấy đúng Webhook URL.\nLambda + EventBridge Hình minh họa cấu hình Lambda và EventBridge:\nKết quả kiểm thử (Test Result) Lab 27 Hình minh họa:\nLab 28 Hình minh họa:\nVùng (Regions) \u0026amp; EC2 EC2 tại ap-northeast-1 (Tokyo)\nEC2 tại us-east-1 (North Virginia)\nThẻ (Tags) Các cặp key/value mẫu được sử dụng:\nKey Value Name Example Team Beta Team Alpha Team TEST Minh họa trên giao diện:\nName = Example, Team = Beta\nName = Example, Team = Alpha\nTeam = TEST\nLab 30 Policies : IAM : Check Permission : Lab 33 Policies Role User KMS S3 CloudTrail Athena TEST sau khi make ACLs Kết luận: Trong tuần 5, tôi đã nâng cao khả năng sử dụng các công cụ bảo mật và quản lý truy cập của AWS. Những kiến thức và kỹ năng này là cơ sở quan trọng để tiếp tục triển khai các giải pháp bảo mật và tối ưu hóa chi phí trong các dự án AWS sắp tới. Các bài thực hành giúp tôi củng cố lý thuyết và nâng cao khả năng sử dụng AWS trong môi trường thực tế.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4 Hiểu sâu về dịch vụ lưu trữ cốt lõi của AWS là Amazon S3. Nắm vững các khái niệm: bucket, object, storage class, access point, static website hosting, và CORS. Tìm hiểu các giải pháp lưu trữ lai (hybrid storage) và di chuyển dữ liệu như AWS Storage Gateway và AWS Snow Family. Làm quen với Amazon FSx for Windows File Server và dịch vụ sao lưu tự động AWS Backup. Thực hành triển khai, quản lý và kết nối các dịch vụ lưu trữ AWS trong môi trường thực tế. Công việc cần thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Nghiên cứu lý thuyết Dịch vụ Lưu trữ trên AWS (S3) – Module 04-01.\n- Làm quen với khái niệm Bucket, Object và cơ chế lưu trữ. 29/09/2025 29/09/2025 https://docs.aws.amazon.com/s3/ 3 - Học về Access Point và Storage Class trong S3 – Module 04-02.\n- Phân biệt các loại storage class: Standard, IA, Glacier, Deep Archive. 30/09/2025 30/09/2025 https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html 4 - Tìm hiểu S3 Static Website \u0026amp; CORS, quyền truy cập (Access Control), Object Key, Performance, Glacier – Module 04-03. 01/10/2025 01/10/2025 https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html 5 - Thực hành: Module 04-Lab13 – Deploy AWS Backup to the System.\n- Thực hành: Module 04-Lab14 – VM Import/Export. 02/10/2025 02/10/2025 Lab13, Lab14 6 - Thực hành: Module 04-Lab24 – Using File Storage Gateway.\n- Thực hành: Module 04-Lab25 – Amazon FSx for Windows File Server.\n- Ôn tập và tổng hợp toàn bộ nội dung về dịch vụ lưu trữ AWS. 03/10/2025 03/10/2025 Lab24, Lab25 Kết quả đạt được trong Tuần 4 Hiểu rõ kiến trúc và nguyên lý hoạt động của Amazon S3, bao gồm:\nCách tạo và quản lý Bucket, Object, và chính sách truy cập (Access Policy). Các Storage Classes khác nhau và chiến lược tối ưu chi phí lưu trữ. Cấu hình S3 Static Website Hosting và xử lý CORS cho ứng dụng web. Làm quen với S3 Glacier – dịch vụ lưu trữ lạnh, tiết kiệm chi phí cho dữ liệu ít truy cập.\nNắm vững khái niệm Hybrid Storage \u0026amp; Data Migration thông qua:\nAWS Snow Family (Snowcone, Snowball, Snowmobile). AWS Storage Gateway – giải pháp kết nối giữa hệ thống on-premises và đám mây AWS. Thực hành thành công các lab sau:\nLab 13 – AWS Backup Mục tiêu: Cấu hình và triển khai sao lưu tài nguyên với AWS Backup. Step 1:\nStep 2:\nStep 3:\nStep 4:\nSuccess:\nLab 14 – VM Import/Export Mục tiêu: Thực hiện VM Import/Export – chuyển đổi máy ảo giữa môi trường cục bộ và AWS. Step 1:\nSuccess:\nStep 2:\nStep 3:\nStep 4:\nStep 5:\nStep 6 (thành công tải máy ảo lên EC2 (AMIs)):\nStep 7:\nStep 8 (Test Internet):\nStep 9:\nStep 10 (Done):\nLab 24 – File Storage Gateway Mục tiêu: Cấu hình File Storage Gateway – tạo và liên kết lưu trữ file giữa on-premises và AWS. Lưu ý: Phải nâng cấp tài khoản.\nStep 1 – Sau khi tạo S3 thì vào tạo File Storage Gateway (FSG):\nStep 2 – EC2 setting:\nStep 3:\nLab 25 – Amazon FSx for Windows File Server Mục tiêu: Triển khai hệ thống lưu trữ file cho Windows với Amazon FSx for Windows File Server. Step 1 (lỗi Lambda – Node.js version):\nStep 2:\nHoàn thành toàn bộ Module 04 – AWS Storage Services, tạo nền tảng vững chắc để chuyển sang các dịch vụ tính toán, cơ sở dữ liệu và bảo mật trong các tuần tiếp theo. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu rõ về Amazon EC2 và các thành phần liên quan (AMI, Backup, Key Pair, EBS, Instance Store, User Data, Metadata). Tìm hiểu Auto Scaling của EC2 và vai trò của nó trong việc mở rộng linh hoạt và tối ưu chi phí. Khám phá các dịch vụ tính toán liên quan: EFS, FSx, Lightsail, và AWS MGN. Củng cố kiến thức lưu trữ AWS qua các bài lab thực hành với S3, AWS Backup, và Storage Gateway. Phát triển kỹ năng thực tế trong việc cấu hình, quản lý và mở rộng workload trên EC2. Công việc trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Lý thuyết: + Tổng quan EC2: AMI, Backup, Key Pair 22/09/2025 22/09/2025 AWS EC2 Documentation 2 - Lý thuyết: + EBS (Elastic Block Store) + Instance Store 23/09/2025 23/09/2025 AWS EBS Documentation 3 - Lý thuyết: + EC2 User Data + EC2 Metadata 24/09/2025 24/09/2025 AWS EC2 User Guide 4 - Lý thuyết: + EC2 Auto Scaling + Các dịch vụ liên quan: EFS, FSx, Lightsail, MGN 25/09/2025 25/09/2025 AWS Auto Scaling 5 - Thực hành: + Lab 57: Làm quen với Amazon S3 26/09/2025 26/09/2025 AWS Study Group - Lab57 6 - Thực hành: + Lab 13: Triển khai AWS Backup để bảo vệ workload 27/09/2025 27/09/2025 AWS Study Group - Lab13 7 - Thực hành: + Lab 24: Sử dụng AWS Storage Gateway tích hợp với hệ thống on-premises 28/09/2025 28/09/2025 AWS Study Group - Lab24 Kết quả đạt được Tuần 3: Kiến thức lý thuyết vững chắc về Amazon EC2, bao gồm:\nAMI và chiến lược backup để tăng độ tin cậy. Cách dùng Key Pair cho xác thực SSH an toàn. Sự khác biệt giữa EBS (lưu trữ bền vững) và Instance Store (lưu trữ tạm thời). Vai trò của EC2 User Data (chạy script tự động khi khởi tạo instance) và EC2 Metadata (cung cấp thông tin động về instance). Cách EC2 Auto Scaling giúp duy trì hiệu năng và tối ưu chi phí. Mở rộng hiểu biết về các dịch vụ liên quan:\nAmazon EFS và FSx cho lưu trữ chia sẻ và hiệu năng cao. Amazon Lightsail như một giải pháp đơn giản cho workload nhỏ. AWS MGN để di chuyển workload từ on-premises lên AWS. Hoàn thành các bài lab thực hành:\nTạo và quản lý bucket S3 (Lab57). Triển khai AWS Backup để bảo vệ workload (Lab13). Tích hợp hệ thống on-premises với AWS bằng Storage Gateway (Lab24). Kỹ năng then chốt đã đạt được:\nPhân biệt các loại lưu trữ (EBS, Instance Store, EFS, FSx). Tự động hóa vòng đời EC2 bằng User Data và Auto Scaling. Kết hợp giải pháp backup và hybrid storage để xây dựng kiến trúc có độ tin cậy cao. Định hướng:\nTuần này đào sâu về nền tảng compute và storage. Việc kết hợp lý thuyết với bài tập thực hành giúp tăng khả năng không chỉ triển khai và quản lý EC2 mà còn thiết kế kiến trúc linh hoạt, tin cậy và tối ưu chi phí, tích hợp với các dịch vụ lưu trữ và di trú của AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Làm quen, kết nối với các thành viên trong First Cloud Journey. Hiểu các dịch vụ AWS cơ bản, cách thao tác qua Console \u0026amp; CLI. Các công việc triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Gặp gỡ và làm quen thành viên FCJ.\n- Đọc và ghi nhớ các nội quy, quy định tại đơn vị thực tập. 02/09/2025 02/09/2025 3 - Tìm hiểu AWS và các nhóm dịch vụ chính:\n+ Compute + Storage + Networking + Database + \u0026hellip; 03/09/2025 03/09/2025 https://000001.awsstudygroup.com/vi/ 4 - Đăng ký AWS Free Tier account.\n- Làm quen AWS Console \u0026amp; AWS CLI.\n- Thực hành:\n+ Tạo AWS account + Cài đặt \u0026amp; cấu hình AWS CLI + Thao tác cơ bản với CLI 04/09/2025 04/09/2025 https://000001.awsstudygroup.com/vi/ 5 - Cấu hình bảo mật cơ bản:\n+ Setup Virtual MFA Device + Tạo nhóm admin \u0026amp; user admin + Account authentication support + Tạo Budget từ template 05/09/2025 06/09/2025 https://000007.awsstudygroup.com/vi/ 6 - Thực hành quản lý chi phí:\n+ Tạo Cost Budget + Tạo Usage Budget + Reservation Instance (RI) + Savings Plans Budget 06/09/2025 06/09/2025 https://000007.awsstudygroup.com/vi/ 7 - Gửi yêu cầu và quản lý AWS support.\n- Viết worklog \u0026amp; tự đánh giá mức độ hiểu AWS cơ bản.\n- Chuẩn bị cho mục tiêu tuần 2. 07/09/2025 07/09/2025 https://000009.awsstudygroup.com/vi/ Kết quả đạt được tuần 1: Hoàn thành bước khởi động tại đơn vị thực tập:\nLàm quen với các thành viên trong nhóm FCJ. Nắm rõ nội quy, quy định cơ bản. Kiến thức nền tảng AWS:\nHiểu AWS là gì, nắm được các nhóm dịch vụ cơ bản: Compute Storage Networking Database \u0026hellip; Thực hành tạo \u0026amp; cấu hình tài khoản:\nĐăng ký thành công AWS Free Tier account. Thiết lập bảo mật cơ bản: bật MFA, tạo nhóm admin và user admin. Thiết lập ngân sách (Budget) để theo dõi chi phí: Cost Budget, Usage Budget, RI, Savings Plans. Làm quen công cụ quản lý:\nTrải nghiệm AWS Management Console: tìm kiếm, truy cập, và thao tác với dịch vụ qua giao diện web. Cài đặt và cấu hình AWS CLI trên máy tính cá nhân với: Access Key, Secret Key, Region mặc định. Thao tác với AWS CLI:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình. Lấy danh sách region. Xem thông tin dịch vụ EC2. Tạo và quản lý key pair. Kiểm tra dịch vụ đang chạy. Kết nối song song GUI \u0026amp; CLI:\nQuản lý tài nguyên AWS đồng thời qua Console và CLI. So sánh cách thao tác, rút kinh nghiệm cho việc chọn công cụ phù hợp với từng tình huống. Tổng kết cá nhân:\nHoàn tất ôn tập, viết worklog tuần 1 (nộp chậm sang tuần sau). Đánh giá mức độ hiểu biết và xác định mục tiêu cho tuần tiếp theo. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Võ Trường Thành Phát\nSố điện thoại: 0707712750\nEmail: phatvttse171823@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Thực nghiệm ML nhanh cho doanh nghiệp với Amazon SageMaker AI và Comet Bởi: Vikesh Pandey, Naufal Mir và Sarah Ostermeier \u0026ndash; Ngày: 22/9/2025\nChủ đề: Amazon SageMaker AI, SageMaker Unified Studio, Partner solutions ,Sarah Ostermeier\nTrong quá trình mở rộng hoạt động machine learning (ML) của doanh nghiệp từ giai đoạn proof-of-concept sang sản xuất, việc quản lý các thực nghiệm, theo dõi dòng kế thừa mô hình (model lineage), và đảm bảo tái tạo kết quả (reproducibility) trở nên phức tạp hơn rất nhiều. Nguyên nhân chính là các nhà khoa học dữ liệu và kỹ sư ML thường thử nghiệm nhiều phép kết hợp hyperparameter, kiến trúc mô hình và phiên bản dataset, sinh ra một lượng metadata lớn cần được theo dõi để đảm bảo khả năng tái tạo và tuân thủ quy định. Khi quy mô mô hình ML lan rộng qua nhiều đội, yêu cầu về quy định (regulation) gia tăng, việc theo dõi thực nghiệm trở thành điều bắt buộc chứ không chỉ là \u0026ldquo;best practice\u0026rdquo;.\nAmazon SageMaker AI cung cấp cơ sở hạ tầng được quản lý để doanh nghiệp mở rộng workloads ML, xử lý việc cấp phát computer , huấn luyện phân tán, deployment mà không cần lo hạ tầng. Tuy nhiên, các đội vẫn cần một hệ thống theo dõi thực nghiệm mạnh mẽ, khả năng so sánh mô hình và hợp tác vượt lên những logging cơ bản.\nComet là một nền tảng quản lý thực nghiệm ML (ML experiment management) toàn diện, tự động theo dõi, so sánh và tối ưu các thực nghiệm ML suốt vòng đời mô hình. Nó cung cấp cho các nhà khoa học dữ liệu và kỹ sư ML các công cụ mạnh về tracking, monitoring mô hình, tối ưu hyperparameter và phát triển mô hình hợp tác. Nó cũng có Opik \u0026mdash; nền tảng mã nguồn mở của Comet cho quan sát và phát triển LLM (large language model).\nComet có sẵn trong SageMaker AI như một Partner AI App, như một khả năng được quản lý đầy đủ cho thực nghiệm, với bảo mật cấp doanh nghiệp, tích hợp mượt vào workflow, và quy trình mua đơn giản qua AWS Marketplace.\nSự kết hợp này đáp ứng nhu cầu của quy trình ML doanh nghiệp end-to-end: SageMaker AI xử lý hạ tầng và compute, Comet cung cấp khả năng quản lý thực nghiệm, đăng ký mô hình (model registry) và giám sát sản xuất mà các đội cần cho tuân thủ quy định và hiệu quả vận hành. Trong bài viết này, chúng tôi minh hoạ một workflow phát hiện gian lận (fraud detection) hoàn chỉnh dùng SageMaker AI + Comet, minh chứng khả năng tái tạo và logging sẵn sàng audit mà doanh nghiệp ngày nay cần.\nComet \u0026ldquo;Enterprise-ready\u0026rdquo; trên SageMaker AI Trước khi đi vào hướng dẫn triển khai, các tổ chức cần xác định mô hình vận hành (operating model) và từ đó quyết định cách triển khai Comet. AWS khuyến nghị thiết lập Comet theo mô hình liên bang (federated operating model): Comet được quản lý trung tâm trong tài khoản shared services, và mỗi đội dữ liệu ML có môi trường tự chủ riêng. Mỗi mô hình vận hành có lợi \u0026mdash; hại riêng. (Tham khảo SageMaker Studio Administration Best Practices để biết chi tiết).\nTrong kiến trúc này, thường có hai vai:\nAdministrator \u0026ndash; người chịu trách nhiệm thiết lập hạ tầng chung và môi trường cho các đội use-case\nUser (Người dùng) \u0026ndash; nhà thực nghiệm ML từ các đội use-case, sử dụng môi trường đã thiết lập để giải quyết bài toán doanh nghiệp\nComet hoạt động tốt với cả SageMaker AI và Amazon SageMaker (SageMaker AI dùng môi trường tích hợp trong SageMaker Studio IDE; SageMaker dùng Unified Studio IDE). Ở đây, chúng ta dùng SageMaker Studio trong ví dụ.\nHành trình của Administrator Khi một đội muốn triển khai use-case phát hiện gian lận, admin thực hiện:\nThực hiện các bước prerequisite để thiết lập Partner AI Apps \u0026mdash; cấp phép để Comet có thể giả danh role SageMaker AI của người dùng và quản lý đăng ký Comet qua AWS Marketplace.\nTrong console SageMaker AI, vào phần Applications and IDEs → Partner AI Apps → Comet để xem chi tiết.\nHiển thị chi tiết hợp đồng, mô hình pricing, ước tính chi phí hạ tầng Comet. Chọn Go to Marketplace để đăng ký Comet từ AWS Marketplace.\nChọn \u0026ldquo;View purchase options\u0026rdquo; và điền thông tin đăng ký.\nSau khi đăng ký xong, admin bắt đầu cấu hình Comet.\nKhi deploy Comet, thêm project lead của đội phát hiện gian lận làm admin quản lý dashboard Comet. Quá trình deploy Comet mất vài phút. (Tham khảo hướng dẫn Partner AI App provisioning để biết chi tiết).\nThiết lập domain SageMaker AI theo hướng dẫn *Use custom setup for Amazon SageMaker AI *. Theo best practice, cung cấp URL domain có pre-signed để đội use-case truy cập Comet UI mà không cần đăng nhập console SageMaker.\nThêm thành viên đội vào domain và bật quyền truy cập Comet khi cấu hình domain.\nSau các bước này, domain SageMaker AI đã sẵn sàng để user đăng nhập và bắt đầu làm việc.\nHành trình của User (nhà ML) Khi môi trường đã sẵn sàng, user thực hiện:\nĐăng nhập domain SageMaker AI qua URL đã được pre-signed.\nTự động chuyển tới IDE SageMaker Studio, user name và IAM execution role đã được admin cấu hình sẵn. Tạo một JupyterLab Space theo hướng dẫn JupyterLab user guide.\nBắt đầu làm use-case phát hiện gian lận bằng cách khởi chạy notebook.\nAdmin đã cấp quyền truy cập dữ liệu qua bucket S3 cần thiết. Để dùng API của Comet, cài gói comet_ml và cấu hình biến môi trường (environment variables) theo hướng dẫn Set up Partner AI Apps SDKs.\nTrong SageMaker Studio, chọn Partner AI Apps → Open Comet để truy cập giao diện Comet UI.\nBắt đầu workflow thực nghiệm. Tổng quan giải pháp (Solution overview) Use-case này nhấn mạnh các thách thức thường gặp trong doanh nghiệp:\nDataset mất cân bằng (ví dụ ở đây chỉ ~0,17% giao dịch là gian lận)\nNhiều vòng thực nghiệm (iterations)\nYêu cầu tái tạo hoàn chỉnh (reproducibility) và tuân thủ audit\nDòng kế thừa dữ liệu \u0026amp; mô hình (lineage) cần được ghi lại chi tiết\nSử dụng dataset Credit Card Fraud Detection, với nhãn nhị phân \u0026mdash; 1 là gian lận, 0 là hợp lệ. Các bước sau đây minh họa các phần quan trọng của triển khai (toàn bộ mã có trong repo GitHub của Comet).\nPrerequisites (Cài đặt trước) Cấu hình các import và biến môi trường Comet + SageMaker:\n# Comet ML for experiment tracking\nimport comet_ml\nfrom comet_ml import Experiment, API, Artifact\nfrom comet_ml.integration.sagemaker import log_sagemaker_training_job_v1\nAWS_PARTNER_APP_AUTH = True\nAWS_PARTNER_APP_ARN = \u0026lt;Your_AWS_PARTNER_APP_ARN\u0026gt;\nCOMET_API_KEY = \u0026lt;Your_Comet_API_Key\u0026gt;\nCOMET_WORKSPACE = '\u0026lt;your-comet-workspace-name\u0026gt;'\nCOMET_PROJECT_NAME = '\u0026lt;your-comet-project-name\u0026gt;'\nBiến AWS_PARTNER_APP_ARN và COMET_API_KEY lấy từ trang chi tiết Comet trong SageMaker.\nCOMET_WORKSPACE và COMET_PROJECT_NAME là tên workspace và project bạn sẽ dùng để nhóm các thực nghiệm.\nChuẩn bị dataset Một tính năng quan trọng của Comet là versioning dataset tự động \u0026amp; theo dõi lineage. Điều này cho phép audit đầy đủ dữ liệu nào được dùng để huấn luyện mỗi mô hình \u0026mdash; rất quan trọng trong các môi trường quy định (regulation).\nVí dụ:\n# Tạo Artifact dataset để theo dõi dataset gốc\ndataset_artifact = Artifact(\nname=\u0026quot;fraud-dataset\u0026quot;,\nartifact_type=\u0026quot;dataset\u0026quot;,\naliases=[\u0026quot;raw\u0026quot;]\n)\ndataset_artifact.add_remote(s3_data_path, metadata={\n\u0026quot;dataset_stage\u0026quot;: \u0026quot;raw\u0026quot;,\n\u0026quot;dataset_split\u0026quot;: \u0026quot;not_split\u0026quot;,\n\u0026quot;preprocessing\u0026quot;: \u0026quot;none\u0026quot;\n})\nArtifact cho phép đánh dấu file dataset và metadata kèm theo\nDữ liệu gốc được thêm vào artifact để Comet theo dõi nguồn dataset\nBắt đầu một experiment Comet Sau khi artifact đã được log, bạn bắt đầu một experiment và Comet sẽ tự động ghi lại metadata nền, environment, thư viện, code, v.v.\nexperiment_1 = comet_ml.Experiment(\nproject_name=COMET_PROJECT_NAME,\nworkspace=COMET_WORKSPACE,\n)\nexperiment_1.log_artifact(dataset_artifact)\nExperiment tự động bắt đầu ghi thông tin\nlog_artifact để ghi dataset artifact vào experiment cho truy vết\nTiền xử lý dữ liệu (Preprocess) Các bước tiền xử lý bao gồm:\nLoại bỏ bản ghi trùng\nBỏ các cột không cần thiết\nChia dữ liệu thành các tập train/validation/test\nChuẩn hoá các đặc trưng (standardization) dùng StandardScaler của scikit-learn\nMã tiền xử lý được viết trong file preprocess.py và chạy như SageMaker Processing Job:\nprocessor = SKLearnProcessor(\nframework_version='1.0-1',\nrole=sagemaker.get_execution_role(),\ninstance_count=1,\ninstance_type='ml.t3.medium'\n)\nprocessor.run(\ncode='preprocess.py',\ninputs=[ProcessingInput(source=s3_data_path, destination='/opt/ml/processing/input')],\noutputs=[ProcessingOutput(source='/opt/ml/processing/output', destination=f's3://{bucket_name}/{processed_data_prefix}')]\n)\nKhi job bắt đầu, SageMaker AI tạo instance, xử lý dữ liệu, và sau đó giải phóng resource.\nKết quả tiền xử lý được lưu lên S3.\nSau khi hoàn tất, bạn tạo phiên bản mới của artifact dataset để theo dõi dữ liệu đã được xử lý:\npreprocessed_dataset_artifact = Artifact(\nname=\u0026quot;fraud-dataset\u0026quot;,\nartifact_type=\u0026quot;dataset\u0026quot;,\naliases=[\u0026quot;preprocessed\u0026quot;],\nmetadata={\n\u0026quot;description\u0026quot;: \u0026quot;Credit card fraud detection dataset\u0026quot;,\n\u0026quot;fraud_percentage\u0026quot;: f\u0026quot;{fraud_percentage:.3f}%\u0026quot;,\n\u0026quot;dataset_stage\u0026quot;: \u0026quot;preprocessed\u0026quot;,\n\u0026quot;preprocessing\u0026quot;: \u0026quot;StandardScaler + train/val/test split\u0026quot;,\n}\n)\npreprocessed_dataset_artifact.add_remote(\nuri=f's3://{bucket_name}/{processed_data_prefix}',\nlogical_path='split_data'\n)\nexperiment_1.log_artifact(preprocessed_dataset_artifact)\nArtifact cùng tên nhưng alias khác cho phép Comet quản lý versioning\nMetadata bổ sung giúp ghi chú những gì đã làm (split, preprocessing\u0026hellip;)\nWorkflow thực nghiệm Comet + SageMaker AI Để thúc đẩy thực nghiệm nhanh, bạn nên tổ chức workflow thành các hàm tiện ích (utility functions) có thể gọi lại nhiều lần với các hyperparameters khác nhau mà vẫn đảm bảo logging và đánh giá thống nhất.\nCác hàm quan trọng:\ntrain() \u0026mdash; tạo job huấn luyện XGBoost trên SageMaker:\nestimator = Estimator(\nimage_uri=xgboost_image,\nrole=execution_role,\ninstance_count=1,\ninstance_type='ml.m5.large',\noutput_path=model_output_path,\nsagemaker_session=sagemaker_session_obj,\nhyperparameters=hyperparameters_dict,\nmax_run=1800 # thời gian tối đa (giây)\n)\nestimator.fit({\n'train': train_channel,\n'validation': val_channel\n})\nlog_training_job() \u0026mdash; ghi metadata huấn luyện vào Comet và liên kết mô hình: \\log_sagemaker_training_job_v1(\nestimator=training_estimator,\nexperiment=api_experiment\n)\nlog_model_to_comet() \u0026mdash; ghi artifact mô hình lên Comet: experiment.log_remote_model(\nmodel_name=model_name,\nuri=model_artifact_path,\nmetadata=metadata\n)\ndeploy_and_evaluate_model() \u0026mdash; triển khai endpoint và đánh giá,log metrics: predictor = estimator.deploy(initial_instance_count=1, instance_type=\u0026quot;ml.m5.xlarge\u0026quot;)\nexperiment.log_metrics(metrics)\nexperiment.log_confusion_matrix(matrix=cm, labels=['Normal', 'Fraud'])\nfpr, tpr, _ = roc_curve(y_test, y_pred_prob_as_np_array)\nexperiment.log_curve(\u0026quot;roc_curve\u0026quot;, x=fpr, y=tpr)\nToàn bộ mã dự đoán và đánh giá chi tiết có trong repo GitHub. Chạy các thực nghiệm (Run the experiments) Bạn có thể thử nhiều experiment bằng cách gọi hàm tiện ích với các cấu hình hyperparameter khác nhau và so sánh kết quả để chọn cấu hình tối ưu cho use-case.\nVí dụ, experiment đầu tiên (baseline):\nhyperparameters_v1 = {\n'objective': 'binary:logistic',\n'num_round': 100,\n'eval_metric': 'auc',\n'learning_rate': 0.15,\n'booster': 'gbtree'\n}\nestimator_1 = train(\nmodel_output_path=f\u0026quot;s3://{bucket_name}/{model_output_prefix}/1\u0026quot;,\nexecution_role=role,\nsagemaker_session_obj=sagemaker_session,\nhyperparameters_dict=hyperparameters_v1,\ntrain_channel_loc=train_channel_location,\nval_channel_loc=validation_channel_location\n)\nlog_training_job(experiment_key = experiment_1.get_key(), training_estimator=estimator_1)\nlog_model_to_comet(\nexperiment = experiment_1,\nmodel_name=\u0026quot;fraud-detection-xgb-v1\u0026quot;,\nmodel_artifact_path=estimator_1.model_data,\nmetadata=metadata\n)\ndeploy_and_evaluate_model(\nexperiment=experiment_1,\nestimator=estimator_1,\nX_test_scaled=X_test_scaled,\ny_test=y_test\n)\nKhi chạy một Comet experiment từ notebook Jupyter, bạn cần gọi experiment_1.end() để đảm bảo mọi thông tin được ghi lại và lưu trên máy chủ Comet.\nSau khi experiment baseline hoàn thành, bạn có thể khởi chạy experiment kế tiếp với hyperparameter khác và so sánh hai experiment trong giao diện Comet UI.\nXem experiment trong giao diện Comet Để truy cập UI, bạn có thể lấy URL từ SageMaker Studio IDE hoặc in ra từ notebook bằng experiment_2.url.\nẢnh chụp màn hình giao diện Comet cho thấy các experiment được so sánh \u0026mdash; chi tiết này dùng để minh họa, không đại diện cho experiment thực tế.\n(Note: chèn ảnh màn hình UI Comet tại đây)\nClean up (Dọn dẹp tài nguyên) Do tính chất ephemeral của hạ tầng SageMaker (processing, training) \u0026mdash; nó tự shut down sau khi job kết thúc. Nhưng bạn vẫn cần:\nTắt JupyterLab Space khi không dùng (theo hướng dẫn Idle shutdown).\nHủy đăng ký Comet nếu không tiếp tục dùng (tránh phí) \u0026mdash; hợp đồng sẽ tự gia hạn nếu không huỷ.\nLợi ích của tích hợp SageMaker + Comet Streamlined model development Sự kết hợp SageMaker \u0026ndash; Comet giảm bớt gánh nặng thủ công khi chạy experiment. Trong khi SageMaker lo cấp phát hạ tầng, Comet tự động logging hyperparameters, metrics, code, thư viện, thông tin hệ thống \u0026mdash; không cần cấu hình thêm.\nComet hỗ trợ trực quan hóa vượt mức đồ thị metric đơn giản: các biểu đồ tích hợp giúp so sánh experiment nhanh chóng; panels Python tuỳ chỉnh giúp bạn debug hành vi mô hình, tối ưu hyperparameter, hoặc tạo visual riêng khi tool mặc định không đáp ứng.\nHợp tác doanh nghiệp \u0026amp; quản trị Trong môi trường doanh nghiệp, sự kết hợp này tạo ra nền tảng mạnh để mở rộng dự án ML trong môi trường có quy định nghiêm ngặt. SageMaker đảm bảo môi trường ML nhất quán, an toàn; Comet hỗ trợ hợp tác với dòng artifact và lineage hoàn chỉnh. Điều này giúp tránh lỗi khi các đội không thể tái tạo kết quả trước đó.\nTích hợp vòng đời ML hoàn chỉnh Khác với các giải pháp rời rạc chỉ hỗ trợ training hay monitoring, SageMaker + Comet hỗ trợ toàn bộ vòng đời ML.\nMô hình có thể được đăng ký trong model registry của Comet với version, quản lý.\nSageMaker lo deployment.\\rkflow phê duyệt promotion.\nComet giữ lineage và wo\nComet giám sát hiệu suất mô hình, theo dõi drift dữ liệu sau khi deployment \u0026mdash; tạo vòng feedback, nơi thông tin từ production ảnh hưởng đến experiment tiếp theo.\nKết luận Trong bài viết này, chúng tôi đã trình bày cách tích hợp SageMaker và Comet để tạo môi trường ML được quản lý hoàn chỉnh, hỗ trợ khả năng tái tạo và theo dõi experiment. Để bổ sung cho workflow SageMaker, bạn có thể triển khai Comet ngay trong môi trường SageMaker qua AWS Marketplace.\nVề các tác giả "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" Sử dụng workflow Apache Airflow để điều phối xử lý dữ liệu trên Amazon SageMaker Unified Studio của Vinod Jayendra , Kamen Sharlandjiev , Sean Bjurstrom và Suba Palanisamy\n22 THÁNG 9 NĂM 2025\nĐiều phối pipeline machine learning là công việc phức tạp, đặc biệt khi phần xử lý dữ liệu, huấn luyện mô hình và triển khai được thực hiện trên nhiều dịch vụ và công cụ khác nhau. Trong bài viết này, chúng tôi sẽ đi qua ví dụ thực tế “end-to-end” — xây dựng, thử nghiệm và chạy một pipeline ML sử dụng workflow của SageMaker thông qua giao diện SageMaker Unified Studio. Các workflow này được hỗ trợ bởi Amazon Managed Workflows for Apache Airflow (Amazon MWAA).\nMặc dù SageMaker Unified Studio có trình xây dựng trực quan (low-code) để tạo workflow, bài viết này tập trung vào cách làm bằng code: viết và quản lý workflow như các DAG (Directed Acyclic Graph) bằng Python trong Apache Airflow.\nChúng ta sẽ cùng xem ví dụ pipeline gồm các bước: ingest dữ liệu thời tiết và dữ liệu taxi, chuyển đổi \u0026amp; gộp dữ liệu, rồi dùng ML để dự đoán giá cước taxi — toàn bộ được điều phối qua SageMaker Unified Studio workflow.\nTổng quan giải pháp (Solution overview) Giải pháp này minh họa cách dùng workflows trong SageMaker Unified Studio để điều phối pipeline từ dữ liệu đến mô hình ML trong một môi trường tập trung. Pipeline gồm các tác vụ sau:\nIngest \u0026amp; tiền xử lý dữ liệu thời tiết\nSử dụng notebook trong SageMaker Unified Studio để ingest dữ liệu thời tiết giả lập, xử lý các thuộc tính như thời gian, nhiệt độ, lượng mưa, độ ẩm, tốc độ gió.\nIngest, xử lý và hợp nhất dữ liệu taxi\nSử dụng notebook thứ hai để ingest dữ liệu taxi NYC (bao gồm pickup time, drop-off time, khoảng cách, số lượng khách, tiền cước). Sau đó xử lý và join dữ liệu taxi \u0026amp; thời tiết, lưu kết quả lên Amazon S3 để dùng cho bước tiếp theo.\nHuấn luyện và dự đoán mô hình ML\nNotebook thứ ba áp dụng kỹ thuật hồi quy (regression) để xây dựng mô hình dự đoán giá taxi dựa trên dữ liệu gộp. Mô hình sau đó được dùng để dự đoán giá cho các dữ liệu mới.\nQua cách tiếp cận này, ETL (extract, transform, load) và các bước ML được điều phối trong cùng workflow, với khả năng theo dõi đầy đủ quá trình dữ liệu và đảm bảo tính tái tạo (reproducibility) thông qua workflow quản lý trong SageMaker Unified Studio.\nChuẩn bị trước (Prerequisites) Trước khi xây workflow, bạn cần:\nTạo một domain SageMaker Unified Studio — làm theo hướng dẫn của AWS.\n( mục Tạo miền Amazon SageMaker Unified Studio – thiết lập nhanh )\nĐăng nhập domain SageMaker Unified Studio — dùng domain bạn đã tạo.\n( Truy cập Amazon SageMaker Unified Studio )\nTạo một project trong SageMaker Unified Studio — trong phần tạo project, chọn profile “All capabilities” để hỗ trợ đầy đủ công năng workflow.\n( hướng dẫn tạo dự án. )\nThiết lập workflow environment Bạn có thể dùng workflow trong SageMaker Unified Studio để thiết lập và chạy chuỗi tác vụ như notebooks, querybooks, jobs. Workflow được viết bằng code Python (Airflow DAG), sau đó bạn có thể truy cập UI Airflow từ SageMaker để theo dõi.\nCác bước cụ thể:\nTrong project của bạn, vào mục Compute → Workflow environment.\nChọn Create environment để thiết lập môi trường workflow mới.\nTheo mặc định, SageMaker Unified Studio sẽ dùng loại môi trường mw1.micro — phù hợp cho thử nghiệm nhỏ.\nNếu cần, bạn có thể override cấu hình mặc định (ví dụ tăng tài nguyên) khi tạo project hoặc chỉnh trong blueprint deployment settings.\nPhát triển workflow (Develop workflows) Workflow cho phép bạn điều phối notebooks, querybooks, v.v. trong dự án. Bạn có thể viết DAG Python, test và chia sẻ với các thành viên khác.\nVí dụ:\nTải 3 notebook mẫu: Weather Data Ingestion, Taxi Ingest \u0026amp; Join, Prediction về máy bạn.\nTrong SageMaker Unified Studio, vào Build → JupyterLab, upload 3 notebook trên.\nCấu hình space: dừng space hiện tại → đổi loại instance (ví dụ ml.m5.8xlarge) → khởi động lại space.\nVào Build → Orchestration → Workflows, chọn “Create new workflow” → chọn “Create in code editor”.\nTrong editor, tạo file Python mới multinotebook_dag.py trong thư mục src/workflows/dags. Dán đoạn mã DAG ví dụ sau (sửa \u0026lt;REPLACE-OWNER\u0026gt; và các đường dẫn notebook cho phù hợp):\nfrom airflow.decorators import dag\nfrom airflow.utils.dates import days_ago\nfrom workflows.airflow.providers.amazon.aws.operators.sagemaker_workflows import NotebookOperator\nWORKFLOW_SCHEDULE = \u0026lsquo;@daily\u0026rsquo;\nNOTEBOOK_PATHS = [\n\u0026lsquo;\u0026lt;FULL_PATH/Weather_Data_Ingestion.ipynb\u0026gt;\u0026rsquo;,\n\u0026lsquo;\u0026lt;FULL_PATH/Taxi_Weather_Data_Collection.ipynb\u0026gt;\u0026rsquo;,\n\u0026lsquo;\u0026lt;FULL_PATH/Prediction.ipynb\u0026gt;\u0026rsquo;\n]\ndefault_args = {\n\u0026lsquo;owner\u0026rsquo;: \u0026lsquo;\u0026lt;REPLACE-OWNER\u0026gt;\u0026rsquo;,\n}\n@dag(\ndag_id=\u0026lsquo;workflow-multinotebooks\u0026rsquo;,\ndefault_args=default_args,\nschedule_interval=WORKFLOW_SCHEDULE,\nstart_date=days_ago(2),\nis_paused_upon_creation=False,\ntags=[\u0026lsquo;MLPipeline\u0026rsquo;],\ncatchup=False\n)\ndef multi_notebook():\nprevious_task = None\nfor idx, notebook_path in enumerate(NOTEBOOK_PATHS, 1):\ncurrent_task = NotebookOperator(\ntask_id=f\u0026quot;Notebook{idx}task\u0026quot;,\ninput_config={\u0026lsquo;input_path\u0026rsquo;: notebook_path, \u0026lsquo;input_params\u0026rsquo;: {}},\noutput_config={\u0026lsquo;output_formats\u0026rsquo;: [\u0026lsquo;NOTEBOOK\u0026rsquo;]},\nwait_for_completion=True,\npoll_interval=5\n)\nif previous\\_task: previous\\_task \\\u0026gt;\\\u0026gt; current\\_task previous\\_task \\= current\\_task multi_notebook()\nNotebookOperator được dùng để chạy từng notebook, với dependencies để đảm bảo thứ tự thực thi.\nBạn có thể tùy chỉnh WORKFLOW_SCHEDULE (ví dụ @daily, @hourly, hoặc cron expression).\nSau khi workflow environment được tạo và file DAG được sync vào dự án, các thành viên trong dự án có thể xem và chạy workflow chung.\nKiểm thử và giám sát workflow Vào Build → Orchestration → Workflows, bạn sẽ thấy workflow đang chạy theo schedule hoặc được kích hoạt.\nKhi workflow hoàn thành, trạng thái chuyển sang “success”.\nBạn có thể vào từng execution để xem chi tiết, logs từng task.\nTruy cập Airflow UI từ SageMaker để xem DAGs, lịch sử chạy, logs chi tiết.\nKết quả \u0026amp; đầu ra Kết quả của mô hình được ghi ra thư mục kết quả trên Amazon S3. Bạn cần kiểm tra:\nĐộ chính xác dự đoán (prediction accuracy)\nSự nhất quán về quan hệ giữa các biến\nNếu có kết quả bất thường, cần xem lại bước xử lý dữ liệu, pipeline, giả định mô hình.\nDọn dẹp tài nguyên (Clean up) Để tránh phát sinh chi phí không cần thiết, bạn nên xóa các tài nguyên tạo ra:\nDomain SageMaker Unified Studio\nBucket S3 liên quan tới domain\nCác workflow environment, project nếu không dùng nữa\nKết luận Trong bài viết này, chúng tôi đã minh họa cách bạn có thể sử dụng SageMaker Unified Studio để xây dựng workflow ML tích hợp, bao gồm:\nTạo project SageMaker Unified Studio\nDùng multi-compute notebook để xử lý dữ liệu\nXây workflow DAG bằng Python để điều phối toàn bộ pipeline\nChạy, giám sát workflow trong SageMaker Unified Studio\nSageMaker cung cấp bộ công cụ toàn diện để thực thi các bước từ chuẩn bị dữ liệu, huấn luyện mô hình đến deployment. Khi sử dụng qua SageMaker Unified Studio, các công cụ này được hợp nhất trong một môi trường làm việc duy nhất, giúp loại bỏ ma sát giữa các công cụ rời rạc.\nKhi các tổ chức xây dựng các ứng dụng dữ liệu phức tạp, các đội có thể dùng SageMaker + Unified Studio để hợp tác hiệu quả và vận hành AI/ML với độ tin cậy cao. Bạn có thể phát hiện dữ liệu, xây mô hình và điều phối workflow trong một môi trường được quản lý và có kiểm soát.\nVề phần tác giả "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Di chuyển tìm kiếm toàn văn từ SQL Server sang Amazon Aurora PostgreSQL-Compatible Edition hoặc Amazon RDS for PostgreSQL Tác giả: Sivaprasad Appana , Surya Nallu , và Saumitra Das\nNgày đăng: 19 tháng 8, 2024\nTrong thế giới dữ liệu ngày nay, khả năng tìm và truy xuất thông tin từ các tập dữ liệu lớn là rất quan trọng. Mặc dù một số hệ quản trị cơ sở dữ liệu (cả thương mại và mã nguồn mở) nổi trội trong xử lý dữ liệu cấu trúc, PostgreSQL cũng cung cấp các công cụ mạnh mẽ để tìm kiếm dữ liệu không cấu trúc hoặc bán cấu trúc. PostgreSQL có sẵn full-text search (FTS) tích hợp, và còn hỗ trợ các extension như pg_trgm và pg_bigm cho việc tìm kiếm văn bản.\nCác truy vấn truyền thống dùng toán tử LIKE, ILIKE hoặc biểu thức chính quy rất phù hợp để tìm chuỗi chính xác hoặc dữ liệu cấu trúc, nhưng có hạn chế nếu cần tìm trong các vùng văn bản lớn như tài liệu, bài viết hoặc mô tả sản phẩm.\nKhi di chuyển từ một cơ sở dữ liệu thương mại như SQL Server sang PostgreSQL (như Amazon Aurora PostgreSQL-Compatible hoặc Amazon RDS for PostgreSQL), việc di chuyển full-text search đòi hỏi phải sửa đổi các truy vấn và cấu trúc schema, vì cách triển khai FTS giữa hai hệ thống khác nhau. Công cụ AWS Schema Conversion Tool (AWS SCT) không tự động chuyển đổi mã liên quan full-text search.\nSQL Server FTS được thiết kế để tìm từ, cụm từ hay các dạng từ (stemming) trong dữ liệu văn bản không cấu trúc. Nó hỗ trợ tìm nhanh, xếp hạng và lập chỉ mục văn bản, giúp ứng dụng xử lý lượng lớn thông tin dạng văn bản hiệu quả.\nTrong bài viết này, chúng tôi sẽ hướng dẫn cách di chuyển full-text search từ SQL Server sang Amazon Aurora PostgreSQL bằng cách sử dụng các kiểu dữ liệu tsvector và tsquery. Đồng thời, chúng tôi cũng chỉ cách triển khai FTS bằng extension pg_trgm và pg_bigm.\nYêu cầu chuẩn bị (Prerequisites) Trong bài này, chúng tôi sử dụng cơ sở dữ liệu mẫu AdventureWorks2019 để minh họa cách di chuyển FTS từ SQL Server 2019 Standard sang PostgreSQL.\nCác bước chính để thiết lập FTS trong SQL Server:\nKích hoạt full-text search cho database AdventureWorks2019: USE [AdventureWorks2019]\nGO\nEXEC sp_fulltext_database \u0026rsquo;enable\u0026rsquo;\nGO\nTạo một full-text catalog: CREATE FULLTEXT CATALOG DescFTSCatalog;\nGO\nFull-text catalog là thành phần logic để quản lý các chỉ mục full-text, xác định các word breakers và stemmers theo ngôn ngữ.\nĐịnh nghĩa một full-text index cho các cột chứa dữ liệu văn bản mà bạn muốn tìm: CREATE FULLTEXT INDEX\nON\n[AdventureWorks2019].[Production].[ProductDescription]([Description])\nKEY INDEX [PK_ProductDescription_ProductDescriptionID]\nON DescFTSCatalog\nGO\nSử dụng AWS SCT và AWS Database Migration Service (AWS DMS) để chuyển cơ sở dữ liệu AdventureWorks 2019 từ SQL Server sang Amazon Aurora PostgreSQL. Trong bài, chúng tôi chuyển bảng Product Description. PostgreSQL có vài lựa chọn để tìm kiếm trong văn bản: tìm chính xác, pattern matching, biểu thức chính quy và full-text search. Trong phần tiếp theo, chúng tôi hướng dẫn cách sử dụng FTS trong PostgreSQL trên database đã chuyển để đạt kết quả tương tự.\nFull-text search trong PostgreSQL Toán tử LIKE, ILIKE và biểu thức chính quy được dùng trong mệnh đề WHERE cho tìm theo mẫu. Tuy nhiên, LIKE / ILIKE không hỗ trợ xếp hạng và thường bỏ qua các từ như “the”, “is”, v.v. PostgreSQL cung cấp FTS bằng cách sử dụng tsvector và tsquery, cùng các hàm, toán tử và tham số liên quan.\ntsvector: kiểu dữ liệu đại diện cho phiên bản đã xử lý của văn bản (tách từ, loại bỏ stop words, giảm về lexeme), tối ưu cho tìm kiếm text nhanh. Hàm to_tsvector chuyển văn bản sang tsvector.\ntsquery: chứa một hoặc nhiều lexeme dùng để tìm. Lexeme có thể được kết hợp với các toán tử để tạo điều kiện tìm phức tạp. Hàm to_tsquery hoặc plainto_ts query chuyển truy vấn tìm kiếm sang tsquery.\nVí dụ: “He is running in the park” → các từ “he”, “run”, “park” sau khi loại bỏ stop words và stemming.\nCONTAINS predicate với toán tử AND Truy vấn FTS đơn giản trong SQL Server sử dụng thuật ngữ CONTAINS . CONTAINS Thuật ngữ này trong Transact-SQL cung cấp một cách linh hoạt để thực hiện FTS nâng cao trong cơ sở dữ liệu SQL Server. Nó hỗ trợ nhiều điều kiện tìm kiếm, tìm kiếm gần đúng, ký tự đại diện và các tính năng từ điển đồng nghĩa, cho phép bạn tùy chỉnh truy vấn để đáp ứng các yêu cầu cụ thể.\nTrong truy vấn mẫu sau, thuật ngữ CONTAINS kiểm tra các từ “entry” và “level” trong cột Mô tả:\nSELECT ProductDescriptionID,Description\nFROM [AdventureWorks2019].[Production].[ProductDescription]\nWHERE CONTAINS([Description], \u0026rsquo;entry \u0026amp; level\u0026rsquo;);\nChứa vị ngữ với toán tử OR Điều này tương tự như trường hợp sử dụng trước đó sử dụng CONTAINS vị ngữ, ngoại trừ việc kiểm tra được thực hiện bằng OR toán tử. Trong truy vấn mẫu sau, vị ngữ kiểm tra \u0026ldquo;mục nhập\u0026rdquo;, \u0026ldquo;mức\u0026rdquo; hoặc cả hai:\nSELECT ProductDescriptionID,Description\nFROM [AdventureWorks2019].[Production].[ProductDescription]\nWHERE CONTAINS([Description], \u0026rsquo;entry | level\u0026rsquo;);\nBạn có thể viết lại truy vấn trong PostgreSQL bằng cách sử dụng các hàm to_tsvector và to_tsquery như sau và sử dụng giá trị từ điển tìm kiếm văn bản tích hợp mặc định là pg_catalog.simple .\nVị ngữ FREETEXT Thuật FREETEXT ngữ vị ngữ trong Transact-SQL (T-SQL) được sử dụng để thực hiện tìm kiếm toàn văn bản trong cơ sở dữ liệu SQL Server. Không giống như CONTAINS hàm, vốn yêu cầu các điều khoản và điều kiện cụ thể, thuật ngữ này FREETEXT cho phép tìm kiếm linh hoạt hơn và dựa trên ngôn ngữ tự nhiên.\nTrong các truy vấn mẫu sau, FREETEXT hãy kiểm tra các từ “entry” hoặc “level” và dạng của chúng (sử dụng phép loại suy) trong cột Mô tả:\nSELECT ProductDescriptionID, Description\nFROM [AdventureWorks2019].[Production].[Product description]\nWHERE FREETEXT([Description], \u0026rsquo;entry level\u0026rsquo;);\nBạn có thể viết lại truy vấn trong PostgreSQL bằng các hàm to_tsvector and to_tsquery như sau với giá trị cấu hình pg_catalog.english. Cấu hình này sử dụng english_stemand một từ điển đơn giản để chuyển đổi token thành lexeme. Do đó, lexeme đại diện cho một dạng chuẩn hóa của một từ hoặc token có thể được lập chỉ mục và sử dụng cho các thao tác tìm kiếm.\nHàm FREETEXTTABLE với RANK FTS trong SQL Server có thể tạo ra một điểm số (hoặc giá trị thứ hạng) tùy chọn, thể hiện mức độ liên quan của dữ liệu được trả về bởi truy vấn toàn văn. Giá trị thứ hạng này được tính toán trên mỗi hàng và có thể được sử dụng làm tiêu chí sắp xếp để sắp xếp tập kết quả của truy vấn theo mức độ liên quan. Giá trị thứ hạng chỉ hiển thị thứ tự liên quan tương đối của các hàng trong tập kết quả. Giá trị thực tế không quan trọng và thường khác nhau mỗi lần bạn chạy truy vấn. Giá trị thứ hạng không có ý nghĩa gì giữa các truy vấn.\nTrong các truy vấn mẫu sau, FREETEXTTABLE kiểm tra các từ “entry” hoặc “level” và dạng của chúng (sử dụng phép loại suy) trong cột Mô tả và cũng lấy thông tin RANK:\nSELECT FT_TBL.[ProductDescriptionID],FT_TBL.[Description], KEY_TBL.[RANK]\nFROM [AdventureWorks2019].[Production].[ProductDescription] FT_TBL\nINNER JOIN FREETEXTTABLE([AdventureWorks2019].[Production].[ProductDescription], [Description], \u0026rsquo;entry OR level\u0026rsquo;,1033) AS KEY_TBL\nON FT\\_TBL.\\[ProductDescriptionID\\] \\=KEY\\_TBL.\\[KEY\\] ORDER BY KEY_TBL.[RANK] DESC,FT_TBL.[ProductDescriptionID];\nTrong PostgreSQL, ts_rank hàm này được sử dụng để tính toán thứ hạng liên quan của kết quả tìm kiếm dựa trên mức độ khớp của chúng với một truy vấn cụ thể. Thứ hạng được tính toán bằng cách sử dụng một giá trị số biểu thị mức độ khớp của tài liệu với các thuật ngữ tìm kiếm trong truy vấn.\nHàm này ts_headlineđược sử dụng để tạo phiên bản tóm tắt văn bản của tài liệu, làm nổi bật các phần liên quan nhất khớp với truy vấn tìm kiếm cụ thể. Hàm này hữu ích để tạo các đoạn trích hoặc tiêu đề kết quả tìm kiếm, cung cấp ngữ cảnh cho người dùng về lý do tại sao một tài liệu nhất định được áp dụng cho tìm kiếm của họ. Ảnh chụp màn hình sau đây hiển thị kết quả của cột tiêu đề truy vấn PostgreSQL được tạo bằng hàm ts_headline.\n![][image5]\nCác hàm CONTAINSTABLE và FORMSOF với RANK Hàm này FORMSOF trong SQL Server được sử dụng để thực hiện tìm kiếm biến tố . Tìm kiếm biến tố bao gồm việc tìm kiếm các dạng khác nhau của một từ, chẳng hạn như dạng số nhiều, thì động từ hoặc các dạng từ liên quan. Điều này có thể giúp bạn tìm thấy các tài liệu liên quan ngay cả khi chúng chứa các biến thể của thuật ngữ tìm kiếm, do đó cải thiện độ chính xác của tìm kiếm.\nTrong các truy vấn mẫu sau, CONTAINSTABLE kiểm tra từ “gear” và dạng của chúng (sử dụng INFLECTIONAL) trong cột Mô tả và cũng lấy RANK thông tin:\nSELECT FT_TBL.[ProductDescriptionID],FT_TBL.[Description], KEY_TBL.[RANK]\nFROM [AdventureWorks2019].[Production].[ProductDescription] FT_TBL\n**INNER JOIN CONTAINSTABLE(\\[AdventureWorks2019\\].\\[Production\\].\\[ProductDescription\\],** **\\[Description\\], 'FORMSOF(INFLECTIONAL,''gear'')',1033)** AS KEY_TBL\nON FT_TBL.[ProductDescriptionID] = KEY_TBL.[KEY]\nORDER BY KEY_TBL.[RANK] DESC,FT_TBL.[ProductDescriptionID];\nTrong các truy vấn PostgreSQL, các cụm từ trước tiên được chia thành các từ hoặc mã thông báo, và các từ này được chuẩn hóa và phân loại thành các từ gốc (lexeme) bằng cách sử dụng pg_catalog.english cấu hình FTS. Các lexeme này sẽ giống nhau cho các dạng khác nhau (phân loại) của một từ. Do đó, tính năng này sẽ tự động xử lý các tìm kiếm biến tố.\nMáy chủ SQL SELECT FT_TBL.[ProductDescriptionID],FT_TBL.[Description], KEY_TBL.[RANK] FROM [AdventureWorks2019].[Production].[ProductDescription] FT_TBL INNER JOIN CONTAINSTABLE([AdventureWorks2019].[Production].[ProductDescription], [Description], \u0026lsquo;FORMSOF(INFLECTIONAL,\u0026lsquo;\u0026lsquo;gear\u0026rsquo;\u0026rsquo;)\u0026rsquo;,1033) AS KEY_TBL ON FT_TBL.[ProductDescriptionID] = KEY_TBL.[KEY] ORDER BY KEY_TBL.[RANK] DESC,FT_TBL.[ProductDescriptionID]; ![][image6] PostgreSQL **SELECT p.productdescriptionid ,p.description, ts_rank(to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;,p.Description), query) AS rank, ts_headline(\u0026lsquo;pg_catalog.english\u0026rsquo;,p.Description,query) headline FROM production.productdescription p, to_tsquery(\u0026lsquo;pg_catalog.english\u0026rsquo;,\u0026lsquo;gear\u0026rsquo;) query WHERE query @@ to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;,p.Description) ORDER BY rank desc,p.productdescriptionid; Cải thiện hiệu suất truy vấn trong PostgreSQL Đối với các truy vấn PostgreSQL mẫu được hiển thị trước đó, to_tsvector hàm này lấy các tsvector giá trị từ cột Mô tả trong productdescription bảng. Trong các phần sau, chúng tôi sẽ giới thiệu cho bạn các tùy chọn khác nhau để cải thiện hiệu suất truy vấn.\nGiải pháp 1: Sử dụng chỉ mục GIN Chỉ mục GIN (Generalized Inverted Index) trong PostgreSQL là một phương pháp lập chỉ mục phổ biến được sử dụng để tăng tốc hiệu quả việc tìm kiếm các kiểu dữ liệu phức tạp như JSON và tìm kiếm toàn văn bản. Chỉ mục cơ sở dữ liệu chuẩn, một cây B, được thiết kế để kiểm tra tính bằng nhau, trong khi GIN được thiết kế cho các mẫu tìm kiếm hoạt động trên các cấu trúc dữ liệu lồng nhau hoặc tổng hợp, cho phép các mẫu tìm kiếm biểu cảm hơn. Bằng cách lập chỉ mục các thành phần của các kiểu dữ liệu phức tạp riêng biệt, chỉ mục GIN cho phép truy vấn nhanh hơn trên các mảng, dữ liệu JSON và các thao tác tìm kiếm văn bản. Điều này khiến chỉ mục GIN trở thành một công cụ hữu ích để cải thiện hiệu suất của các truy vấn liên quan đến các cấu trúc dữ liệu phức tạp trong cơ sở dữ liệu PostgreSQL.\nTrong cách tiếp cận này, bạn tạo chỉ mục GIN dựa trên biểu thức trên cột quan tâm trong bảng mô tả sản phẩm.\nChạy lệnh sau: CREATE INDEX productdescription_gin_idx ON production.productdescription\nUSING GIN (to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;, Description)); Nếu bảng có hàng triệu hàng, bạn có thể tăng maintenance_work_mem tham số cấu hình ở cấp độ phiên để tăng tốc thời gian tạo chỉ mục. maintenance_work_mem chỉ định lượng bộ nhớ tối đa tính bằng MB sẽ được sử dụng cho các hoạt động bảo trì như tạo INDEX—theo mặc định (PostgreSQL), là 64 MB. Chạy truy vấn EXPLAIN ANALYZE sau: EXPLAIN ANALYZE\nSELECT * FROM production.productdescription\nWHERE to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;, Description) @@ to_tsquery(\u0026lsquo;pg_catalog.english\u0026rsquo;,\u0026rsquo;entry | level\u0026rsquo;)\nORDER BY productdescriptionid DESC; Đầu ra hiển thị quá trình quét chỉ mục bitmap đang được thực hiện trên productdescription_gin_index, giúp cải thiện hiệu suất truy vấn. Ảnh chụp màn hình sau đây cho thấy kế hoạch giải thích trước khi tạo chỉ mục.\nẢnh chụp màn hình sau đây cho thấy kế hoạch giải thích sau khi tạo chỉ mục.\nTrong trường hợp này, chúng ta có thể thấy hiệu suất truy vấn được cải thiện khi sử dụng chỉ mục GIN. Mặc dù nhìn chung, việc sử dụng chỉ mục GIN cho tìm kiếm toàn văn trong PostgreSQL có thể giúp cải thiện hiệu suất, bạn cần lưu ý những đánh đổi khác về hiệu suất, bao gồm thời gian cần thiết để xây dựng chỉ mục và dung lượng lưu trữ bổ sung mà chỉ mục yêu cầu.\nGiải pháp 2: Sử dụng cột được tạo đã lưu trữ Trong cách tiếp cận này, bạn tạo một cột tính toán description_tsv chứa tsvector giá trị từ cột mô tả trong bảng theo sau là chỉ mục GIN trên cột tính toán.\nChạy các lệnh sau: ALTER TABLE production.productdescription\nADD COLUMN description_tsv tsvector\nGENERATED ALWAYS AS (to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;,Description )) STORED;\nCREATE INDEX productdescription_gin_idx ON production.productdescription USING GIN(description_tsv); Chạy truy vấn EXPLAIN ANALYZE mẫu sau: EXPLAIN ANALYZE\nSELECT *\nFROM production.productdescription\nWHERE description_tsv @@ to_tsquery(\u0026lsquo;pg_catalog.english\u0026rsquo;,\u0026rsquo;entry | level\u0026rsquo;)\nORDER BY productdescriptionid DESC; Đầu ra cho thấy quá trình quét chỉ mục bitmap đang được thực hiện trên productdescription_gin_index , trong trường hợp này chứng minh sự cải thiện về hiệu suất truy vấn:\nTìm kiếm toàn văn bản trong PostgreSQL bằng tiện ích mở rộng pg_trgm Trong PostgreSQL, pg_trgm phần mở rộng này được triển khai cho các chức năng tìm kiếm văn bản sử dụng trigram. Trigram về cơ bản là tập hợp ba ký tự liên tiếp được trích xuất từ ​​một chuỗi cho trước. Bằng cách sử dụng trigram, người dùng có thể xác định sự tương đồng hoặc trùng khớp trong các mẫu văn bản bên trong chuỗi bằng cách so sánh số lượng trigram trùng khớp giữa các chuỗi, cùng với tham số ngưỡng tương đồng được xác định trước được thiết lập trước khi thực hiện tìm kiếm.\nTiện pg_trgm ích mở rộng cung cấp các toán tử có thể được sử dụng để tạo chỉ mục trigram trên các cột văn bản trong bảng cần tìm kiếm. Chỉ mục này cho phép thực hiện các phép toán tương tự hiệu quả trên các cột được lập chỉ mục. Tiện ích mở rộng cung cấp ba phép toán tương tự: similarity (%), word_similarity (\u0026lt;%), và strict_word_similarity (\u0026lt;\u0026lt;%). Các tham số ngưỡng cho các phép toán tương ứng là pg_trgm.similarity_threshold, pg_trgm.word_similarity_threshold, và pg_trgm.strict_word_similarity_threshold, có thể được đặt thành giá trị từ 0 (không tương tự) đến 1 (khớp hoàn hảo). Các hàm similarity(), word_similarty(), và strict_word_similarity()được sử dụng để tính điểm tương tự. Bạn có thể sử dụng pg_trgmnhư trong đoạn mã sau:\nChạy lệnh sau để tạo phần mở rộng pg_trgm:\nCREATE EXTENSION pg_trgm; Chạy lệnh sau để tạo chỉ mục GIN trên cột productdescription: CREATE INDEX productdescription_trgm_idx ON production.productdescription USING GIN (Description gin_trgm_ops); Chạy lệnh sau để đặt giá trị cấu hình similarity_threshold thành 0,2. Tính năng similarity sẽ kiểm tra các trigram chung giữa hai chuỗi và trả về giá trị từ 0–1. SET pg_trgm.similarity_threshold = 0.2;\nSET enable_seqscan = off;\nSELECT productdescriptionid, Description, similarity(Description, \u0026rsquo;entry level\u0026rsquo;) AS sml\nFROM production.product description\nWHERE Description % \u0026rsquo;entry level\u0026rsquo;\nORDER BY sml DESC, Description; Chạy lệnh sau để đặt giá trị cấu hình word_similarity_threshold thành 0,6. word_similarity kiểm tra các trigram chung giữa các chuỗi ở cấp độ từ. SET pg_trgm.word_similarity_threshold = 0.6;\nSET enable_seqscan = off;\nSELECT productdescriptionid, Description, word_similarity(\u0026rsquo;entry level\u0026rsquo;, Description) AS sml\nFROM production.productdescription\nWHERE \u0026rsquo;entry level\u0026rsquo; \u0026lt;% Description\nORDER BY sml DESC, Description; Chạy lệnh sau để đặt giá trị cấu hình strict_word_similarity_threshold thành 0,6. strict_word_similarity giống như word_similarity nhưng nó chỉ xem xét các trigram chung khi cả hai từ giống hệt nhau. SET pg_trgm.strict_word_similarity_threshold = 0.6;\nSET enable_seqscan = off;\nSELECT productdescriptionid, Description, strict_word_similarity(\u0026lsquo;aluminum cups and hollow axle\u0026rsquo;, Description) AS sml\nFROM production.productdescription\nWHERE \u0026rsquo;entry level\u0026rsquo; \u0026lt;\u0026lt;% Description\nORDER BY sml DESC, Description; Chạy lệnh sau để xóa chỉ mục và kích hoạt quét tuần tự: DROP INDEX production.productdescription_trgm_idx; Tìm kiếm toàn văn bản trong PostgreSQL bằng tiện ích mở rộng pg_bigm Phần pg_bigmmở rộng trong PostgreSQL tăng cường khả năng tìm kiếm toàn văn bản, đặc biệt đối với các ngôn ngữ có bộ ký tự phức tạp như ngôn ngữ châu Á.\nBigram là một nhóm hai ký tự liên tiếp được lấy từ một chuỗi. Phần mở rộng này sử dụng phương pháp lập chỉ mục bigram, bao gồm việc chia văn bản thành các cặp ký tự liên tiếp và xây dựng một chỉ mục dựa trên các bigram này. Phần mởpg_bigm rộng cung cấp bigm_similarity()hàm, toán tử tương tự bigm = %và pg_bigm.similarity_limittham số ngưỡng. Bạn có thể sử dụng pg_bigmnhư sau:\nChạy lệnh sau để tạo phần mở rộng pg_bigm. Để biết hướng dẫn tạo phần mở rộng trong Amazon RDS for PostgreSQL, hãy tham khảo bài viết Sử dụng phần mở rộng PostgreSQL với Amazon RDS for PostgreSQL . CREATE EXTENSION pg_bigm; Chạy lệnh sau để tạo chỉ mục GIN trên cột productdescription: CREATE INDEX productdescription_bigm_idx ON production.productdescription USING gin (Description gin_bigm_ops); Chạy lệnh sau để đặt giá trị cấu hình similarity_limit thành 0,15. Kiểm tra tính tương đồng để tìm các bigram chung giữa hai chuỗi và trả về giá trị từ 0–1. SET pg_bigm.similarity_limit TO 0.15;\nSELECT *,bigm_similarity(Description, \u0026lsquo;%entry level%\u0026rsquo;) rank1\nFROM production.productdescription\nWHERE Description =% \u0026lsquo;%entry level%\u0026rsquo;\nORDER BY rank1 DESC; Chạy lệnh sau để xóa chỉ mục và bật quét tuần tự: DROP INDEX production.productdescription_bigm_idx;\nSET enable_seqscan = on; Phần kết luận Trong bài viết này, chúng tôi đã hướng dẫn bạn cách di chuyển FTS từ SQL Server sang PostgreSQL và so sánh một số trường hợp sử dụng phổ biến. Việc di chuyển tìm kiếm toàn văn bản từ SQL Server sang PostgreSQL đòi hỏi phải viết lại mã thủ công. Để tìm hiểu thêm, vui lòng tham khảo các hạn chế của tính năng tìm kiếm văn bản trong PostgreSQL . Chúng tôi cũng đã hướng dẫn bạn cách sử dụng các phần mở rộng pg_trgm và pg_bigm trong PostgreSQL để triển khai FTS.\nVề các tác giả\n![][image15]\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; Mục Đích Của Sự Kiện Tìm hiểu tác động biến đổi của generative AI trong phát triển phần mềm Hiểu cách tích hợp AI vào vòng đời phát triển phần mềm (SDLC) Giới thiệu các công cụ AI để tự động hóa tác vụ phát triển: Amazon Q Developer và Kiro Học cách tận dụng AI để tăng năng suất và tập trung vào công việc có giá trị cao Diễn Giả \u0026amp; Tổ Chức Giảng viên:\nToan Huynh – Tổng quan về AI-Driven Development Life Cycle và trình diễn Amazon Q Developer My Nguyen – Trình diễn Kiro Điều phối viên:\nDiem My Dai Truong Dinh Nguyen Chi Tiết Sự Kiện Ngày: Thứ Sáu, 3 tháng 10 năm 2025 Thời gian: 14:00 – 16:30 Địa điểm: AWS Event Hall, Tầng 26, Tòa nhà Bitexco, thành phố Hồ Chí Minh Thời lượng: 2.5 giờ Chương Trình 14:00 - 14:15: Đón tiếp 14:15 - 15:30: Tổng quan về AI-Driven Development Life Cycle và trình diễn Amazon Q Developer (bởi Toan Huynh) 15:30 - 15:45: Nghỉ giải lao 15:45 - 16:30: Trình diễn Kiro (bởi My Nguyen) Nội Dung Nổi Bật Sự Nổi Lên Của Generative AI Trong Phát Triển Phần Mềm Sự biến đổi: Generative AI tái tưởng tượng cách các nhà phát triển và tổ chức học hỏi, lập kế hoạch, tạo ra, triển khai và quản lý ứng dụng một cách an toàn Tích hợp SDLC: AI có thể được tích hợp vào toàn bộ vòng đời phát triển phần mềm: kiến trúc, phát triển, kiểm thử, triển khai và bảo trì Lợi ích tự động hóa: Tự động hóa các tác vụ nặng không phân biệt, cho phép các nhà phát triển tập trung vào công việc có giá trị cao và sáng tạo hơn Tăng năng suất: Tăng năng suất đồng thời cho phép các nhà phát triển tập trung vào giải quyết vấn đề sáng tạo và đổi mới AI-Driven Development Life Cycle Bao phủ end-to-end: Từ lập kế hoạch kiến trúc ban đầu thông qua phát triển, kiểm thử, triển khai và bảo trì liên tục Biến đổi workflow: Cách các công cụ AI định hình lại các workflow phát triển truyền thống Best practices: Hướng dẫn để tích hợp AI hiệu quả vào quy trình phát triển hiện có Amazon Q Developer Hỗ trợ SDLC: Công cụ AI toàn diện hỗ trợ toàn bộ vòng đời phát triển phần mềm Khả năng chính: Hỗ trợ tạo mã, gỡ lỗi, kiểm thử, tài liệu hóa và refactoring Tích hợp: Tích hợp mượt mà với các IDE và môi trường phát triển phổ biến Trình diễn thực tế: Ví dụ thực tế về sử dụng Amazon Q Developer để tăng tốc tác vụ phát triển Kiro AI-powered development: Giới thiệu Kiro như một trợ lý phát triển AI Use cases: Các tình huống cụ thể nơi Kiro nâng cao năng suất của nhà phát triển Tính năng: Các tính năng và khả năng chính được trình diễn trong phiên Trải nghiệm thực hành: Trình diễn thực tế về Kiro trong hành động Những Gì Học Được Chiến Lược Tích Hợp AI Áp dụng dần dần: Bắt đầu với các use case cụ thể và mở rộng dần việc tích hợp công cụ AI Đảm bảo chất lượng: Công cụ AI hỗ trợ nhưng giám sát và xem xét của con người vẫn quan trọng Đường cong học tập: Hiểu các công cụ AI cần thời gian và thực hành để tối đa hóa lợi ích Hợp tác nhóm: AI nâng cao năng suất nhóm nhưng đòi hỏi workflow và hướng dẫn rõ ràng Nâng Cao Workflow Phát Triển Tác vụ tự động: Xác định các tác vụ lặp đi lặp lại, giá trị thấp có thể được tự động hóa bằng AI Chất lượng mã: Sử dụng AI cho code review, kiểm thử và tài liệu để duy trì tiêu chuẩn cao Tăng tốc: Tận dụng AI để tăng tốc chu kỳ phát triển mà không hy sinh chất lượng Học tập liên tục: Công cụ AI phát triển nhanh chóng—cập nhật các tính năng và best practices mới Năng Suất Và Tập Trung Tạo giá trị: Giải phóng các nhà phát triển khỏi các tác vụ thường ngày để tập trung vào giải quyết vấn đề phức tạp và đổi mới Tiết kiệm thời gian: Tiết kiệm thời gian đáng kể trong viết mã, gỡ lỗi và tài liệu hóa Bổ sung kiến thức: Công cụ AI giúp thu hẹp khoảng cách kiến thức và cung cấp hỗ trợ theo ngữ cảnh Khả năng mở rộng: AI cho phép các nhóm xử lý các dự án lớn hơn với cùng tài nguyên Ứng Dụng Vào Công Việc Tích hợp Amazon Q Developer: Bắt đầu sử dụng nó trong các tác vụ phát triển hàng ngày để tạo mã và hỗ trợ Khám phá Kiro: Đánh giá Kiro cho các use case cụ thể trong workflow phát triển của bạn Thiết lập AI workflows: Xác định hướng dẫn về khi nào và cách sử dụng công cụ AI trong các dự án nhóm Đo lường năng suất: Theo dõi cải thiện về tốc độ phát triển và chất lượng mã sau khi áp dụng công cụ AI Chia sẻ học hỏi: Tài liệu hóa best practices và chia sẻ kinh nghiệm với các thành viên nhóm Cập nhật liên tục: Theo dõi cập nhật cho các công cụ phát triển AI và tích hợp các tính năng mới khi chúng có sẵn Kết Quả Hoặc Giá Trị Đạt Được Tham gia sự kiện này mang lại giá trị đáng kể thông qua kiến thức mới, kỹ năng và hiểu biết thực tế có thể áp dụng trực tiếp vào các dự án hiện tại và tương lai.\nKiến Thức Mới Thu Được Khái Niệm AI-Driven Development:\nHiểu biết sâu sắc về cách generative AI biến đổi vòng đời phát triển phần mềm từ lập kế hoạch đến bảo trì Kiến thức toàn diện về tích hợp công cụ AI vào các giai đoạn khác nhau: thiết kế kiến trúc, tạo mã, kiểm thử, triển khai và giám sát liên tục Hiểu biết về best practices cho phát triển hỗ trợ AI, bao gồm khi nào nên tận dụng AI và khi nào phán đoán con người là quan trọng Chuyên Môn Amazon Q Developer:\nKiến thức thực tế về sử dụng Amazon Q Developer cho tạo mã, gỡ lỗi, tài liệu hóa và refactoring Hiểu cách tích hợp Amazon Q Developer với các IDE và môi trường phát triển hiện có Học về các khả năng cụ thể: gợi ý mã thông minh, hỗ trợ kiểm thử tự động, và cải thiện chất lượng mã Hiểu Biết Nền Tảng Kiro:\nKhám phá Kiro như một trợ lý phát triển AI và các tính năng độc đáo của nó Kiến thức về các use case cụ thể nơi Kiro có thể nâng cao năng suất của nhà phát triển Hiểu cách Kiro bổ sung cho các công cụ phát triển AI khác trong workflow Kỹ Năng Mới Phát Triển Tích Hợp Công Cụ AI:\nKỹ năng: Khả năng xác định cơ hội tự động hóa AI trong các workflow phát triển Kỹ năng: Thành thạo trong tích hợp công cụ AI như Amazon Q Developer vào các tác vụ phát triển hàng ngày Kỹ năng: Khả năng đánh giá và lựa chọn công cụ AI phù hợp cho nhu cầu dự án cụ thể Nâng Cao Workflow Phát Triển:\nKỹ năng: Cải thiện khả năng tự động hóa các tác vụ lập trình lặp đi lặp lại mà vẫn duy trì chất lượng mã Kỹ năng: Nâng cao khả năng code review bằng phân tích hỗ trợ AI Kỹ năng: Thực hành tài liệu hóa tốt hơn thông qua tạo tài liệu bằng AI Giải Quyết Vấn Đề Hỗ Trợ AI:\nKỹ năng: Tận dụng AI cho gỡ lỗi và xử lý sự cố phức tạp Kỹ năng: Sử dụng gợi ý AI để cải thiện hiệu quả mã và best practices Kỹ năng: Cân bằng hỗ trợ AI với xem xét và phán đoán quan trọng của con người Bài Học Rút Ra Hiểu Biết Thực Tế:\nCông cụ AI là bộ nhân năng suất mạnh mẽ nhưng đòi hỏi hiểu biết và tích hợp workflow phù hợp Chiến lược áp dụng dần dần hiệu quả hơn việc cố gắng tích hợp tất cả công cụ AI cùng một lúc Giám sát con người vẫn cần thiết—AI hỗ trợ nhưng không thay thế chuyên môn và phán đoán của nhà phát triển Đo lường cải thiện năng suất và chất lượng mã giúp biện minh cho việc áp dụng công cụ AI Hiểu Biết Chiến Lược:\nTích hợp AI thành công đòi hỏi sự đồng nhất nhóm và hướng dẫn rõ ràng về cách sử dụng Công cụ AI phát triển nhanh chóng—cập nhật liên tục với tính năng mới tối đa hóa giá trị lâu dài Xác định đúng use case là quan trọng—không phải tất cả tác vụ phát triển đều hưởng lợi như nhau từ hỗ trợ AI Chất lượng mã thực sự có thể cải thiện với công cụ AI khi được sử dụng một cách có suy nghĩ và được xem xét đúng cách Đóng Góp Cho Nhóm/Dự Án Chia Sẻ Kiến Thức:\nTài liệu hóa: Tạo ghi chú và tài liệu về best practices từ sự kiện để chia sẻ với các thành viên nhóm Trình bày: Chuẩn bị chia sẻ hiểu biết về Amazon Q Developer và Kiro với nhóm phát triển Hướng dẫn: Phát triển hướng dẫn ban đầu để tích hợp công cụ AI vào workflow nhóm Ứng Dụng Thực Tế:\nDự án thí điểm: Xác định các dự án cụ thể nơi công cụ AI có thể được thí điểm để đạt được lợi ích năng suất ngay lập tức Cải thiện workflow: Đề xuất tích hợp Amazon Q Developer cho code review và tác vụ tài liệu hóa Đào tạo: Lập kế hoạch tổ chức các phiên nội bộ về thực hành phát triển dựa trên AI cho nhóm Giá Trị Dài Hạn:\nLợi thế cạnh tranh: Có được kiến thức giúp nhóm tận dụng các công cụ phát triển AI tiên tiến Cải thiện hiệu quả: Dự kiến cải thiện 20-30% tốc độ phát triển cho các tác vụ lặp đi lặp lại bằng công cụ AI Nâng cao chất lượng: Tiềm năng cải thiện chất lượng mã thông qua xem xét hỗ trợ AI và gợi ý best practices Đổi mới: Khả năng mới cho phép nhóm giải quyết các vấn đề phức tạp hơn bằng cách giao phó công việc thường ngày cho AI Phát Triển Cá Nhân Phát Triển Kỹ Thuật:\nMở rộng hiểu biết về thực hành phát triển phần mềm hiện đại với tích hợp AI Phát triển quan điểm tư duy tiến bộ về sự tiến hóa của kỹ thuật phần mềm Nâng cao khả năng đánh giá và áp dụng công nghệ mới hiệu quả Phát Triển Nghề Nghiệp:\nTăng tự tin trong làm việc với công cụ phát triển AI Cải thiện khả năng giao tiếp khái niệm kỹ thuật cho cả đối tượng kỹ thuật và phi kỹ thuật Tăng cường kết nối mạng với các nhà phát triển khác quan tâm đến phát triển dựa trên AI Trải nghiệm trong event Tham gia phiên \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; là một trải nghiệm mở mang tầm mắt, cung cấp những hiểu biết sâu sắc về cách generative AI đang biến đổi phát triển phần mềm. Các trải nghiệm chính bao gồm:\nHiểu về sự biến đổi AI Học cách generative AI đánh dấu sự thay đổi biến đổi trong thực hành phát triển phần mềm. Hiểu biết về tích hợp AI vào toàn bộ SDLC: kiến trúc, phát triển, kiểm thử, triển khai và bảo trì. Hiểu cách tự động hóa AI cho phép các nhà phát triển tập trung vào các tác vụ sáng tạo có giá trị cao hơn. Trình diễn công cụ thực hành Chứng kiến Amazon Q Developer trong hành động, xem cách nó có thể hỗ trợ tạo mã, gỡ lỗi và tài liệu hóa. Khám phá Kiro như một trợ lý phát triển AI và tìm hiểu về các khả năng và use case cụ thể của nó. Xem các ví dụ thực tế về cách các công cụ này tăng tốc phát triển đồng thời duy trì chất lượng mã. Học tập thực tế Học về best practices để tích hợp công cụ AI vào các workflow phát triển hiện có. Hiểu tầm quan trọng của giám sát con người và đảm bảo chất lượng khi sử dụng công cụ AI. Hiểu biết về xác định cơ hội cho tự động hóa AI trong quy trình phát triển. Kết nối và thảo luận Kết nối với các nhà phát triển khác quan tâm đến phát triển dựa trên AI. Trao đổi ý tưởng về ứng dụng thực tế của công cụ AI trong các dự án thực tế. Thảo luận về thách thức và cơ hội trong việc áp dụng công cụ phát triển AI. Bài học rút ra Công cụ AI là trợ lý mạnh mẽ nhưng phán đoán và xem xét của con người vẫn cần thiết cho mã chất lượng. Tích hợp AI thành công đòi hỏi áp dụng dần dần và đào tạo nhóm. Công cụ AI phù hợp có thể tăng năng suất đáng kể và giải phóng các nhà phát triển cho công việc sáng tạo hơn. Cập nhật với sự tiến hóa của công cụ AI là rất quan trọng để tối đa hóa lợi ích. Một số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện này mở mang tầm mắt về tiềm năng của phát triển dựa trên AI và cung cấp hướng dẫn thực tế về cách tận dụng những công cụ mạnh mẽ này để nâng cao năng suất, cải thiện chất lượng mã và tập trung vào công việc có giá trị cao trong kỹ thuật phần mềm.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AI/ML/GenAI on AWS\u0026rdquo; Mục Đích Của Sự Kiện Cung cấp tổng quan toàn diện về dịch vụ và khả năng AI/ML của AWS Giới thiệu Amazon SageMaker như một nền tảng ML end-to-end Khám phá Generative AI với Amazon Bedrock Minh họa các ứng dụng thực tế thông qua demo trực tiếp Chia sẻ best practices cho triển khai AI/ML tại Việt Nam Chi Tiết Sự Kiện Ngày: Thứ Bảy, 15 tháng 11 năm 2025 Thời gian: 8:30 – 12:00 Địa điểm: Văn phòng AWS Vietnam Thời lượng: 3.5 giờ (không bao gồm nghỉ trưa) Chương Trình 8:30 – 9:00 | Đón tiếp \u0026amp; Giới thiệu Đăng ký tham gia và networking Tổng quan workshop và mục tiêu học tập Hoạt động phá băng Tổng quan về thị trường AI/ML tại Việt Nam 9:00 – 10:30 | Tổng quan dịch vụ AWS AI/ML Amazon SageMaker – Nền tảng ML end-to-end Chuẩn bị và gắn nhãn dữ liệu Huấn luyện, tinh chỉnh và triển khai mô hình Khả năng MLOps tích hợp Demo trực tiếp: Hướng dẫn SageMaker Studio 10:30 – 10:45 | Nghỉ giải lao 10:45 – 12:00 | Generative AI với Amazon Bedrock Foundation Models: Claude, Llama, Titan – so sánh \u0026amp; hướng dẫn lựa chọn Prompt Engineering: Kỹ thuật, Chain-of-Thought reasoning, Few-shot learning Retrieval-Augmented Generation (RAG): Kiến trúc \u0026amp; Tích hợp Knowledge Base Bedrock Agents: Multi-step workflows và tích hợp công cụ Guardrails: An toàn và lọc nội dung Demo trực tiếp: Xây dựng chatbot Generative AI sử dụng Bedrock Nội Dung Nổi Bật Nền Tảng Amazon SageMaker Nền Tảng ML Toàn Diện: Giải pháp hoàn chỉnh cho xây dựng, huấn luyện và triển khai mô hình machine learning Chuẩn Bị Dữ Liệu: Công cụ cho gắn nhãn dữ liệu, feature engineering, và validation dữ liệu Huấn Luyện Mô Hình: Hỗ trợ các framework và thuật toán ML khác nhau với khả năng huấn luyện phân tán Triển Khai Mô Hình: Các tùy chọn triển khai linh hoạt bao gồm real-time inference, batch processing, và serverless inference Tích Hợp MLOps: Khả năng tích hợp sẵn cho giám sát mô hình, versioning, và automated workflows Generative AI với Amazon Bedrock Lựa Chọn Foundation Model: Hiểu sự khác biệt giữa các mô hình Claude, Llama, và Titan Claude: Khả năng lý luận và trò chuyện mạnh mẽ Llama: Mô hình mã nguồn mở với hiệu suất tốt Titan: Mô hình do AWS phát triển được tối ưu cho các use case cụ thể Kỹ Thuật Prompt Engineering: Chain-of-Thought reasoning cho giải quyết vấn đề phức tạp Few-shot learning với ví dụ Quản lý ngữ cảnh và tối ưu hóa prompt Kiến Trúc RAG: Kết hợp retrieval với generation cho phản hồi chính xác, nhận biết ngữ cảnh Tích hợp knowledge base Vector embeddings và similarity search Chiến lược chunking tài liệu Bedrock Agents: Tác nhân tự động có thể thực hiện các tác vụ multi-step Tích hợp công cụ và gọi API Orchestration workflow Khả năng ra quyết định Guardrails cho An Toàn AI: Lọc nội dung và kiểm soát an toàn Phát hiện nội dung có hại Cấu hình policy tùy chỉnh Tuân thủ và quản trị Thị Trường AI/ML tại Việt Nam Xu hướng và cơ hội áp dụng hiện tại Use cases cụ thể cho thị trường Việt Nam Thách thức và giải pháp cho doanh nghiệp địa phương Câu chuyện thành công và case studies Những Gì Học Được Best Practices Machine Learning Cách Tiếp Cận Nền Tảng End-to-end: Sử dụng SageMaker cho quản lý vòng đời ML hoàn chỉnh Chất Lượng Dữ Liệu Trước Tiên: Đầu tư vào chuẩn bị và gắn nhãn dữ liệu để cải thiện hiệu suất mô hình Tích Hợp MLOps: Triển khai giám sát và automated workflows ngay từ đầu Chiến Lược Lựa Chọn Mô Hình: Chọn mô hình phù hợp dựa trên use case, không chỉ metrics hiệu suất Triển Khai Generative AI Lựa Chọn Foundation Model: Hiểu điểm mạnh của từng mô hình (Claude, Llama, Titan) cho các scenario khác nhau Thành Thạo Prompt Engineering: Chain-of-Thought và Few-shot learning cải thiện đáng kể kết quả RAG cho Độ Chính Xác: Sử dụng kiến trúc RAG khi độ chính xác thực tế là quan trọng Thiết Kế Agent: Xây dựng agent có thể xử lý multi-step workflows với tích hợp công cụ phù hợp An Toàn Trước Tiên: Luôn triển khai guardrails cho lọc nội dung và tuân thủ Sẵn Sàng Sản Xuất Bắt Đầu Nhỏ, Mở Rộng Dần: Bắt đầu với dự án thí điểm trước khi triển khai đầy đủ Tối Ưu Chi Phí: Giám sát và tối ưu chi phí inference với các tùy chọn serverless Bảo Mật \u0026amp; Tuân Thủ: Triển khai kiểm soát truy cập và biện pháp bảo mật dữ liệu phù hợp Cải Thiện Liên Tục: Giám sát hiệu suất mô hình và lặp lại dựa trên phản hồi thực tế Ứng Dụng Vào Công Việc Khám Phá SageMaker: Bắt đầu với SageMaker Studio cho thử nghiệm ML và phát triển mô hình Triển Khai Giải Pháp RAG: Xây dựng knowledge base cho ứng dụng domain-specific sử dụng kiến trúc RAG Phát Triển Bedrock Agents: Tạo tác nhân tự động cho dịch vụ khách hàng hoặc tự động hóa workflow Thực Hành Prompt Engineering: Áp dụng kỹ thuật Chain-of-Thought và Few-shot để cải thiện phản hồi AI Triển Khai Guardrails: Triển khai lọc nội dung và kiểm soát an toàn cho ứng dụng GenAI sản xuất Thiết Lập MLOps: Thiết lập giám sát mô hình và automated deployment pipelines sử dụng khả năng SageMaker Trải nghiệm trong event Tham gia workshop \u0026ldquo;AI/ML/GenAI on AWS\u0026rdquo; là một trải nghiệm học tập đặc biệt cung cấp hiểu biết toàn diện về khả năng AI và machine learning của AWS. Sự kiện kết hợp kiến thức lý thuyết với các trình diễn thực tế, giúp em hiểu rõ cách triển khai giải pháp AI/ML trên AWS.\nHọc từ chương trình toàn diện Chương trình có cấu trúc bao phủ mọi thứ từ khái niệm ML cơ bản đến triển khai Generative AI nâng cao. Bắt đầu với tổng quan nền tảng SageMaker giúp em hiểu vòng đời ML hoàn chỉnh trước khi đi sâu vào chi tiết GenAI. Sự tiến triển từ ML truyền thống đến Generative AI cho thấy sự tiến hóa và tính bổ sung của các công nghệ này. Trải nghiệm kỹ thuật thực hành Hướng dẫn SageMaker Studio minh họa quy trình thực tế xây dựng mô hình ML, từ chuẩn bị dữ liệu đến triển khai. Em học về các công cụ gắn nhãn dữ liệu và cách chúng có thể cải thiện đáng kể độ chính xác mô hình với chất lượng dữ liệu phù hợp. Khả năng MLOps cho em thấy cách triển khai continuous integration và giám sát cho mô hình ML trong sản xuất. Tìm hiểu sâu về Generative AI Phiên Amazon Bedrock rất mở mang tầm mắt, cho em thấy cách tận dụng foundation models mà không cần huấn luyện từ đầu. Kỹ thuật Prompt Engineering như Chain-of-Thought reasoning và Few-shot learning được minh họa với các ví dụ thực tế. Học về kiến trúc RAG giúp em hiểu cách xây dựng ứng dụng AI chính xác kết hợp retrieval với generation. Demo Bedrock Agents cho thấy cách xây dựng hệ thống AI tự động có thể thực hiện các tác vụ multi-step phức tạp. Trình diễn thực tế Demo trực tiếp xây dựng chatbot Generative AI sử dụng Bedrock cho em bức tranh hoàn chỉnh về triển khai từ đầu đến cuối. Xem Guardrails hoạt động minh chứng tầm quan trọng của an toàn và lọc nội dung trong ứng dụng GenAI sản xuất. So sánh giữa các mô hình Claude, Llama, và Titan giúp em hiểu khi nào sử dụng mỗi mô hình. Kết nối và thảo luận Workshop cung cấp cơ hội networking tuyệt vời với các người đam mê và thực hành AI/ML khác tại Việt Nam. Thảo luận về thị trường AI/ML tại Việt Nam cho em hiểu biết theo ngữ cảnh về cơ hội và thách thức thị trường địa phương. Chia sẻ kinh nghiệm với đồng nghiệp giúp em hiểu các thách thức và giải pháp triển khai thực tế. Bài học rút ra SageMaker cung cấp một nền tảng hoàn chỉnh đơn giản hóa toàn bộ vòng đời ML, từ chuẩn bị dữ liệu đến triển khai. Foundation models trong Bedrock loại bỏ nhu cầu huấn luyện mô hình lớn từ đầu, giảm đáng kể thời gian và chi phí. Kiến trúc RAG là quan trọng cho xây dựng ứng dụng GenAI chính xác cần tham chiếu knowledge base cụ thể. Prompt engineering là một kỹ năng đòi hỏi thực hành và hiểu biết các kỹ thuật khác nhau để có kết quả tối ưu. Guardrails là cần thiết cho ứng dụng GenAI sản xuất để đảm bảo an toàn và tuân thủ. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop này cung cấp cho em cả kiến thức nền tảng và kỹ năng thực tế cần thiết để triển khai giải pháp AI/ML và Generative AI trên AWS. Sự kết hợp giữa tổng quan nền tảng toàn diện, khả năng GenAI chi tiết, và các trình diễn thực hành cho em tự tin bắt đầu xây dựng các ứng dụng được hỗ trợ bởi AI.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;DevOps on AWS\u0026rdquo; Mục Đích Của Sự Kiện Giới thiệu văn hóa, nguyên tắc và các metrics chính của DevOps Trình diễn các dịch vụ AWS DevOps cho tự động hóa CI/CD pipeline Khám phá Infrastructure as Code (IaC) với CloudFormation và CDK Bao phủ các dịch vụ container và chiến lược triển khai microservices Cung cấp best practices về monitoring và observability Chia sẻ case studies DevOps thực tế và best practices Chi Tiết Sự Kiện Ngày: Thứ Hai, 17 tháng 11 năm 2025 Thời gian: 08:30 – 17:00 Địa điểm: Tòa nhà Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh Thời lượng: Cả ngày (8.5 giờ với các giờ nghỉ) Chương Trình Buổi Sáng (8:30 AM – 12:00 PM) 8:30 – 9:00 | Đón tiếp \u0026amp; DevOps Mindset\nTóm tắt lại phiên AI/ML Văn hóa và nguyên tắc DevOps Lợi ích và các metrics chính (DORA, MTTR, tần suất deployment) 9:00 – 10:30 | Dịch vụ AWS DevOps – CI/CD Pipeline\nSource Control: AWS CodeCommit, Git strategies (GitFlow, Trunk-based) Build \u0026amp; Test: Cấu hình CodeBuild, testing pipelines Deployment: CodeDeploy với Blue/Green, Canary, và Rolling updates Orchestration: Tự động hóa CodePipeline Demo: Hướng dẫn CI/CD pipeline đầy đủ 10:30 – 10:45 | Nghỉ giải lao\n10:45 – 12:00 | Infrastructure as Code (IaC)\nAWS CloudFormation: Templates, stacks, và drift detection AWS CDK (Cloud Development Kit): Constructs, reusable patterns, và language support Demo: Triển khai với CloudFormation và CDK Thảo luận: Lựa chọn giữa các công cụ IaC Nghỉ Trưa (12:00 – 13:00) Buổi Chiều (13:00 – 17:00) 13:00 – 14:30 | Dịch Vụ Container trên AWS\nDocker Fundamentals: Microservices và containerization Amazon ECR: Lưu trữ image, scanning, lifecycle policies Amazon ECS \u0026amp; EKS: Chiến lược deployment, scaling, và orchestration AWS App Runner: Triển khai container đơn giản Demo \u0026amp; Case Study: So sánh triển khai microservices 14:30 – 14:45 | Nghỉ giải lao\n14:45 – 16:00 | Monitoring \u0026amp; Observability\nCloudWatch: Metrics, logs, alarms, và dashboards AWS X-Ray: Distributed tracing và performance insights Demo: Thiết lập full-stack observability Best Practices: Alerting, dashboards, và quy trình on-call 16:00 – 16:45 | DevOps Best Practices \u0026amp; Case Studies\nChiến lược deployment: Feature flags, A/B testing Automated testing và tích hợp CI/CD Quản lý incident và postmortems Case Studies: Chuyển đổi DevOps của startups và enterprise 16:45 – 17:00 | Q\u0026amp;A \u0026amp; Tổng kết\nCon đường nghề nghiệp DevOps Lộ trình chứng chỉ AWS Nội Dung Nổi Bật Văn Hóa và Nguyên Tắc DevOps DevOps Mindset: Hợp tác giữa các team development và operations Chuyển Đổi Văn Hóa: Phá vỡ silos và thúc đẩy trách nhiệm chia sẻ Metrics Chính (DORA): Đo lường hiệu suất DevOps Deployment Frequency: Tần suất triển khai xảy ra Lead Time: Thời gian từ code commit đến production MTTR (Mean Time To Recovery): Thời gian khôi phục sau lỗi Change Failure Rate: Tỷ lệ phần trăm các deployment gây lỗi Lợi Ích: Giao hàng nhanh hơn, độ tin cậy cải thiện, hợp tác tốt hơn Dịch Vụ AWS CI/CD Pipeline AWS CodeCommit:\nDịch vụ source control được quản lý đầy đủ Version control dựa trên Git Tích hợp với các dịch vụ AWS khác Git strategies: GitFlow, Trunk-based development, feature branches AWS CodeBuild:\nDịch vụ build được quản lý đầy đủ Môi trường build có thể mở rộng Hỗ trợ nhiều ngôn ngữ lập trình và công cụ build Build artifacts và test reports Tích hợp với testing frameworks AWS CodeDeploy:\nDịch vụ deployment tự động Chiến lược deployment: Blue/Green: Triển khai zero-downtime với rollback tức thì Canary: Rollout dần dần với rollback tự động khi có lỗi Rolling: Cập nhật rolling với kích thước batch có thể cấu hình Triển khai ứng dụng trên EC2, Lambda, và on-premises AWS CodePipeline:\nDịch vụ continuous delivery được quản lý đầy đủ Trình tạo workflow trực quan Tích hợp với công cụ bên thứ ba Orchestration pipeline tự động Approval gates và điểm can thiệp thủ công Infrastructure as Code (IaC) AWS CloudFormation:\nDịch vụ IaC khai báo Cú pháp template JSON/YAML Quản lý stack và cung cấp tài nguyên Drift detection và cập nhật stack Change sets để xem trước thay đổi Nested stacks cho hạ tầng modular AWS CDK (Cloud Development Kit):\nIaC lập trình sử dụng ngôn ngữ lập trình quen thuộc Hỗ trợ TypeScript, Python, Java, C#, và Go Constructs cho các pattern hạ tầng có thể tái sử dụng Abstractions cấp cao hơn và best practices Tích hợp với CloudFormation CLI tools cho deployment và quản lý Lựa Chọn Giữa Các Công Cụ IaC:\nCloudFormation: Khai báo, dựa trên template, AWS-native CDK: Lập trình, type-safe, thân thiện với developer Use cases và khi nào chọn mỗi cách tiếp cận Dịch Vụ Container trên AWS Docker Fundamentals:\nLợi ích containerization và use cases Kiến trúc microservices với containers Tạo và tối ưu Docker image Multi-stage builds và best practices Amazon ECR (Elastic Container Registry):\nDocker container registry được quản lý đầy đủ Lưu trữ và versioning image Scanning image để tìm lỗ hổng Lifecycle policies cho cleanup tự động Tích hợp với ECS và EKS Amazon ECS (Elastic Container Service):\nContainer orchestration được quản lý đầy đủ Fargate (serverless) và EC2 launch types Task definitions và service configurations Auto-scaling và load balancing Service discovery và networking Amazon EKS (Elastic Kubernetes Service):\nDịch vụ Kubernetes được quản lý Kubernetes-native orchestration Quản lý worker nodes Add-ons và tích hợp ecosystem Multi-tenant và namespace isolation AWS App Runner:\nTriển khai container đơn giản Auto-scaling và load balancing tự động Triển khai source code hoặc container image Tích hợp CI/CD tích hợp sẵn Mô hình định giá pay-per-use Monitoring \u0026amp; Observability Amazon CloudWatch:\nMetrics: Metrics ứng dụng và hạ tầng Logs: Quản lý và phân tích log tập trung Alarms: Alerting và thông báo tự động Dashboards: Trực quan hóa tùy chỉnh metrics và logs Insights: Phát hiện bất thường tự động Composite Alarms: Logic cảnh báo phức tạp AWS X-Ray:\nDistributed tracing cho microservices Trực quan hóa luồng request Xác định bottleneck hiệu suất Tạo service map Tích hợp với Lambda, ECS, và API Gateway Phân tích và lọc trace Best Practices:\nThiết lập chiến lược alerting hiệu quả Tạo dashboards có ý nghĩa Quy trình on-call và incident response Tổng hợp và phân tích log Thu thập metrics và retention policies DevOps Best Practices Chiến Lược Deployment:\nFeature Flags: Rollout tính năng dần dần A/B Testing: So sánh các phiên bản khác nhau Canary Deployments: Giảm thiểu rủi ro thông qua rollout dần dần Blue/Green Deployments: Cập nhật zero-downtime Automated Testing:\nUnit, integration, và end-to-end testing Test automation trong CI/CD pipelines Quality gates và test coverage Performance và load testing Quản Lý Incident:\nTạo và bảo trì runbook Quy trình incident response Phân tích postmortem và học hỏi Quy trình cải thiện liên tục Những Gì Học Được Chuyển Đổi Văn Hóa DevOps Thay Đổi Văn Hóa Là Căn Bản: Chỉ công cụ không tạo ra DevOps—văn hóa và hợp tác là chìa khóa Đo Lường Những Gì Quan Trọng: Sử dụng DORA metrics để theo dõi mức độ trưởng thành DevOps Cải Thiện Liên Tục: DevOps là một hành trình, không phải đích đến Tự Động Hóa Trước Tiên: Tự động hóa các tác vụ lặp đi lặp lại để tập trung vào công việc có giá trị cao Best Practices CI/CD Bắt Đầu Đơn Giản, Mở Rộng Dần: Bắt đầu với pipeline cơ bản và thêm phức tạp theo thời gian Git Strategy Quan Trọng: Chọn GitFlow hoặc Trunk-based dựa trên kích thước team và nhịp độ release Testing Là Quan Trọng: Tích hợp automated testing ở mọi giai đoạn Chiến Lược Deployment: Sử dụng chiến lược deployment phù hợp dựa trên mức độ chấp nhận rủi ro Infrastructure as Code: Luôn sử dụng IaC cho hạ tầng có thể tái tạo và được version control Container Orchestration Chọn Thông Minh: ECS cho đơn giản, EKS cho ecosystem Kubernetes Bắt Đầu Với Serverless: Fargate loại bỏ overhead quản lý node Tối Ưu Images: Image nhỏ hơn có nghĩa là deployment nhanh hơn và chi phí thấp hơn Bảo Mật Trước Tiên: Scan images và sử dụng IAM policies least-privilege Chiến Lược Observability Triển Khai Full-Stack Observability: Metrics, logs, và traces cùng nhau Monitoring Chủ Động: Thiết lập alarms trước khi incident xảy ra Dashboards Có Ý Nghĩa: Tạo dashboards cung cấp insights có thể hành động Distributed Tracing: Cần thiết cho debug kiến trúc microservices Ứng Dụng Vào Công Việc Triển Khai CI/CD Pipelines: Thiết lập CodePipeline cho deployments tự động Áp Dụng Infrastructure as Code: Sử dụng CloudFormation hoặc CDK cho tất cả hạ tầng Containerize Applications: Bắt đầu containerize ứng dụng để portability tốt hơn Thiết Lập Monitoring: Triển khai CloudWatch và X-Ray cho observability Thiết Lập DevOps Practices: Tạo runbooks, quy trình incident response, và templates postmortem Đo Lường DevOps Metrics: Theo dõi DORA metrics để đo lường cải thiện Trải nghiệm trong event Tham gia workshop \u0026ldquo;DevOps on AWS\u0026rdquo; cả ngày là một trải nghiệm học tập chuyên sâu và toàn diện bao phủ toàn bộ phạm vi DevOps từ văn hóa đến triển khai. Sự kiện cung cấp cả kiến thức lý thuyết và trình diễn thực tế, giúp em hiểu hoàn chỉnh về triển khai DevOps practices trên AWS.\nHọc các nguyên tắc cơ bản DevOps Phiên bắt đầu với DevOps mindset và văn hóa, nhấn mạnh rằng DevOps không chỉ là công cụ—đó là về hợp tác và trách nhiệm chia sẻ. Em học về DORA metrics (Deployment Frequency, Lead Time, MTTR, Change Failure Rate) và cách đo lường mức độ trưởng thành DevOps. Hiểu lợi ích của DevOps giúp em thấy bức tranh lớn hơn ngoài triển khai kỹ thuật. Tìm hiểu sâu về AWS CI/CD pipeline Hướng dẫn CodeCommit, CodeBuild, CodeDeploy, và CodePipeline cho em thấy cách xây dựng CI/CD pipeline hoàn chỉnh. Học về các Git strategies khác nhau (GitFlow vs Trunk-based) giúp em hiểu khi nào sử dụng mỗi cách tiếp cận. Demo chiến lược deployment (Blue/Green, Canary, Rolling) rất mở mang tầm mắt, cho thấy cách giảm thiểu rủi ro và downtime. Demo CI/CD pipeline trực tiếp minh họa toàn bộ workflow từ code commit đến production deployment. Thành thạo Infrastructure as Code CloudFormation minh họa cách quản lý hạ tầng khai báo với templates. AWS CDK cho em thấy cách viết code hạ tầng bằng ngôn ngữ lập trình quen thuộc, làm cho nó dễ bảo trì hơn. So sánh giữa CloudFormation và CDK giúp em hiểu khi nào sử dụng mỗi công cụ. Học về drift detection và change sets cho em tự tin quản lý hạ tầng an toàn. Khám phá dịch vụ container Docker fundamentals làm mới hiểu biết của em về containerization và lợi ích của nó. Amazon ECR cho thấy cách quản lý container images an toàn với scanning và lifecycle policies. So sánh ECS và EKS giúp em hiểu trade-offs giữa dịch vụ được quản lý và tính linh hoạt Kubernetes. AWS App Runner giới thiệu cách triển khai container đơn giản hơn mà không cần quản lý hạ tầng. Case study triển khai microservices cung cấp insights thực tế về lựa chọn dịch vụ container phù hợp. Thiết lập monitoring và observability CloudWatch bao phủ toàn diện cho em thấy cách thu thập metrics, logs, và thiết lập alarms. AWS X-Ray distributed tracing minh họa cách debug kiến trúc microservices phức tạp. Demo full-stack observability cho thấy cách kết nối tất cả các phần monitoring lại với nhau. Học về best practices alerting và quy trình on-call cung cấp kiến thức vận hành thực tế. Best practices và case studies Chiến lược deployment như feature flags và A/B testing cho thấy kỹ thuật nâng cao cho deployments an toàn. Tích hợp automated testing minh họa cách xây dựng quality gates vào CI/CD pipelines. Quản lý incident practices và templates postmortem cung cấp cấu trúc cho xử lý các vấn đề production. Case studies từ startups và enterprises cho thấy chuyển đổi DevOps thực tế và bài học học được. Hướng dẫn nghề nghiệp và chứng chỉ Thảo luận con đường nghề nghiệp DevOps giúp em hiểu các vai trò và yêu cầu kỹ năng khác nhau. Lộ trình chứng chỉ AWS cung cấp hướng dẫn rõ ràng về các chứng chỉ liên quan đến DevOps. Hiểu sự tiến triển nghề nghiệp cho em lộ trình phát triển chuyên nghiệp. Trình diễn thực tế Mọi phiên đều bao gồm demo trực tiếp cho thấy triển khai thực tế, không chỉ slides. Hướng dẫn CI/CD pipeline đầy đủ minh họa tự động hóa end-to-end. Demo CloudFormation và CDK cho thấy cả hai cách tiếp cận quản lý hạ tầng. So sánh triển khai container giúp em hình dung các cách tiếp cận khác nhau cạnh nhau. Kết nối và thảo luận Định dạng cả ngày cho phép networking mở rộng với các DevOps practitioners khác. Phiên Q\u0026amp;A cung cấp cơ hội nhận câu trả lời cho các câu hỏi cụ thể. Thảo luận thách thức thực tế với đồng nghiệp giúp em hiểu các pitfalls và giải pháp phổ biến. Bài học rút ra DevOps là chuyển đổi văn hóa đòi hỏi sự đồng thuận từ cả team development và operations. Tự động hóa là cần thiết nhưng phải được triển khai cẩn thận để tránh tạo technical debt. Infrastructure as Code là không thể thương lượng cho DevOps practices hiện đại. Monitoring và observability là quan trọng cho duy trì hệ thống production. Bắt đầu đơn giản và lặp lại thay vì cố gắng triển khai mọi thứ cùng một lúc. Đo lường mọi thứ sử dụng DORA metrics để theo dõi cải thiện theo thời gian. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop cả ngày này cung cấp cho em kiến thức toàn diện về dịch vụ AWS DevOps và best practices. Sự kết hợp giữa nguyên tắc chuyển đổi văn hóa, trình diễn công cụ thực tế, và case studies thực tế cho em tự tin triển khai DevOps practices trong các dự án của em. Độ sâu và phạm vi nội dung bao phủ mọi thứ từ CI/CD pipelines đến container orchestration và observability, cung cấp nền tảng hoàn chỉnh cho xây dựng khả năng DevOps trên AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tổng quan Worklog này ghi lại hành trình của tôi trong chương trình thực tập AWS Cloud Journey, nơi tôi hoàn thành trải nghiệm học tập và dự án thực hành toàn diện trong 12 tuần. Chương trình được cấu trúc để xây dựng kiến thức từ các khái niệm AWS cơ bản đến triển khai một kiến trúc web application hoàn chỉnh, sẵn sàng cho production trên AWS.\nThời gian: 12 tuần (khoảng 3 tháng)\nNgày hoàn thành: Tháng 11 năm 2025\nDự án cuối cùng: AWS web application production-ready với CI/CD, monitoring, và security\nTiến độ theo tuần Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS - Giới thiệu về hệ sinh thái AWS, điều hướng console, và các dịch vụ cơ bản.\nTuần 2: Khám phá các dịch vụ AWS cơ bản - Đi sâu vào các dịch vụ AWS cốt lõi và use cases của chúng.\nTuần 3: Các khái niệm AWS nâng cao - Khám phá các tính năng nâng cao và tích hợp dịch vụ.\nTuần 4: Thực hành labs và bài tập - Các bài tập thực hành và phiên lab để củng cố kiến thức.\nTuần 5: Labs và workshops nâng cao - Các kịch bản phức tạp và tích hợp đa dịch vụ.\nTuần 6: Dịch vụ Database trên AWS - Amazon RDS, Aurora, Redshift, ElastiCache, và các công cụ migration database (DMS, SCT).\nTuần 7: Dịch vụ Analytics và Data Lake - Amazon DynamoDB, AWS Glue, Amazon Athena, Amazon QuickSight, và xây dựng data lakes trên AWS.\nTuần 8: Edge Layer và Frontend Infrastructure - Route 53, S3 static hosting, CloudFront CDN, AWS WAF, và thiết lập ACM Certificate.\nTuần 9: VPC và Networking Core - Tạo VPC, subnets, Internet Gateway, NAT Gateway, Security Groups, IAM roles, và VPC Flow Logs.\nTuần 10: Triển khai Backend và Database - Thiết lập EC2 backend, cấu hình RDS database, API Gateway, Cognito authentication, và Auto Scaling Group.\nTuần 11: CI/CD Pipeline và Monitoring - Tích hợp GitLab, CodePipeline, CodeBuild, SSH-less deployment, CloudWatch monitoring, CloudTrail, và SNS alerts.\nTuần 12: Hoàn thiện dự án và tài liệu - Kiểm tra cuối cùng, tài liệu, và bàn giao dự án.\nKhó khăn và Giải pháp Trong suốt 12 tuần của chương trình, tôi đã gặp phải nhiều thách thức kỹ thuật đòi hỏi giải quyết vấn đề và hiểu biết sâu hơn:\nKhó khăn 1: Cấu hình CloudFront Origin Access Control (OAC) Vấn đề: Ban đầu bị nhầm lẫn giữa Origin Access Identity (OAI) và Origin Access Control (OAC) mới hơn. Phương pháp OAI đã bị deprecated, và tôi cần sử dụng OAC cho truy cập S3 bucket.\nGiải pháp: Nghiên cứu tài liệu AWS và học được rằng OAC là phương pháp được khuyến nghị. Cập nhật S3 bucket policies để hoạt động với OAC và cấu hình CloudFront distribution tương ứng. Điều này yêu cầu hiểu sự khác biệt trong mô hình permissions giữa OAI và OAC.\nKhó khăn 2: Thiết lập API Gateway VPC Link cho Private Resources Vấn đề: Kết nối API Gateway với EC2 instances trong private subnet là thách thức. Ban đầu thử HTTP integration trực tiếp, nhưng private subnet resources không thể truy cập trực tiếp.\nGiải pháp: Triển khai API Gateway VPC Link để thiết lập kết nối giữa API Gateway và VPC. Điều này yêu cầu tạo Network Load Balancer (NLB) trong private subnet và cấu hình VPC Link trỏ đến NLB. Học được tầm quan trọng của VPC endpoints và các mẫu kết nối private.\nKhó khăn 3: Kết nối RDS từ EC2 trong Private Subnet Vấn đề: EC2 instance trong private subnet ban đầu không thể kết nối với RDS database. Security group rules không được cấu hình đúng, và tôi không sử dụng RDS endpoint chính xác.\nGiải pháp:\nXác minh Security Group rules: RDS Security Group phải cho phép inbound từ EC2 Security Group trên database port (3306/5432). Sử dụng AWS Secrets Manager để retrieve database credentials an toàn thay vì hardcode. Kiểm tra kết nối sử dụng AWS Systems Manager Session Manager để truy cập EC2 mà không cần SSH. Khó khăn 4: CodeBuild và CloudFront Cache Invalidation Vấn đề: Sau khi deploy frontend updates qua CodeBuild lên S3, các thay đổi không được phản ánh ngay lập tức do CloudFront caching. Manual cache invalidation tốn thời gian.\nGiải pháp: Tự động hóa CloudFront cache invalidation trong file buildspec.yml của CodeBuild. Thêm AWS CLI command để tạo invalidation sau khi upload S3, đảm bảo người dùng thấy nội dung cập nhật ngay sau deployment.\nKhó khăn 5: SSH-less Deployment cho Backend Vấn đề: Deployment dựa trên SSH truyền thống không an toàn và không hoạt động tốt với Auto Scaling Group (instances là ephemeral). Cần một cách tiếp cận tốt hơn cho automated backend deployments.\nGiải pháp: Triển khai SSH-less deployment sử dụng AWS Systems Manager (SSM) Run Command. Điều này cho phép CodeBuild thực thi deployment scripts trên EC2 instances mà không cần SSH keys. Cách tiếp cận thay thế sử dụng CodeDeploy cũng được khám phá cho các kịch bản deployment phức tạp hơn.\nKhó khăn 6: CloudWatch Alarms Không Kích Hoạt Vấn đề: Tạo CloudWatch alarms nhưng không nhận được notifications. Ban đầu, alarm threshold quá cao, và SNS topic subscriptions không được cấu hình đúng.\nGiải pháp:\nĐiều chỉnh alarm thresholds dựa trên metrics thực tế của application (CPU \u0026gt;80% trong 5 phút, RDS connections \u0026gt;80% của max). Xác minh SNS topic subscriptions (email confirmation là bắt buộc). Kiểm tra alarms bằng cách manually trigger conditions để đảm bảo notification flow hoạt động đúng. Khó khăn 7: Xác thực Cognito JWT Token trong API Gateway Vấn đề: Sau khi thiết lập Cognito User Pool và Authorizer trong API Gateway, các API calls với JWT tokens bị từ chối với lỗi 401 Unauthorized.\nGiải pháp:\nXác minh JWT token format và expiration. Kiểm tra Cognito User Pool App Client settings (allowed OAuth flows, callback URLs). Đảm bảo API Gateway Authorizer được cấu hình đúng với Cognito User Pool ARN. Kiểm tra token generation và validation flow từng bước. Khó khăn 8: Vấn đề Launch Template của Auto Scaling Group Vấn đề: Auto Scaling Group không thể launch instances. Launch Template tham chiếu đến AMI không có sẵn trong target Availability Zone.\nGiải pháp:\nTạo base AMI trong cùng region và Availability Zone với Auto Scaling Group. Xác minh cấu hình Launch Template (instance type, security groups, IAM role, user data). Kiểm tra Launch Template manually trước khi sử dụng trong Auto Scaling Group. Đảm bảo tất cả resources cần thiết (Security Groups, IAM roles) tồn tại trước khi tạo ASG. Khó khăn 9: Tối ưu hóa Chi phí VPC Flow Logs Vấn đề: VPC Flow Logs tạo ra lượng dữ liệu lớn, dẫn đến chi phí CloudWatch Logs cao.\nGiải pháp:\nCấu hình log retention policies (7 ngày cho detailed logs, 30 ngày cho aggregated logs). Sử dụng S3 làm destination cho long-term log storage (hiệu quả về chi phí hơn CloudWatch Logs). Triển khai log filtering để capture chỉ các traffic patterns liên quan. Thiết lập lifecycle policies trên S3 để chuyển logs sang storage classes rẻ hơn. Khó khăn 10: Độ phức tạp của End-to-End Testing Vấn đề: Kiểm tra luồng hoàn chỉnh từ Route 53 → CloudFront → WAF → API Gateway → EC2 → RDS là phức tạp, và các vấn đề khó cô lập.\nGiải pháp:\nTriển khai comprehensive logging ở mỗi layer (CloudFront access logs, API Gateway logs, EC2 application logs, RDS slow query logs). Sử dụng CloudWatch dashboards để visualize toàn bộ request flow. Tạo test scripts để validate từng component độc lập trước khi end-to-end testing. Tài liệu hóa troubleshooting procedures cho các vấn đề phổ biến ở mỗi layer. Những bài học quan trọng Infrastructure as Code (IaC): Học được tầm quan trọng của việc sử dụng CloudFormation cho reproducible infrastructure deployments.\nSecurity Best Practices: Triển khai least-privilege IAM policies, network segmentation, và secure credential management với Secrets Manager.\nMonitoring và Observability: Thiết lập monitoring toàn diện với CloudWatch, CloudTrail, và VPC Flow Logs cho security và performance insights.\nCI/CD Automation: Automated deployment pipelines giảm lỗi thủ công và cải thiện tốc độ deployment.\nCost Optimization: Học cách cân bằng performance, security, và chi phí thông qua proper resource sizing, caching strategies, và log retention policies.\nKết luận Hành trình 12 tuần này cung cấp kinh nghiệm thực hành với nhiều AWS services và best practices. Dự án cuối cùng thể hiện một kiến trúc production-ready với security, monitoring, automation, và scalability phù hợp. Các thách thức gặp phải và giải quyết trong giai đoạn này đã tăng cường đáng kể hiểu biết của tôi về cloud architecture và AWS services.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Hiểu rõ khái niệm và cấu trúc của VPC (CIDR, Subnet, Route Table, ENI). Nắm được cách cấu hình tường lửa trong VPC (NACL, Security Group). Làm quen với các dịch vụ kết nối mạng: VPN, Direct Connect. Tìm hiểu và thực hành Load Balancer. Triển khai thực hành các thành phần cơ bản: VPC, Subnet, Route Table, IGW, EBS, Elastic IP. Biết cách kết nối và remote vào EC2 bằng SSH. Làm quen với Hybrid DNS bằng Route 53 Resolver. Thực hành kết nối nhiều VPC với nhau bằng VPC Peering. Triển khai AWS Transit Gateway để quản lý kết nối giữa nhiều VPC. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học lý thuyết\n- Thế nào là VPC, cách tối ưu hóa thuê các dịch vụ cloud 15/09/2025 15/09/2025 AWS VPC Documentation 3 - Tìm hiểu về VPC\n+ Subnet, CIDR + Route table + ENI (Elastic Network Interface) 16/09/2025 16/09/2025 YouTube - AWS VPC 4 - Cấu hình tường lửa VPC: NACL, Security Group\n- VPN, Direct Connect\n- Load Balancer\n- Extra Resources 17/09/2025 17/09/2025 YouTube - AWS Security 5 - Thực hành: + VPC + Subnet\n+ Route Table\n+ IGW\n+ EBS\n+ \u0026hellip;\n- Các cách remote SSH vào EC2\n- Tìm hiểu Elastic IP 18/09/2025 18/09/2025 AWS Study Group - 000003 6 - Thực hành: + Set up Hybrid DNS với Route 53 Resolver 19/09/2025 19/09/2025 AWS Study Group - 000010 7 - Thực hành: + Set up VPC Peering 19/09/2025 19/09/2025 AWS Study Group - 000019 8 - Thực hành: + Set up AWS Transit Gateway 19/09/2025 19/09/2025 AWS Study Group - 000020 Kết quả đạt được tuần 2: Hiểu rõ kiến trúc Amazon VPC, cách các thành phần như Subnet, CIDR, Route Table và ENI kết hợp với nhau để tạo nên một mạng bảo mật và có khả năng mở rộng. Biết cách thiết kế và áp dụng chính sách bảo mật mạng thông qua Security Group và Network ACL, nắm được tình huống thực tế khi nên dùng từng loại. Tìm hiểu các dịch vụ mạng của AWS như VPN và Direct Connect, từ đó nắm được giải pháp kết nối hybrid cloud trong môi trường doanh nghiệp. Thực hành triển khai các thành phần cốt lõi: tạo VPC, Subnet, cấu hình Route Table, Internet Gateway, gắn EBS và cấp phát Elastic IP. Củng cố kỹ năng thao tác với EC2 thông qua SSH, hiểu rõ hơn về key pair và quản lý truy cập an toàn. Thực hành các kịch bản nâng cao như Hybrid DNS với Route 53 Resolver để mở rộng khả năng phân giải tên trong môi trường hybrid. Thiết lập kết nối giữa các VPC thông qua VPC Peering và kiểm thử giao tiếp giữa tài nguyên thuộc các mạng khác nhau. Triển khai AWS Transit Gateway để tập trung và đơn giản hóa quản lý kết nối mạng nhiều VPC, củng cố kiến thức về kiến trúc mạng có khả năng mở rộng. Kết luận: Sau tuần 2, tôi không chỉ nắm vững lý thuyết về VPC và các dịch vụ mạng mà còn có nhiều trải nghiệm thực hành, đủ tự tin thiết kế và quản lý hạ tầng mạng trên AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;Kick-off AWS First Cloud Journey Workforce OJT FALL 2025\u0026rdquo; Mục Đích Của Sự Kiện Chào mừng và khai mạc chương trình AWS First Cloud Journey Workforce OJT FALL 2025 Giới thiệu về chương trình và định hướng tương lai trong lĩnh vực Cloud Computing Chia sẻ kinh nghiệm từ các alumni và chuyên gia trong ngành Kết nối sinh viên với cộng đồng AWS và các doanh nghiệp đối tác Truyền cảm hứng và động lực cho hành trình học tập và phát triển sự nghiệp Chi Tiết Sự Kiện Ngày: Thứ Bảy, 06 tháng 9 năm 2025 Thời gian: 8:30 – 12:00 Địa điểm: Tầng 26, Tòa nhà Bitexco Financial Tower, số 2 Hải Triều, P. Bến Nghé, Quận 1, TP.HCM Thời lượng: 3.5 giờ (bao gồm tea break và networking) Về Chương trình AWS First Cloud Journey Workforce Khởi động từ năm 2021, chương trình đã đồng hành cùng hơn 2,000 sinh viên trên khắp cả nước.\nHơn 150 học viên đã được đào tạo chuyên sâu và hiện đang làm việc tại các công ty công nghệ hàng đầu Việt Nam và quốc tế.\nMục tiêu chính:\nXây dựng thế hệ AWS Builders chất lượng cao cho Việt Nam Trang bị kỹ năng thực chiến về Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics Kết nối sinh viên với cộng đồng AWS Study Group 47,000+ thành viên và các doanh nghiệp đối tác AWS Chương trình không chỉ là đào tạo công nghệ, mà còn là cầu nối quan trọng giữa tri thức – công nghệ – sự nghiệp, giúp sinh viên tự tin hòa nhập vào thế giới công nghệ hiện đại và hội nhập quốc tế.\nChương Trình 8:30 – 9:00 | Đón tiếp \u0026amp; Check-in Networking \u0026amp; chụp hình lưu niệm Đăng ký và nhận tài liệu Gặp gỡ các bạn sinh viên cùng khóa 9:00 – 9:15 | Khai mạc \u0026amp; Chào mừng Đại diện Nhà trường: Thầy Nguyễn Trần Phước Bảo – Trưởng phòng Quan hệ Doanh nghiệp (QHDN)\nPhát biểu khai mạc chương trình Giới thiệu về AWS First Cloud Journey Workforce Định hướng và kỳ vọng cho khóa học Tham dự cùng 2–3 anh/chị thuộc Phòng QHDN Keynote \u0026amp; Industry Sharing 9:15 – 9:40 | AWS First Cloud Journey \u0026amp; Định hướng Tương lai (25 phút) Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam\nGiới thiệu về AWS First Cloud Journey Tầm nhìn và định hướng tương lai của chương trình Cơ hội nghề nghiệp trong lĩnh vực Cloud Computing Lộ trình phát triển sự nghiệp với AWS Q\u0026amp;A 9:40 – 10:05 | DevOps \u0026amp; Sự nghiệp tương lai (25 phút) Đỗ Huy Thắng – DevOps Lead, VNG\nDevOps là gì và tại sao quan trọng Sự nghiệp trong lĩnh vực DevOps Kỹ năng cần thiết và cách phát triển Kinh nghiệm thực tế từ VNG Q\u0026amp;A 10:05 – 10:20 | Tea Break \u0026amp; Networking (15 phút) Nghỉ giải lao Networking với các speakers và participants Chụp ảnh lưu niệm Alumni \u0026amp; Career Sharing 10:20 – 10:40 | Từ First Cloud Journey đến GenAI Engineer (20 phút) Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova\nHành trình từ First Cloud Journey đến GenAI Engineer Kinh nghiệm học tập và phát triển Cơ hội trong lĩnh vực AI/ML Lời khuyên cho các bạn sinh viên mới Q\u0026amp;A 10:40 – 11:00 | She in Tech \u0026amp; Hành trình cùng First Cloud Journey (20 phút) Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne\nHành trình của phụ nữ trong công nghệ Kinh nghiệm tham gia First Cloud Journey Thách thức và cơ hội Lời khuyên cho các bạn nữ muốn theo đuổi sự nghiệp tech Q\u0026amp;A 11:00 – 11:20 | Một ngày làm Cloud Engineer (20 phút) Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific\nMột ngày làm việc của Cloud Engineer Công việc thực tế và trách nhiệm Kỹ năng và công cụ sử dụng hàng ngày Challenges và cách giải quyết Q\u0026amp;A 11:20 – 11:40 | Hành trình đến với First Cloud Journey (20 phút) Nguyễn Đồng Thanh Hiệp – Principal Cloud Engineer, G-Asia Pacific\nHành trình cá nhân đến với First Cloud Journey Bài học và kinh nghiệm quý giá Lộ trình phát triển từ junior đến principal engineer Lời khuyên cho các bạn mới bắt đầu Q\u0026amp;A 11:40 – 12:00 | Q\u0026amp;A \u0026amp; Tổng kết (20 phút) Giải đáp thắc mắc từ speakers \u0026amp; mentors Tổng kết nội dung chính của sự kiện Thông tin về các bước tiếp theo trong chương trình Chụp ảnh lưu niệm 📸 Meet Our Speakers Nguyễn Gia Hưng Head of Solutions Architect, AWS Vietnam\nChuyên gia hàng đầu về AWS architecture và solutions Kinh nghiệm sâu rộng trong việc tư vấn và triển khai giải pháp cloud Người dẫn dắt chương trình AWS First Cloud Journey tại Việt Nam Đỗ Huy Thắng DevOps Lead, VNG\nChuyên gia về DevOps practices và automation Kinh nghiệm trong việc xây dựng và vận hành hệ thống quy mô lớn Mentor cho nhiều thế hệ DevOps engineers Danh Hoàng Hiếu Nghị GenAI Engineer, Renova\nAlumni của chương trình First Cloud Journey Chuyên gia về Generative AI và Machine Learning Kinh nghiệm trong việc phát triển AI solutions Bùi Hồ Linh Nhi AI Engineer, SoftwareOne\nAlumni của chương trình First Cloud Journey Chuyên gia về AI/ML engineering Người truyền cảm hứng cho phụ nữ trong công nghệ Phạm Nguyễn Hải Anh Cloud Engineer, G-Asia Pacific\nChuyên gia về cloud infrastructure và operations Kinh nghiệm thực tế trong việc quản lý và vận hành cloud systems Mentor cho các cloud engineers mới vào nghề Nguyễn Đồng Thanh Hiệp Principal Cloud Engineer, G-Asia Pacific\nAlumni của chương trình First Cloud Journey Chuyên gia về cloud architecture và best practices Kinh nghiệm từ junior đến principal level Nội Dung Nổi Bật AWS First Cloud Journey Program Giới thiệu chương trình:\nChương trình đào tạo thực hành (OJT) về AWS Cloud Computing Đã đồng hành cùng hơn 2,000 sinh viên từ năm 2021 Hơn 150 học viên đã được đào tạo chuyên sâu và làm việc tại các công ty hàng đầu Mục tiêu:\nXây dựng thế hệ AWS Builders chất lượng cao Trang bị kỹ năng thực chiến về Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics Kết nối với cộng đồng AWS Study Group 47,000+ thành viên Lợi ích:\nĐào tạo chuyên sâu với các chuyên gia AWS Cơ hội thực hành với môi trường AWS thực tế Kết nối với các doanh nghiệp đối tác Hỗ trợ phát triển sự nghiệp Career Pathways in Cloud Computing DevOps Career:\nDevOps là gì và vai trò trong tổ chức Kỹ năng cần thiết: CI/CD, Infrastructure as Code, Monitoring Lộ trình phát triển: Junior → Mid → Senior → Lead Cơ hội nghề nghiệp và mức lương Cloud Engineer Career:\nCông việc hàng ngày của Cloud Engineer Kỹ năng technical và soft skills Challenges và cách giải quyết Growth opportunities AI/ML Engineer Career:\nTừ Cloud Engineer đến AI/ML Engineer Kỹ năng cần thiết cho AI/ML Cơ hội trong lĩnh vực Generative AI Future trends và opportunities Alumni Success Stories Từ First Cloud Journey đến thành công:\nHành trình của các alumni Bài học và kinh nghiệm quý giá Challenges và cách vượt qua Lời khuyên cho các bạn mới Diversity in Tech:\nHành trình của phụ nữ trong công nghệ Thách thức và cơ hội Support và resources available Inspiration và motivation Những Gì Học Được Hiểu về AWS First Cloud Journey Chương trình là gì: OJT program về AWS Cloud Computing Mục tiêu và lợi ích: Xây dựng kỹ năng thực chiến và kết nối với cộng đồng Lộ trình học tập: Các giai đoạn và milestones trong chương trình Cơ hội nghề nghiệp: Kết nối với các doanh nghiệp đối tác Career Pathways DevOps: Hiểu về sự nghiệp DevOps và kỹ năng cần thiết Cloud Engineer: Công việc thực tế và trách nhiệm AI/ML Engineer: Lộ trình phát triển trong lĩnh vực AI/ML Career progression: Từ junior đến senior và principal level Real-world Insights Alumni experiences: Hành trình và bài học từ các alumni Day-to-day work: Công việc thực tế của các roles khác nhau Challenges: Thách thức và cách giải quyết Best practices: Lời khuyên và tips từ experts Networking and Community AWS Study Group: Cộng đồng 47,000+ thành viên Mentorship: Cơ hội được mentor từ các chuyên gia Peer learning: Học hỏi từ các bạn cùng khóa Industry connections: Kết nối với các doanh nghiệp Ứng Dụng Vào Công Việc Đặt mục tiêu rõ ràng: Xác định career path muốn theo đuổi Xây dựng kỹ năng: Focus vào các kỹ năng cần thiết cho career path đã chọn Thực hành thường xuyên: Tận dụng môi trường AWS để practice Kết nối và networking: Tham gia cộng đồng và kết nối với mentors Học từ alumni: Áp dụng lessons learned từ các alumni thành công Phát triển soft skills: Không chỉ technical skills mà còn communication, teamwork Trải nghiệm trong event Tham gia sự kiện Kick-off AWS First Cloud Journey Workforce OJT FALL 2025 là một trải nghiệm đầy cảm hứng và động lực. Sự kiện không chỉ cung cấp thông tin về chương trình mà còn truyền cảm hứng cho hành trình học tập và phát triển sự nghiệp trong lĩnh vực Cloud Computing.\nKhai mạc và chào mừng Phát biểu khai mạc của Thầy Nguyễn Trần Phước Bảo tạo không khí trang trọng và chuyên nghiệp. Em hiểu rõ về mục tiêu và kỳ vọng của chương trình. Giới thiệu về First Cloud Journey giúp em hình dung rõ về hành trình sắp tới. Keynote từ AWS Session của Nguyễn Gia Hưng cung cấp tầm nhìn tổng thể về AWS First Cloud Journey. Hiểu về định hướng tương lai và cơ hội nghề nghiệp trong Cloud Computing. Lộ trình phát triển sự nghiệp cho em roadmap rõ ràng để follow. Industry Insights DevOps session của Đỗ Huy Thắng cho em hiểu về sự nghiệp DevOps. Học về kỹ năng cần thiết và cách phát triển trong lĩnh vực này. Real-world examples từ VNG giúp em hình dung công việc thực tế. Alumni Success Stories Hành trình của Danh Hoàng Hiếu Nghị từ First Cloud Journey đến GenAI Engineer rất inspiring. Em học được về persistence và continuous learning. Session của Bùi Hồ Linh Nhi về She in Tech rất empowering. Hiểu về challenges và opportunities cho phụ nữ trong tech. Day-to-day Work Insights Session của Phạm Nguyễn Hải Anh về một ngày làm Cloud Engineer rất practical. Em hiểu về công việc thực tế và trách nhiệm của Cloud Engineer. Hành trình của Nguyễn Đồng Thanh Hiệp từ junior đến principal rất motivating. Học được về career progression và growth mindset. Networking và kết nối Networking sessions cho phép em kết nối với các speakers và participants. Chia sẻ experiences và learnings với các bạn cùng khóa. Q\u0026amp;A sessions cung cấp cơ hội để hỏi specific questions. Gặp gỡ các alumni và nhận advice về career development. Bài học rút ra First Cloud Journey là cơ hội tuyệt vời: Chương trình cung cấp foundation vững chắc cho sự nghiệp cloud. Career paths đa dạng: Có nhiều con đường phát triển trong cloud computing. Continuous learning là key: Cần học hỏi liên tục để phát triển. Networking matters: Kết nối với cộng đồng và mentors rất quan trọng. Diversity và inclusion: Tech industry đang trở nên inclusive hơn. Set clear goals: Cần có mục tiêu rõ ràng và plan để achieve. Một số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện Kick-off này là một khởi đầu tuyệt vời cho hành trình AWS First Cloud Journey. Sự kết hợp giữa thông tin về chương trình, career insights, và alumni success stories cho em động lực và định hướng rõ ràng. Đặc biệt, networking với các speakers, alumni, và participants cung cấp connections và support có giá trị cho hành trình học tập và phát triển sự nghiệp của em trong lĩnh vực Cloud Computing.\nLời kết Sự kiện Kick-off hôm nay chính là bước khởi đầu cho hành trình AWS Builders – nơi các bạn sinh viên không chỉ tiếp cận công nghệ điện toán đám mây tiên tiến nhất, mà còn được truyền cảm hứng, kết nối cùng chuyên gia và mở rộng cơ hội nghề nghiệp.\nMột lần nữa, xin chúc mừng các bạn sinh viên đã chính thức trở thành một phần của AWS First Cloud Journey Workforce OJT FALL 2025. Hãy cùng nhau khởi động hành trình mới – hành trình của sự học hỏi, xây dựng và phát triển, để đưa công nghệ điện toán đám mây tại Việt Nam vươn xa! 🚀\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.2-prerequisite/","title":"Chuẩn bị &amp; Yêu cầu","tags":[],"description":"","content":"Yêu cầu Hệ thống 1. Tài khoản AWS Tài khoản AWS đang hoạt động Quyền Administrator hoặc các quyền sau: CloudFormation: Full access EC2: Full access VPC: Full access RDS: Full access S3: Full access CloudFront: Full access IAM: Create roles and policies CloudWatch: Full access 2. AWS CLI Cài đặt và cấu hình AWS CLI:\nWindows:\n# Download và cài đặt từ: https://aws.amazon.com/cli/ # Hoặc sử dụng chocolatey: choco install awscli # Kiểm tra cài đặt aws --version Linux/Mac:\n# Sử dụng pip pip install awscli # Hoặc sử dụng package manager # Ubuntu/Debian sudo apt-get install awscli # MacOS brew install awscli # Kiểm tra cài đặt aws --version Cấu hình AWS CLI:\naws configure # AWS Access Key ID: \u0026lt;your-access-key\u0026gt; # AWS Secret Access Key: \u0026lt;your-secret-key\u0026gt; # Default region name: ap-southeast-1 # Default output format: json 3. EC2 Key Pair Tạo EC2 Key Pair để SSH vào instances:\nQua AWS Console:\nMở EC2 Console Chọn region ap-southeast-1 (Singapore) Vào Network \u0026amp; Security → Key Pairs Click Create key pair Nhập tên: workshop-aws-key Key pair type: RSA Private key file format: .pem (Linux/Mac) hoặc .ppk (Windows/PuTTY) Click Create key pair Lưu file .pem vào thư mục an toàn Qua AWS CLI:\n# Tạo key pair aws ec2 create-key-pair \\ --key-name workshop-aws-key \\ --query \u0026#39;KeyMaterial\u0026#39; \\ --output text \\ --region ap-southeast-1 \u0026gt; workshop-aws-key.pem # Set permissions (Linux/Mac only) chmod 400 workshop-aws-key.pem 4. Development Tools Java Development Kit (JDK) 17:\n# Windows (chocolatey) choco install openjdk17 # Linux (Ubuntu/Debian) sudo apt-get install openjdk-17-jdk # MacOS brew install openjdk@17 # Kiểm tra java -version Maven:\n# Windows choco install maven # Linux sudo apt-get install maven # MacOS brew install maven # Kiểm tra mvn -version Node.js và npm:\n# Windows choco install nodejs # Linux curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - sudo apt-get install -y nodejs # MacOS brew install node # Kiểm tra node --version npm --version Chuẩn bị Project Files 1. Clone hoặc Download Project # Nếu có Git repository git clone \u0026lt;your-repo-url\u0026gt; cd aws_project # Hoặc download và extract ZIP file 2. Cấu trúc Project aws_project/\r├── aws/\r│ ├── infrastructure.yaml # CloudFormation template chính\r│ ├── cicd-pipeline.yaml # CI/CD pipeline (optional)\r│ ├── parameters.json # Parameters cho stack\r│ ├── deploy.bat # Deploy script (Windows)\r│ ├── deploy.sh # Deploy script (Linux/Mac)\r│ └── README.md # Hướng dẫn chi tiết\r├── BE/\r│ └── workshop_BE/\r│ ├── src/ # Backend source code\r│ ├── pom.xml # Maven configuration\r│ └── README.md\r└── FE/\r├── src/ # Frontend source code\r├── package.json # npm dependencies\r└── README.md 3. Cấu hình Parameters Mở file aws/parameters.json và cập nhật các giá trị:\n[ { \u0026#34;ParameterKey\u0026#34;: \u0026#34;ProjectName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;workshop-aws\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;dev\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;KeyPairName\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;workshop-aws-key\u0026#34; // ⚠️ Thay bằng tên key pair của bạn }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;DBPassword\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;YourStrongPassword123!\u0026#34; // ⚠️ Đổi mật khẩu mạnh }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;InstanceType\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;t3.micro\u0026#34; }, { \u0026#34;ParameterKey\u0026#34;: \u0026#34;DBInstanceClass\u0026#34;, \u0026#34;ParameterValue\u0026#34;: \u0026#34;db.t3.micro\u0026#34; } ] Lưu ý quan trọng:\nKeyPairName: Phải khớp với tên key pair đã tạo DBPassword: Tối thiểu 8 ký tự, bao gồm chữ hoa, chữ thường, số và ký tự đặc biệt Không commit file này với mật khẩu thật vào Git 4. Cập nhật AMI ID CloudFormation template sử dụng AMI ID mặc định. Bạn cần cập nhật cho region của mình:\nTìm AMI ID:\n# Tìm Amazon Linux 2023 AMI cho region ap-southeast-1 aws ec2 describe-images \\ --owners amazon \\ --filters \u0026#34;Name=name,Values=al2023-ami-*-x86_64\u0026#34; \\ --query \u0026#39;Images | sort_by(@, \u0026amp;CreationDate) | [-1].[ImageId,Name,CreationDate]\u0026#39; \\ --region ap-southeast-1 \\ --output table Cập nhật trong infrastructure.yaml:\nTìm dòng ~530:\nLaunchTemplate: Properties: LaunchTemplateData: ImageId: ami-0c55b159cbfafe1f0 # ⚠️ Thay bằng AMI ID của bạn Kiểm tra Chuẩn bị Checklist Đảm bảo bạn đã hoàn thành tất cả các bước sau:\nTài khoản AWS đã được cấu hình AWS CLI đã cài đặt và cấu hình (aws configure) EC2 Key Pair đã được tạo Java 17 đã cài đặt Maven đã cài đặt Node.js và npm đã cài đặt Project files đã được download File parameters.json đã được cập nhật AMI ID đã được cập nhật trong infrastructure.yaml Validate AWS Credentials # Kiểm tra AWS credentials aws sts get-caller-identity # Kết quả mong đợi: # { # \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, # \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, # \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/your-username\u0026#34; # } Validate CloudFormation Template cd aws aws cloudformation validate-template \\ --template-body file://infrastructure.yaml \\ --region ap-southeast-1 Nếu thành công, bạn sẽ thấy output với thông tin về template parameters và outputs.\nƯớc tính Chi phí Trước khi triển khai, hãy hiểu rõ chi phí:\nDịch vụ Instance Type Chi phí/tháng (USD) EC2 t3.nano $3.50 RDS MySQL db.t3.micro $2.80 API Gateway - $0.50 S3 + CloudFront - $0.80 Route 53 - $0.50 Cognito - $0.10 CloudWatch - $0.30 CI/CD (CodePipeline) - $0.40 Tổng $8.90 Cho workshop (2-3 giờ): ~$0.50-1.00\nLưu ý:\nChi phí trên áp dụng cho region ap-southeast-1 Sử dụng AWS Free Tier nếu tài khoản đủ điều kiện NAT Gateway (~$32/tháng) có thể tắt để tiết kiệm chi phí Tiếp theo Sau khi hoàn thành tất cả các bước chuẩn bị, bạn đã sẵn sàng để:\n➡️ Triển khai Infrastructure với CloudFormation\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Trình bày dự án của nhóm trước các mentors và supervisors.\nThu thập phản hồi để cải thiện về kiến trúc, triển khai và chất lượng trình bày.\nXác định các lĩnh vực cần điều chỉnh trước khi nộp báo cáo cuối cùng.\nGhi chép tất cả các nhận xét và action items cho sprint tiếp theo.\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài nguyên sử dụng 2 - Chuẩn bị slide deck cuối cùng - Rà soát vai trò trình bày cho từng thành viên 24/11/2025 24/11/2025 Slide deck 3 - Tiến hành buổi diễn tập nội bộ - Điều chỉnh thời gian và chuyển tiếp giữa các người trình bày 25/11/2025 25/11/2025 Ghi chú nội bộ 4 - Trình bày dự án chính thức trước mentors - Trình bày kiến trúc hệ thống, CI/CD pipeline, ước tính chi phí và demo 26/11/2025 26/11/2025 Tài liệu trình bày 5 - Nhận phản hồi từ mentors về thiết kế kỹ thuật, cân nhắc bảo mật và cách tiếp cận triển khai - Ghi chép tất cả nhận xét để theo dõi 27/11/2025 27/11/2025 Phản hồi từ mentors 6 - Phân tích phản hồi đã nhận - Xác định các cải thiện cần thiết cho kiến trúc, sơ đồ và độ rõ ràng của slide 28/11/2025 28/11/2025 Phản hồi tổng hợp 7 - Cập nhật tài liệu và điều chỉnh slide deck theo nhận xét của mentors - Chuẩn bị kế hoạch hành động tiếp theo cho tuần sau 29–30/11/2025 30/11/2025 Proposal, Slide deck Kết quả đạt được tuần 12: Trình bày dự án thành công trước mentors và nhận được phản hồi chi tiết về kiến trúc, triển khai và chất lượng trình bày.\nGhi chép tất cả các nhận xét liên quan đến:\nCải thiện kiến trúc hệ thống\nLàm rõ luồng dữ liệu và các lớp mạng\nGiải thích CI/CD pipeline\nĐề xuất tối ưu hóa chi phí\nCân nhắc về bảo mật\nCải thiện slide deck và tài liệu dự án dựa trên khuyến nghị của mentors.\nXác định các action items quan trọng để tinh chỉnh trước khi nộp báo cáo cuối cùng.\nHoàn thành diễn tập và trình bày presentation giữa kỳ theo kế hoạch.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Trong phần này, bạn cần tóm tắt các nội dung của workshop mà bạn dự định sẽ thực hiện.\nHệ thống Hỗ trợ Hiến máu Giải pháp AWS cho Phần mềm Hỗ trợ Hiến máu 1. Tóm tắt điều hành Hệ thống Hỗ trợ Hiến máu (BDSS) là một nền tảng web hỗ trợ quản lý và kết nối người hiến máu với các cơ sở y tế. Dự án được phát triển bởi một nhóm sinh viên tại Thành phố Hồ Chí Minh nhằm tối ưu hóa quy trình hiến máu, giảm gánh nặng tìm kiếm người hiến máu và cải thiện hiệu quả giao tiếp y tế.\nHệ thống được xây dựng trên kiến trúc AWS Cloud, sử dụng Amazon EC2, Amazon RDS, API Gateway, Cognito và CI/CD Pipeline (GitLab + CodePipeline) để triển khai tự động. BDSS hỗ trợ bốn nhóm người dùng (Guest, Member, Staff, Admin), cung cấp các tính năng tìm kiếm, đăng ký hiến máu, quản lý ngân hàng máu, theo dõi quy trình hiến máu và báo cáo trực quan.\n2. Tuyên bố vấn đề Vấn đề là gì? Các cơ sở y tế hiện đang quản lý quy trình hiến máu thủ công hoặc thông qua các công cụ rời rạc. Việc tìm kiếm người hiến máu phù hợp về nhóm máu hoặc khu vực là khó khăn, đặc biệt trong các tình huống khẩn cấp. Ngoài ra, các hệ thống lưu trữ dữ liệu không được đồng bộ hóa, gây khó khăn cho việc phân tích, báo cáo và tối ưu hóa các chiến dịch hiến máu.\nGiải pháp Phát triển một nền tảng hỗ trợ hiến máu toàn diện trên AWS Cloud, với các chức năng quản lý hiến máu, tìm kiếm người hiến máu và người cần máu theo nhóm máu hoặc vị trí địa lý, tích hợp xác thực người dùng qua Amazon Cognito, và quản trị dữ liệu trên Amazon RDS. Frontend được triển khai qua Route 53 + CloudFront, backend qua API Gateway – EC2, cơ sở dữ liệu MySQL trên Amazon RDS, và pipeline CI/CD tự động sử dụng GitLab – CodePipeline.\nLợi ích và Hoàn vốn đầu tư Giảm 60–70% thời gian tìm kiếm người hiến máu phù hợp. Tăng độ chính xác của thông tin nhóm máu và vị trí. Tối ưu hóa chi phí vận hành với kiến trúc cloud linh hoạt, trả tiền theo sử dụng. Cải thiện phản ứng với các tình huống khẩn cấp về máu\n3. Kiến trúc giải pháp Nền tảng sử dụng kiến trúc AWS cloud toàn diện để hỗ trợ quản lý hiến máu, kết nối người hiến máu với các cơ sở y tế một cách hiệu quả. Hệ thống tích hợp nhiều dịch vụ AWS để cung cấp một giải pháp có thể mở rộng, bảo mật và tiết kiệm chi phí. Kiến trúc được mô tả chi tiết dưới đây:\nHệ thống được chia thành 4 lớp chính:\nLớp Edge Networking: Route 53 quản lý domain và định tuyến DNS. CloudFront tăng tốc độ tải trang và phân phối nội dung tĩnh. AWS WAF bảo vệ chống lại các cuộc tấn công web (SQL injection, DDoS).\nLớp Ứng dụng \u0026amp; Dữ liệu: Amazon EC2: Triển khai backend API và xử lý nghiệp vụ chính. Amazon RDS (MySQL): Lưu trữ dữ liệu người hiến máu, nhóm máu, lịch sử hiến máu. API Gateway: Giao tiếp giữa frontend và backend. Elastic Load Balancer (ELB): Phân phối tải đến các EC2 instances. NAT Gateway \u0026amp; Internet Gateway: Hỗ trợ kết nối Internet an toàn.\nLớp CI/CD \u0026amp; DevOps: GitLab: Quản lý mã nguồn. AWS CodePipeline, CodeBuild: Triển khai và cập nhật tự động.\nLớp Giám sát \u0026amp; Bảo mật: Amazon Cognito: Xác thực và phân quyền (Guest, Member, Staff, Admin). CloudWatch, CloudTrail, IAM, Secrets Manager: Giám sát, bảo mật, cảnh báo hệ thống. SNS: Gửi thông báo khi có sự kiện (khẩn cấp về máu, người hiến máu phù hợp).\n4. Triển khai kỹ thuật Các giai đoạn triển khai\nPhân tích \u0026amp; Thiết kế (Tháng 1) Thu thập yêu cầu, định nghĩa use cases, thiết kế ERD và kiến trúc AWS. Thiết lập Hạ tầng \u0026amp; Pipeline (Tháng 2) Cấu hình Route 53, CloudFront, EC2, RDS và CI/CD trên AWS. Phát triển \u0026amp; Kiểm thử (Tháng 3-4) Xây dựng các module chính: đăng ký hiến máu, tìm kiếm, quản lý ngân hàng máu. Tích hợp Cognito và hệ thống cảnh báo SNS. Triển khai \u0026amp; Vận hành (Tháng 5) Triển khai sản phẩm chính thức và giám sát với CloudWatch. Yêu cầu kỹ thuật chính: Frontend: React/Next.js hoặc Angular (triển khai qua S3/CloudFront). Backend: Spring Boot trên EC2, giao tiếp qua REST API Gateway. Database: Amazon RDS MySQL, tối ưu query và backup định kỳ. CI/CD: GitLab → CodeBuild → CodePipeline → EC2. Auth: Cognito (4 vai trò: Guest, Member, Staff, Admin). Alert \u0026amp; Logs: SNS + CloudWatch + CloudTrail.\n5. Lộ trình \u0026amp; Mốc triển khai Lộ trình Giai đoạn Kết quả chính Tháng 1 Phân tích yêu cầu \u0026amp; thiết kế Kiến trúc AWS + biểu đồ use case Tháng 2 Thiết lập hạ tầng \u0026amp; pipeline EC2, RDS, API Gateway hoạt động Tháng 3–4 Phát triển \u0026amp; kiểm thử Các module chính hoàn thiện Tháng 5 Triển khai live Hệ thống ổn định, có báo cáo Dashboard 6. Ước tính ngân sách Dịch vụ Chi phí ước tính/Tháng (USD) Ghi chú EC2 (t3.nano) 3.50 Backend REST API Amazon RDS (MySQL) 2.80 20 GB storage API Gateway 0.50 5,000 requests CloudFront + S3 0.80 Website + CDN Route 53 0.50 Domain \u0026amp; DNS Cognito 0.10 \u0026lt;100 users CloudWatch + Logs 0.30 Giám sát \u0026amp; Cảnh báo CI/CD (CodePipeline, CodeBuild) 0.40 Triển khai tự động Tổng 8.9 USD/tháng ~106.8 USD/năm Tổng chi phí có thể thay đổi dựa trên AWS Free Tier hoặc việc sử dụng spot instance.\n7. Đánh giá rủi ro Rủi ro Tác động Xác suất Giảm thiểu Mất kết nối Internet Trung bình Trung bình Dự phòng trên EC2 Backup Tấn công DDoS Cao Thấp AWS WAF + CloudFront Hư hỏng dữ liệu người dùng Cao Thấp RDS Backup + IAM Restricted Access Vượt quá chi phí Trung bình Thấp AWS Budget Alert Gián đoạn triển khai CI/CD Thấp Trung bình Kiểm thử Pipeline trước khi Merge 8. Kết quả kỳ vọng Công nghệ: Hệ thống cloud-native, CI/CD tự động, hỗ trợ đa người dùng và bảo mật cao. Ứng dụng: Giúp các cơ sở y tế quản lý hiến máu hiệu quả, tối thiểu hóa quy trình thủ công. Mở rộng: Có thể nhân rộng cho nhiều bệnh viện khác, tích hợp AI để phân tích nhu cầu nhóm máu hoặc dự đoán các đợt hiến máu sắp tới.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nCác bước:\nLựa chọn 2 mục acknowledgement Chọn Create stack Chờ CloudFormation deployment hoàn thành (khoảng 15 phút) Tài nguyên được tạo:\n2 VPCs 3 EC2 instances "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.3-deploy-infrastructure/","title":"Triển khai Infrastructure với CloudFormation","tags":[],"description":"","content":"Tổng quan Trong bước này, bạn sẽ triển khai toàn bộ hạ tầng AWS bằng CloudFormation template. Template sẽ tạo VPC, subnets, EC2 instances, RDS database, Load Balancer, S3 buckets, CloudFront distribution và tất cả các tài nguyên cần thiết.\nValidate Template Trước khi triển khai, validate template để đảm bảo không có lỗi cú pháp:\ncd aws aws cloudformation validate-template \\ --template-body file://infrastructure.yaml \\ --region ap-southeast-1 Kết quả mong đợi: Thông tin về parameters, outputs và description của template.\nTriển khai Stack Cách 1: Sử dụng Deploy Script (Khuyên dùng) Windows:\ncd aws deploy.bat create Linux/Mac:\ncd aws chmod +x deploy.sh ./deploy.sh create Script sẽ tự động:\nValidate template Create CloudFormation stack Theo dõi tiến trình deployment Hiển thị outputs khi hoàn thành Cách 2: Sử dụng AWS CLI aws cloudformation create-stack \\ --stack-name workshop-aws-dev \\ --template-body file://infrastructure.yaml \\ --parameters file://parameters.json \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 Theo dõi Tiến trình Qua AWS Console Mở CloudFormation Console Chọn stack workshop-aws-dev Tab Events: Xem các resources đang được tạo Tab Resources: Xem danh sách resources Tab Outputs: Xem outputs (sau khi hoàn thành) Qua AWS CLI # Kiểm tra status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Xem events aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --max-items 10 Thời gian Deployment Quá trình tạo stack mất khoảng 15-20 phút:\nVPC và Networking: 2-3 phút NAT Gateway: 2-3 phút RDS Database: 5-7 phút EC2 Auto Scaling Group: 3-5 phút Load Balancer: 2-3 phút CloudFront Distribution: 5-10 phút VPC Endpoints: 2-3 phút Xem Outputs Sau khi stack tạo thành công (Status: CREATE_COMPLETE), lấy outputs:\naws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs\u0026#39; \\ --output table Các Outputs quan trọng:\nOutput Key Mô tả Ví dụ VPCId VPC ID vpc-0123456789abcdef0 FrontendBucketName S3 bucket cho frontend workshop-aws-dev-frontend-123456789012-ap-southeast-1 CloudFrontDomainName CloudFront URL d1234567890abc.cloudfront.net ALBDNSName Load Balancer DNS workshop-aws-dev-alb-123456789.ap-southeast-1.elb.amazonaws.com RDSEndpoint Database endpoint workshop-aws-dev-db.xxxxx.ap-southeast-1.rds.amazonaws.com APIGatewayURL API Gateway URL https://xxxxx.execute-api.ap-southeast-1.amazonaws.com/dev CognitoUserPoolId Cognito User Pool ID ap-southeast-1_xxxxxxxxx Lưu các giá trị này - bạn sẽ cần chúng cho các bước tiếp theo!\nKiểm tra Resources đã tạo 1. VPC và Networking # Lấy VPC ID VPC_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`VPCId`].OutputValue\u0026#39; \\ --output text) # Xem VPC details aws ec2 describe-vpcs --vpc-ids $VPC_ID --region ap-southeast-1 # Xem Subnets aws ec2 describe-subnets \\ --filters \u0026#34;Name=vpc-id,Values=$VPC_ID\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Subnets[*].[SubnetId,CidrBlock,AvailabilityZone,Tags[?Key==`Name`].Value|[0]]\u0026#39; \\ --output table 2. EC2 Instances # Xem EC2 instances trong Auto Scaling Group aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name,PrivateIpAddress,PublicIpAddress]\u0026#39; \\ --output table 3. RDS Database # Xem RDS instance aws rds describe-db-instances \\ --db-instance-identifier workshop-aws-dev-db \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[0].[DBInstanceIdentifier,DBInstanceStatus,Endpoint.Address,Endpoint.Port]\u0026#39; \\ --output table 4. Load Balancer # Xem ALB aws elbv2 describe-load-balancers \\ --names workshop-aws-dev-alb \\ --region ap-southeast-1 \\ --query \u0026#39;LoadBalancers[0].[LoadBalancerName,DNSName,State.Code]\u0026#39; \\ --output table 5. S3 Buckets # List S3 buckets aws s3 ls | grep workshop-aws-dev 6. CloudFront Distribution # Lấy Distribution ID DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) # Xem distribution status aws cloudfront get-distribution --id $DIST_ID \\ --query \u0026#39;Distribution.[Id,Status,DomainName]\u0026#39; \\ --output table Troubleshooting Stack Creation Failed Nếu stack creation bị lỗi:\nXem Events để tìm lỗi: aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;StackEvents[?ResourceStatus==`CREATE_FAILED`].[LogicalResourceId,ResourceStatusReason]\u0026#39; \\ --output table Các lỗi thường gặp: Lỗi: \u0026ldquo;Key pair does not exist\u0026rdquo;\nKiểm tra tên key pair trong parameters.json Đảm bảo key pair tồn tại trong region ap-southeast-1 Lỗi: \u0026ldquo;Invalid AMI ID\u0026rdquo;\nCập nhật AMI ID trong infrastructure.yaml Sử dụng AMI ID phù hợp với region Lỗi: \u0026ldquo;Insufficient permissions\u0026rdquo;\nKiểm tra IAM permissions của user Cần quyền CloudFormation, EC2, VPC, RDS, S3, IAM Lỗi: \u0026ldquo;Resource limit exceeded\u0026rdquo;\nKiểm tra service quotas trong AWS account Request tăng limits nếu cần Rollback và thử lại: # Xóa stack bị lỗi aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 # Đợi stack bị xóa hoàn toàn aws cloudformation wait stack-delete-complete \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 # Thử tạo lại aws cloudformation create-stack \\ --stack-name workshop-aws-dev \\ --template-body file://infrastructure.yaml \\ --parameters file://parameters.json \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 Xác nhận Deployment thành công Checklist để xác nhận infrastructure đã sẵn sàng:\nStack status là CREATE_COMPLETE VPC và subnets đã được tạo EC2 instances đang chạy (State: running) RDS database status là available Load Balancer status là active S3 buckets đã được tạo CloudFront distribution status là Deployed Tất cả outputs đã có giá trị Tiếp theo Sau khi infrastructure đã sẵn sàng, bạn có thể:\n➡️ Cấu hình và Triển khai Backend Application\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Thực nghiệm ML nhanh cho doanh nghiệp với Amazon SageMaker AI và Comet Blog này giới thiệu cách tích hợp Amazon SageMaker AI với Comet để tăng tốc thực nghiệm machine learning cho doanh nghiệp. Bạn sẽ học cách quản lý các thực nghiệm ML, theo dõi dòng kế thừa mô hình (model lineage), và đảm bảo khả năng tái tạo kết quả (reproducibility) trong môi trường sản xuất. Bài viết minh họa một workflow phát hiện gian lận (fraud detection) hoàn chỉnh sử dụng SageMaker AI + Comet, thể hiện việc theo dõi thực nghiệm, so sánh mô hình, và logging sẵn sàng audit mà các doanh nghiệp hiện đại yêu cầu. Bài viết bao gồm cả hành trình của administrator và user, từ việc thiết lập Comet Partner AI App đến chạy các thực nghiệm và so sánh kết quả trong Comet UI.\nBlog 2 - Sử dụng workflow Apache Airflow để điều phối xử lý dữ liệu trên Amazon SageMaker Unified Studio Blog này minh họa cách sử dụng workflow Apache Airflow để điều phối các pipeline xử lý dữ liệu trên Amazon SageMaker Unified Studio. Bạn sẽ học cách xây dựng, kiểm thử và chạy các pipeline ML end-to-end sử dụng workflow của SageMaker thông qua giao diện Unified Studio. Bài viết đi qua một ví dụ thực tế bao gồm việc ingest dữ liệu thời tiết và taxi, chuyển đổi và gộp các dataset, sau đó sử dụng ML để dự đoán giá cước taxi - tất cả được điều phối thông qua workflow của SageMaker Unified Studio được hỗ trợ bởi Amazon Managed Workflows for Apache Airflow (Amazon MWAA). Bài viết tập trung vào cách tiếp cận dựa trên code sử dụng Python DAGs để quản lý workflow.\nBlog 3 - Di chuyển tìm kiếm toàn văn từ SQL Server sang Amazon Aurora PostgreSQL-Compatible Edition hoặc Amazon RDS for PostgreSQL Blog này hướng dẫn bạn cách di chuyển tìm kiếm toàn văn (full-text search) từ SQL Server sang Amazon Aurora PostgreSQL hoặc Amazon RDS for PostgreSQL. Bạn sẽ học cách di chuyển các truy vấn FTS và cấu trúc schema, vì cách triển khai khác nhau giữa hai hệ thống. Bài viết minh họa cách sử dụng các kiểu dữ liệu tsvector và tsquery của PostgreSQL để đạt được chức năng FTS tương tự, và cũng chỉ cách triển khai FTS bằng các extension pg_trgm và pg_bigm. Bài viết bao gồm các trường hợp sử dụng khác nhau như vị ngữ CONTAINS, truy vấn FREETEXT, xếp hạng với RANK, và các kỹ thuật tối ưu hiệu suất sử dụng chỉ mục GIN và các cột được tạo đã lưu trữ.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.4-deploy-backend/","title":"Triển khai Backend Application","tags":[],"description":"","content":"Tổng quan Trong bước này, bạn sẽ build và deploy ứng dụng Spring Boot backend lên EC2 instances. Backend cung cấp RESTful API cho DNA analysis, user authentication, và data management.\nBước 1: Cấu hình Database Connection Lấy RDS endpoint từ CloudFormation outputs:\nRDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;RDS Endpoint: $RDS_ENDPOINT\u0026#34; Cập nhật file BE/workshop_BE/src/main/resources/application.properties:\n# Database Configuration spring.datasource.url=jdbc:mysql://${RDS_ENDPOINT}:3306/workshop_aws?useSSL=true\u0026amp;requireSSL=false\u0026amp;allowPublicKeyRetrieval=true\u0026amp;serverTimezone=Asia/Ho_Chi_Minh spring.datasource.username=admin spring.datasource.password=YourStrongPassword123! spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver # Connection Pool spring.datasource.hikari.maximum-pool-size=10 spring.datasource.hikari.minimum-idle=5 spring.datasource.hikari.connection-timeout=20000 # JPA Configuration spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=false spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect # Server Configuration server.port=8080 server.servlet.context-path=/dna_service # JWT Configuration jwt.signerKey=2VJ50pdhYm96e4VECp/vsZGVmkSl9xp1rSYAZKsZL7n9Ti1pZYle3k9mheQEKt6+ jwt.expiration=86400000 # CORS Configuration cors.allowed.origins=* # Logging logging.level.root=INFO logging.level.aws_project.workshop=DEBUG logging.file.name=/opt/workshop/application.log Bước 2: Build Backend JAR cd BE/workshop_BE # Clean và build mvn clean package -DskipTests # Hoặc sử dụng Maven Wrapper ./mvnw clean package -DskipTests # Kiểm tra JAR file ls -lh target/workshop-0.0.1-SNAPSHOT.jar Kết quả mong đợi: File JAR khoảng 50-80MB trong thư mục target/\nBước 3: Upload JAR lên S3 Tạo S3 bucket cho backend artifacts (nếu chưa có):\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-${ACCOUNT_ID}-ap-southeast-1\u0026#34; # Tạo bucket aws s3 mb s3://${BACKEND_BUCKET} --region ap-southeast-1 # Upload JAR aws s3 cp target/workshop-0.0.1-SNAPSHOT.jar \\ s3://${BACKEND_BUCKET}/jars/ \\ --region ap-southeast-1 # Verify upload aws s3 ls s3://${BACKEND_BUCKET}/jars/ Bước 4: Deploy lên EC2 Lấy EC2 Instance ID INSTANCE_ID=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[0].Instances[0].InstanceId\u0026#39; \\ --output text) echo \u0026#34;Instance ID: $INSTANCE_ID\u0026#34; Kết nối vào EC2 qua Session Manager aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Trên EC2 Instance, chạy các lệnh sau: # Chuyển sang ec2-user sudo su - ec2-user # Di chuyển vào thư mục application cd /opt/workshop # Download JAR từ S3 ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text) BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-${ACCOUNT_ID}-ap-southeast-1\u0026#34; aws s3 cp s3://${BACKEND_BUCKET}/jars/workshop-0.0.1-SNAPSHOT.jar . \\ --region ap-southeast-1 # Kiểm tra file ls -lh workshop-0.0.1-SNAPSHOT.jar Tạo Application Properties cat \u0026gt; application.properties \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; spring.application.name=workshop-aws # Database Configuration spring.datasource.url=jdbc:mysql://REPLACE_WITH_RDS_ENDPOINT:3306/workshop_aws?useSSL=true\u0026amp;requireSSL=false\u0026amp;allowPublicKeyRetrieval=true\u0026amp;serverTimezone=Asia/Ho_Chi_Minh spring.datasource.username=admin spring.datasource.password=YourStrongPassword123! spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver # Connection Pool spring.datasource.hikari.maximum-pool-size=10 spring.datasource.hikari.minimum-idle=5 # JPA Configuration spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=false # Server Configuration server.port=8080 server.servlet.context-path=/dna_service # JWT Configuration jwt.signerKey=2VJ50pdhYm96e4VECp/vsZGVmkSl9xp1rSYAZKsZL7n9Ti1pZYle3k9mheQEKt6+ # Logging logging.level.root=INFO logging.level.aws_project.workshop=DEBUG logging.file.name=/opt/workshop/application.log EOF # Thay thế RDS endpoint RDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) sed -i \u0026#34;s/REPLACE_WITH_RDS_ENDPOINT/${RDS_ENDPOINT}/g\u0026#34; application.properties Khởi động Application # Dừng application cũ (nếu có) sudo systemctl stop workshop.service 2\u0026gt;/dev/null || true pkill -f workshop-0.0.1-SNAPSHOT.jar 2\u0026gt;/dev/null || true # Khởi động application nohup java -jar workshop-0.0.1-SNAPSHOT.jar \\ --spring.config.location=file:/opt/workshop/application.properties \\ \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; # Lưu PID echo $! \u0026gt; application.pid # Đợi application khởi động sleep 10 # Kiểm tra process ps aux | grep java Bước 5: Kiểm tra Application Test Health Endpoint # Trên EC2 curl http://localhost:8080/dna_service/actuator/health # Kết quả mong đợi: # {\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} Test qua Load Balancer # Trên máy local ALB_DNS=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ALBDNSName`].OutputValue\u0026#39; \\ --output text) curl http://${ALB_DNS}/dna_service/actuator/health Test qua API Gateway API_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) curl ${API_URL}/dna_service/actuator/health Bước 6: Cấu hình Systemd Service Để application tự động khởi động khi EC2 restart:\n# Trên EC2 sudo tee /etc/systemd/system/workshop.service \u0026gt; /dev/null \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [Unit] Description=Workshop DNA Analysis Backend After=network.target [Service] Type=simple User=ec2-user Group=ec2-user WorkingDirectory=/opt/workshop ExecStart=/usr/bin/java -jar /opt/workshop/workshop-0.0.1-SNAPSHOT.jar --spring.config.location=file:/opt/workshop/application.properties Restart=always RestartSec=10 StandardOutput=append:/opt/workshop/application.log StandardError=append:/opt/workshop/application.log [Install] WantedBy=multi-user.target EOF # Reload systemd sudo systemctl daemon-reload # Enable service sudo systemctl enable workshop.service # Start service sudo systemctl start workshop.service # Check status sudo systemctl status workshop.service Bước 7: Xem Logs # Xem application logs tail -f /opt/workshop/application.log # Xem systemd logs sudo journalctl -u workshop.service -f # Xem CloudWatch Logs (trên máy local) aws logs tail /aws/workshop-aws/dev/application \\ --follow \\ --region ap-southeast-1 Troubleshooting Application không khởi động Kiểm tra logs:\ntail -100 /opt/workshop/application.log Các lỗi thường gặp:\nDatabase connection failed\nKiểm tra RDS endpoint trong application.properties Kiểm tra Security Group cho phép EC2 connect đến RDS Verify database credentials Port 8080 already in use\n# Kill process đang dùng port 8080 sudo lsof -ti:8080 | xargs kill -9 Out of memory\n# Tăng heap size java -Xmx512m -jar workshop-0.0.1-SNAPSHOT.jar Health check failed # Kiểm tra application đang chạy ps aux | grep java # Kiểm tra port listening sudo netstat -tulpn | grep 8080 # Test local curl -v http://localhost:8080/dna_service/actuator/health Load Balancer health check failed # Kiểm tra Target Group health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;target-group-arn\u0026gt; \\ --region ap-southeast-1 # Kiểm tra Security Group # EC2 SG phải cho phép traffic từ ALB SG trên port 8080 Xác nhận Deployment thành công Checklist:\nJAR file đã build thành công JAR đã upload lên S3 Application đang chạy trên EC2 Health endpoint trả về {\u0026quot;status\u0026quot;:\u0026quot;UP\u0026quot;} Có thể access qua Load Balancer Có thể access qua API Gateway Systemd service đã được enable Logs đang được ghi vào CloudWatch Tiếp theo Sau khi backend đã sẵn sàng:\n➡️ Triển khai Frontend lên S3 và CloudFront\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong thời gian thực tập, em đã tham gia sáu sự kiện. Mỗi sự kiện đều là một trải nghiệm đáng nhớ, cung cấp kiến thức mới, thú vị và hữu ích, cùng với quà tặng và những khoảnh khắc tuyệt vời.\nEvent 1 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: AWS Event Hall, Tầng 26, Tòa nhà Bitexco, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em có được hiểu biết sâu sắc về cách generative AI đang thay đổi phát triển phần mềm. Sự kiện cho em thấy cách AI có thể giúp ích trong toàn bộ vòng đời phát triển, từ lập kế hoạch đến bảo trì. Em học được rằng mặc dù công cụ AI rất mạnh mẽ, nhưng phán đoán của con người vẫn rất quan trọng. Em cũng hiểu rằng chúng ta nên áp dụng công cụ AI dần dần và đảm bảo toàn bộ nhóm đồng nhất. Kỹ năng mới: Em học cách sử dụng Amazon Q Developer cho tạo mã, gỡ lỗi, và tài liệu hóa. Em cũng khám phá Kiro và phát hiện cách nó có thể nâng cao năng suất của em. Em phát triển kỹ năng xác định tác vụ nào có thể hưởng lợi từ tự động hóa AI và học cách cân bằng hỗ trợ AI với xem xét của con người để duy trì chất lượng mã. Đóng góp cho nhóm/dự án: Em đã tài liệu hóa những điểm chính từ sự kiện và chia sẻ với nhóm. Em xác định các dự án cụ thể nơi chúng em có thể pilot công cụ AI, điều này có thể cải thiện tốc độ phát triển của chúng em lên 20-30% cho các tác vụ lặp đi lặp lại. Em tạo ra các hướng dẫn để sử dụng công cụ AI trong workflow của nhóm và lập kế hoạch tổ chức các phiên đào tạo nội bộ. Kiến thức em có được giúp nhóm chúng em duy trì tính cạnh tranh bằng cách sử dụng các công cụ phát triển AI tiên tiến. Event 2 Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Văn phòng AWS Vietnam\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học được về hệ sinh thái AWS AI/ML đầy đủ, từ Amazon SageMaker cho ML truyền thống đến Amazon Bedrock cho Generative AI. Em có được hiểu biết sâu sắc về kỹ thuật prompt engineering như Chain-of-Thought reasoning và Few-shot learning. Em cũng học về kiến trúc RAG (Retrieval-Augmented Generation) và cách nó quan trọng để xây dựng ứng dụng GenAI chính xác. Tầm quan trọng của guardrails cho an toàn AI và lọc nội dung trong ứng dụng sản xuất cũng được nhấn mạnh. Kỹ năng mới: Em phát triển kỹ năng sử dụng Amazon SageMaker Studio cho phát triển và triển khai mô hình ML. Em học cách triển khai kiến trúc RAG cho tích hợp knowledge base. Em có được kiến thức thực tế về prompt engineering và cách xây dựng Bedrock Agents cho multi-step workflows. Em cũng học về các foundation models khác nhau (Claude, Llama, Titan) và khi nào sử dụng từng loại. Đóng góp cho nhóm/dự án: Em chia sẻ ghi chú toàn diện về khả năng SageMaker và tính năng Bedrock với nhóm. Em xác định cơ hội triển khai giải pháp RAG cho ứng dụng domain-specific của chúng em. Em đề xuất dự án thí điểm sử dụng Bedrock Agents cho tự động hóa dịch vụ khách hàng. Em cũng tạo hướng dẫn cho best practices prompt engineering và triển khai guardrail cho các dự án GenAI của chúng em. Event 3 Tên sự kiện: DevOps on AWS\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tòa nhà Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về văn hóa và nguyên tắc DevOps, bao gồm DORA metrics (Deployment Frequency, Lead Time, MTTR, Change Failure Rate) để đo lường mức độ trưởng thành DevOps. Em có được hiểu biết sâu sắc về dịch vụ AWS CI/CD (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) và các chiến lược deployment khác nhau (Blue/Green, Canary, Rolling). Em cũng học về Infrastructure as Code với CloudFormation và CDK, và khi nào sử dụng mỗi cách tiếp cận. Kỹ năng mới: Em phát triển kỹ năng xây dựng CI/CD pipeline hoàn chỉnh sử dụng dịch vụ AWS DevOps. Em học cách triển khai Infrastructure as Code với cả CloudFormation và CDK. Em có được kiến thức thực tế về dịch vụ container (ECR, ECS, EKS, App Runner) và khi nào sử dụng từng loại. Em cũng học cách thiết lập monitoring và observability sử dụng CloudWatch và X-Ray. Đóng góp cho nhóm/dự án: Em chia sẻ ghi chú toàn diện về dịch vụ AWS DevOps và best practices với nhóm. Em đề xuất triển khai CI/CD pipelines sử dụng CodePipeline cho deployments tự động. Em đề xuất áp dụng Infrastructure as Code cho tất cả hạ tầng của chúng em sử dụng CloudFormation hoặc CDK. Em cũng tạo hướng dẫn cho chiến lược containerization và best practices monitoring. Kiến thức có được giúp nhóm chúng em triển khai DevOps practices hiện đại và cải thiện tần suất deployment và độ tin cậy. Event 4 Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: AWS Vietnam Office, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về AWS Well-Architected Framework Security Pillar và năm pillars cốt lõi: Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection, và Incident Response. Em có được hiểu biết sâu sắc về các nguyên tắc bảo mật cốt lõi bao gồm Least Privilege, Zero Trust, và Defense in Depth. Em cũng học về Shared Responsibility Model và các mối đe dọa bảo mật hàng đầu trong môi trường cloud tại Việt Nam. Tầm quan trọng của việc xây dựng bảo mật vào kiến trúc ngay từ đầu, không phải như một add-on sau, được nhấn mạnh. Kỹ năng mới: Em phát triển kỹ năng trong kiến trúc IAM hiện đại sử dụng IAM Identity Center, Service Control Policies, và permission boundaries. Em học cách triển khai detection và monitoring toàn diện sử dụng CloudTrail, GuardDuty, và Security Hub. Em có được kiến thức thực tế về bảo mật mạng với VPC segmentation, Security Groups, NACLs, WAF, và Shield. Em cũng học về mã hóa at rest và in transit, quản lý khóa KMS, và quản lý secrets với Secrets Manager và Parameter Store. Đóng góp cho nhóm/dự án: Em chia sẻ best practices bảo mật toàn diện và framework năm pillars với nhóm. Em đề xuất triển khai các patterns IAM hiện đại với IAM Identity Center cho SSO. Em đề xuất thiết lập monitoring toàn diện sử dụng CloudTrail, GuardDuty, và Security Hub. Em tạo incident response playbooks cho các scenarios phổ biến như compromised IAM keys, S3 public exposure, và EC2 malware detection. Em cũng phát triển hướng dẫn cho chiến lược mã hóa và quản lý secrets. Kiến thức có được giúp nhóm chúng em xây dựng kiến trúc cloud an toàn theo AWS Well-Architected best practices. Event 5 Tên sự kiện: Building Agentic AI: Context Optimization with Amazon Bedrock\nThời gian: 09:00 ngày 05/12/2025\nĐịa điểm: Tầng 26, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về Building Agentic AI và Context Optimization với Amazon Bedrock. Em có được hiểu biết sâu sắc về cách xây dựng autonomous AI agents với Amazon Bedrock thông qua hands-on techniques. Em học về agentic orchestration patterns và context optimization techniques nâng cao. Em cũng hiểu về tầm quan trọng của context optimization trong việc giảm costs và improve performance. Workshop nhấn mạnh rằng agentic AI là tương lai của AI applications và context optimization là key để scale effectively. Kỹ năng mới: Em phát triển kỹ năng xây dựng Bedrock Agents từ đầu với guidance từ experts. Em học về context optimization techniques như compression, summarization, và relevant information extraction. Em có được kiến thức thực tế về agentic orchestration patterns và cách coordinate nhiều agents. Em cũng học về CloudThinker platform và cách nó simplify việc xây dựng agentic systems. Hands-on workshop cho em cơ hội practice với real AWS environments. Đóng góp cho nhóm/dự án: Em chia sẻ comprehensive notes về Building Agentic AI và Context Optimization với nhóm. Em đề xuất pilot projects sử dụng Bedrock Agents cho automation tasks. Em tạo guidelines cho context optimization best practices để reduce costs và improve performance. Em cũng document CloudThinker platform capabilities và integration patterns. Kiến thức có được giúp nhóm chúng em explore agentic AI solutions và optimize costs trong AI/ML projects. Event 6 Tên sự kiện: Kick-off AWS First Cloud Journey Workforce OJT FALL 2025\nThời gian: 08:30 ngày 06/09/2025\nĐịa điểm: Tầng 26, Bitexco Financial Tower, 2 Hải Triều, P. Bến Nghé, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về chương trình AWS First Cloud Journey Workforce, đã đào tạo hơn 2,000 sinh viên từ năm 2021, với hơn 150 học viên đang làm việc tại các công ty công nghệ hàng đầu. Em có được insights về các career pathways khác nhau trong cloud computing bao gồm DevOps, Cloud Engineer, và AI/ML Engineer roles. Em học về tầm quan trọng của continuous learning, networking, và setting clear career goals. Sự kiện nhấn mạnh rằng cloud computing offers diverse career paths và security, DevOps, và AI/ML đều là các hướng viable và rewarding. Kỹ năng mới: Em phát triển hiểu biết tốt hơn về career development trong cloud computing và học về các kỹ năng cần thiết cho các roles khác nhau. Em có được insights về cách xây dựng career path từ junior đến principal level. Em cũng học về tầm quan trọng của soft skills cùng với technical skills, và cách leverage community và mentorship cho career growth. Đóng góp cho nhóm/dự án: Em chia sẻ thông tin chương trình và career insights với nhóm. Em document các career pathways khác nhau và skill requirements cho các cloud roles. Em tạo personal development plan dựa trên roadmap được chia sẻ bởi speakers. Em cũng identify networking opportunities và connections có thể benefit nhóm. Kiến thức có được giúp em hiểu broader cloud computing ecosystem và plan career development accordingly. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.5-deploy-frontend/","title":"Triển khai Frontend","tags":[],"description":"","content":"Tổng quan Trong bước này, bạn sẽ build React frontend và deploy lên S3, sau đó phân phối qua CloudFront CDN để đảm bảo hiệu suất cao và độ trễ thấp cho người dùng toàn cầu.\nBước 1: Cấu hình API Endpoint Lấy API Gateway URL từ CloudFormation outputs:\nAPI_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;API URL: $API_URL\u0026#34; Cập nhật file FE/.env:\ncd FE cat \u0026gt; .env \u0026lt;\u0026lt;EOF VITE_API_URL=${API_URL}/dna_service VITE_APP_NAME=DNA Analysis Workshop VITE_APP_VERSION=1.0.0 EOF Hoặc cập nhật file config trực tiếp FE/src/config/api.ts:\nexport const API_BASE_URL = process.env.VITE_API_URL || \u0026#39;http://localhost:8080/dna_service\u0026#39;; export const API_TIMEOUT = 30000; export const API_ENDPOINTS = { AUTH: { LOGIN: \u0026#39;/auth/login\u0026#39;, REGISTER: \u0026#39;/auth/register\u0026#39;, LOGOUT: \u0026#39;/auth/logout\u0026#39;, REFRESH: \u0026#39;/auth/refresh\u0026#39;, }, DNA: { ANALYZE: \u0026#39;/dna/analyze\u0026#39;, HISTORY: \u0026#39;/dna/history\u0026#39;, RESULT: \u0026#39;/dna/result\u0026#39;, }, USER: { PROFILE: \u0026#39;/user/profile\u0026#39;, UPDATE: \u0026#39;/user/update\u0026#39;, }, }; Bước 2: Install Dependencies cd FE # Install npm packages npm install # Verify installation npm list --depth=0 Bước 3: Build Frontend # Build production bundle npm run build # Kiểm tra build output ls -lh dist/ # Xem cấu trúc files tree dist/ -L 2 Kết quả mong đợi:\ndist/\r├── index.html\r├── assets/\r│ ├── index-[hash].js\r│ ├── index-[hash].css\r│ └── [other assets]\r└── vite.svg Bước 4: Upload lên S3 Lấy S3 bucket name từ outputs:\nFRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend Bucket: $FRONTEND_BUCKET\u0026#34; Upload files lên S3:\n# Sync tất cả files aws s3 sync dist/ s3://${FRONTEND_BUCKET}/ \\ --delete \\ --region ap-southeast-1 # Set cache control cho static assets aws s3 cp dist/assets/ s3://${FRONTEND_BUCKET}/assets/ \\ --recursive \\ --cache-control \u0026#34;max-age=31536000\u0026#34; \\ --region ap-southeast-1 # Set no-cache cho index.html aws s3 cp dist/index.html s3://${FRONTEND_BUCKET}/ \\ --cache-control \u0026#34;no-cache,no-store,must-revalidate\u0026#34; \\ --region ap-southeast-1 # Verify upload aws s3 ls s3://${FRONTEND_BUCKET}/ --recursive Bước 5: Invalidate CloudFront Cache Sau khi upload, cần invalidate CloudFront cache để users nhận được phiên bản mới:\n# Lấy CloudFront Distribution ID DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Distribution ID: $DIST_ID\u0026#34; # Tạo invalidation aws cloudfront create-invalidation \\ --distribution-id $DIST_ID \\ --paths \u0026#34;/*\u0026#34; \\ --region ap-southeast-1 # Theo dõi invalidation status aws cloudfront get-invalidation \\ --distribution-id $DIST_ID \\ --id \u0026lt;invalidation-id\u0026gt; Lưu ý: Invalidation mất 5-10 phút để hoàn thành.\nBước 6: Truy cập Frontend Lấy CloudFront domain name:\nCLOUDFRONT_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend URL: https://${CLOUDFRONT_URL}\u0026#34; Mở trình duyệt và truy cập URL trên.\nBước 7: Kiểm tra Frontend Test Basic Functionality Trang chủ: Kiểm tra trang load đúng Navigation: Test các menu và routing API Connection: Mở Developer Tools → Network tab Console Errors: Kiểm tra không có lỗi JavaScript Test Authentication # Test login endpoint curl -X POST https://${CLOUDFRONT_URL}/api/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;username\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;test123\u0026#34;}\u0026#39; Test CORS Mở Developer Tools → Console và chạy:\nfetch(\u0026#39;${API_URL}/dna_service/actuator/health\u0026#39;) .then(res =\u0026gt; res.json()) .then(data =\u0026gt; console.log(\u0026#39;API Response:\u0026#39;, data)) .catch(err =\u0026gt; console.error(\u0026#39;CORS Error:\u0026#39;, err)); Bước 8: Cấu hình Custom Domain (Optional) Nếu bạn có domain name:\n1. Tạo SSL Certificate trong ACM # Certificate phải tạo trong us-east-1 cho CloudFront aws acm request-certificate \\ --domain-name yourdomain.com \\ --subject-alternative-names www.yourdomain.com \\ --validation-method DNS \\ --region us-east-1 2. Validate Certificate Thêm CNAME records vào DNS theo hướng dẫn từ ACM.\n3. Cập nhật CloudFront Distribution aws cloudfront update-distribution \\ --id $DIST_ID \\ --distribution-config file://cloudfront-config.json 4. Cập nhật Route 53 # Tạo A record alias đến CloudFront aws route53 change-resource-record-sets \\ --hosted-zone-id \u0026lt;zone-id\u0026gt; \\ --change-batch file://route53-changes.json Deployment Script Tạo script tự động hóa deployment:\ncat \u0026gt; deploy-frontend.sh \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; #!/bin/bash set -e echo \u0026#34;Building frontend...\u0026#34; cd FE npm run build echo \u0026#34;Getting S3 bucket name...\u0026#34; FRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Uploading to S3...\u0026#34; aws s3 sync dist/ s3://${FRONTEND_BUCKET}/ --delete --region ap-southeast-1 echo \u0026#34;Invalidating CloudFront cache...\u0026#34; DIST_ID=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDistributionId`].OutputValue\u0026#39; \\ --output text) aws cloudfront create-invalidation \\ --distribution-id $DIST_ID \\ --paths \u0026#34;/*\u0026#34; \\ --region ap-southeast-1 echo \u0026#34;Deployment complete!\u0026#34; echo \u0026#34;Frontend URL: https://$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text)\u0026#34; EOF chmod +x deploy-frontend.sh Sử dụng script:\n./deploy-frontend.sh Troubleshooting Build Failed Lỗi: \u0026ldquo;Module not found\u0026rdquo;\n# Xóa node_modules và reinstall rm -rf node_modules package-lock.json npm install Lỗi: \u0026ldquo;Out of memory\u0026rdquo;\n# Tăng memory cho Node.js export NODE_OPTIONS=\u0026#34;--max-old-space-size=4096\u0026#34; npm run build Upload Failed Lỗi: \u0026ldquo;Access Denied\u0026rdquo;\nKiểm tra AWS credentials Verify IAM permissions cho S3 Lỗi: \u0026ldquo;Bucket does not exist\u0026rdquo;\nKiểm tra bucket name Verify CloudFormation stack đã tạo bucket CloudFront Issues Trang không load:\nĐợi CloudFront distribution deploy (5-10 phút) Check distribution status: Deployed Nhận được phiên bản cũ:\nTạo invalidation mới Clear browser cache (Ctrl+Shift+R) CORS errors:\nKiểm tra API Gateway CORS configuration Verify backend CORS settings API Connection Failed # Test API từ browser console fetch(\u0026#39;${API_URL}/dna_service/actuator/health\u0026#39;) .then(res =\u0026gt; res.text()) .then(data =\u0026gt; console.log(data)) Nếu lỗi:\nKiểm tra API Gateway URL đúng Verify backend đang chạy Check Security Groups Xác nhận Deployment thành công Checklist:\nFrontend build thành công Files đã upload lên S3 CloudFront invalidation hoàn thành Trang web load đúng qua CloudFront URL Không có lỗi trong browser console API calls hoạt động (check Network tab) Authentication flow hoạt động Routing giữa các pages hoạt động Tiếp theo Sau khi frontend đã sẵn sàng:\n➡️ Kiểm tra và Xác thực\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Triển khai Ứng dụng Phân tích DNA trên AWS Tổng quan Trong workshop này, bạn sẽ học cách triển khai một ứng dụng phân tích DNA full-stack sẵn sàng cho production trên AWS sử dụng Infrastructure as Code (IaC) với CloudFormation. Ứng dụng bao gồm frontend React, backend Spring Boot, và cơ sở dữ liệu MySQL, tất cả được triển khai theo các best practices của AWS về bảo mật, khả năng mở rộng và tối ưu chi phí.\nCác dịch vụ AWS được sử dụng:\nVPC \u0026amp; Networking: VPC, Subnets, Internet Gateway, NAT Gateway, VPC Endpoints Compute: EC2 Auto Scaling Group, Application Load Balancer Storage \u0026amp; CDN: S3 để lưu trữ frontend, CloudFront để phân phối nội dung toàn cầu Database: RDS MySQL để lưu trữ dữ liệu với sao lưu tự động Security: Security Groups, IAM Roles, AWS Cognito cho xác thực người dùng Monitoring: CloudWatch Logs, Alarms, và thông báo SNS API Management: API Gateway để expose backend API một cách an toàn Bạn sẽ học được gì Infrastructure as Code: Triển khai toàn bộ hạ tầng AWS bằng CloudFormation templates Thiết kế VPC: Tạo VPC an toàn với public và private subnets trên nhiều availability zones Tối ưu chi phí: Sử dụng VPC Endpoints để giảm chi phí NAT Gateway (~$20-25/tháng) Auto Scaling: Cấu hình EC2 Auto Scaling dựa trên CPU metrics để đảm bảo high availability Quản lý Database: Triển khai và cấu hình RDS MySQL với các best practices về bảo mật Triển khai Frontend: Host static React website trên S3 với CloudFront CDN Triển khai Backend: Deploy ứng dụng Spring Boot trên EC2 với systemd service Best Practices về Security: Triển khai security groups, IAM roles, và Cognito authentication Monitoring \u0026amp; Logging: Thiết lập CloudWatch để giám sát và cảnh báo ứng dụng Sơ đồ Kiến trúc Internet\r│\r├─── CloudFront (CDN) ──\u0026gt; S3 (Frontend)\r│\r└─── API Gateway ──\u0026gt; ALB ──\u0026gt; EC2 (Backend) ──\u0026gt; RDS MySQL\r│\r└─── VPC Endpoints (S3, CloudWatch, SSM) Yêu cầu trước khi bắt đầu Tài khoản AWS với quyền phù hợp (Administrator hoặc tương đương) AWS CLI đã cài đặt và cấu hình (aws configure) EC2 Key Pair đã được tạo trong AWS region của bạn (ap-southeast-1) Hiểu biết cơ bản về các dịch vụ AWS và command line interface Quen thuộc với các khái niệm CloudFormation Chi phí ước tính Chạy hạ tầng workshop này sẽ tốn khoảng $8.90/tháng (nếu chạy 24/7):\nDịch vụ Instance Type Chi phí/tháng (USD) EC2 t3.nano $3.50 RDS MySQL db.t3.micro $2.80 API Gateway - $0.50 S3 + CloudFront - $0.80 Route 53 - $0.50 Cognito - $0.10 CloudWatch - $0.30 CI/CD (CodePipeline) - $0.40 Tổng $8.90 Cho workshop (2-3 giờ): ~$0.50-1.00\n💡 Mẹo tiết kiệm chi phí:\nXóa stack ngay sau khi hoàn thành workshop Sử dụng Free Tier cho các dịch vụ đủ điều kiện Tắt NAT Gateway khi không sử dụng (tiết kiệm ~$32/tháng) Sử dụng VPC Endpoints thay vì NAT Gateway cho production Thời gian Workshop Tổng thời gian: 2-3 giờ Triển khai Infrastructure: 15-20 phút Cấu hình Application: 30-45 phút Testing \u0026amp; Validation: 15-30 phút Cleanup: 5-10 phút Nội dung Tổng quan Workshop Chuẩn bị \u0026amp; Yêu cầu Triển khai Infrastructure với CloudFormation Cấu hình và Triển khai Backend Application Triển khai Frontend lên S3 và CloudFront Kiểm tra và Xác thực Giám sát và Xử lý sự cố Thiết lập CI/CD Pipeline Dọn dẹp tài nguyên "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.6-testing/","title":"Kiểm tra và Xác thực","tags":[],"description":"","content":"Tổng quan Trong bước này, bạn sẽ thực hiện các test cases để xác nhận ứng dụng hoạt động đúng end-to-end, từ frontend qua API Gateway, Load Balancer, đến backend và database.\nBước 1: Kiểm tra Infrastructure Verify All Services Running # Check CloudFormation stack status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Expected: CREATE_COMPLETE # Check EC2 instances aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name,PrivateIpAddress]\u0026#39; \\ --output table # Check RDS status aws rds describe-db-instances \\ --db-instance-identifier workshop-aws-dev-db \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[0].[DBInstanceIdentifier,DBInstanceStatus]\u0026#39; \\ --output table # Expected: available # Check Load Balancer aws elbv2 describe-load-balancers \\ --names workshop-aws-dev-alb \\ --region ap-southeast-1 \\ --query \u0026#39;LoadBalancers[0].[LoadBalancerName,State.Code]\u0026#39; \\ --output table # Expected: active Bước 2: Test Backend API Get API URLs ALB_DNS=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ALBDNSName`].OutputValue\u0026#39; \\ --output text) API_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`APIGatewayURL`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;ALB DNS: $ALB_DNS\u0026#34; echo \u0026#34;API Gateway URL: $API_URL\u0026#34; Test Health Endpoint # Test qua ALB curl -v http://${ALB_DNS}/dna_service/actuator/health # Test qua API Gateway curl -v ${API_URL}/dna_service/actuator/health # Expected response: # {\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} Test User Registration # Register new user curl -X POST ${API_URL}/dna_service/auth/register \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;Test123!@#\u0026#34;, \u0026#34;fullName\u0026#34;: \u0026#34;Test User\u0026#34; }\u0026#39; # Expected: 200 OK with user data Test User Login # Login curl -X POST ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;Test123!@#\u0026#34; }\u0026#39; # Expected: 200 OK with JWT token # Save token for next requests TOKEN=\u0026#34;\u0026lt;jwt-token-from-response\u0026gt;\u0026#34; Test Protected Endpoints # Get user profile curl -X GET ${API_URL}/dna_service/user/profile \\ -H \u0026#34;Authorization: Bearer ${TOKEN}\u0026#34; # Expected: 200 OK with user profile data Bước 3: Test Frontend Access Frontend CLOUDFRONT_URL=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`CloudFrontDomainName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;Frontend URL: https://${CLOUDFRONT_URL}\u0026#34; Mở trình duyệt và truy cập URL trên.\nManual Testing Checklist 1. Trang chủ (Home Page)\nTrang load thành công Logo và branding hiển thị đúng Navigation menu hoạt động Không có lỗi trong Console 2. User Registration\nForm validation hoạt động Có thể đăng ký user mới Hiển thị thông báo thành công Redirect đến login page 3. User Login\nCó thể đăng nhập với credentials vừa tạo JWT token được lưu trong localStorage Redirect đến dashboard sau login User menu hiển thị username 4. DNA Analysis\nCó thể upload DNA sequence file File validation hoạt động Analysis progress được hiển thị Kết quả analysis hiển thị đúng Có thể xem history 5. User Profile\nHiển thị thông tin user Có thể update profile Avatar upload hoạt động (nếu có) Logout hoạt động đúng 6. Responsive Design\nMobile view hoạt động tốt Tablet view hoạt động tốt Desktop view hoạt động tốt Bước 4: Test Database Connection Connect to RDS # Get RDS endpoint RDS_ENDPOINT=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`RDSEndpoint`].OutputValue\u0026#39; \\ --output text) # Connect via MySQL client (từ EC2 hoặc local nếu có public access) mysql -h ${RDS_ENDPOINT} -u admin -p workshop_aws Verify Tables Created -- Show all tables SHOW TABLES; -- Expected tables: -- users, dna_sequences, analysis_results, etc. -- Check user data SELECT id, username, email, created_at FROM users; -- Check DNA analysis data SELECT id, user_id, sequence_name, status, created_at FROM dna_sequences; -- Exit EXIT; Bước 5: Load Testing (Optional) Install Apache Bench # Ubuntu/Debian sudo apt-get install apache2-utils # MacOS brew install httpd # Windows # Download from Apache website Run Load Test # Test health endpoint ab -n 1000 -c 10 http://${ALB_DNS}/dna_service/actuator/health # Test login endpoint ab -n 100 -c 5 -p login-data.json -T application/json \\ ${API_URL}/dna_service/auth/login Monitor During Load Test # Watch CloudWatch metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;5 minutes ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average \\ --region ap-southeast-1 Bước 6: Security Testing Test HTTPS Enforcement # CloudFront should redirect HTTP to HTTPS curl -I http://${CLOUDFRONT_URL} # Expected: 301 redirect to https:// Test CORS # Test preflight request curl -X OPTIONS ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Origin: https://${CLOUDFRONT_URL}\u0026#34; \\ -H \u0026#34;Access-Control-Request-Method: POST\u0026#34; \\ -H \u0026#34;Access-Control-Request-Headers: Content-Type\u0026#34; \\ -v # Expected: CORS headers in response Test SQL Injection Protection # Try SQL injection in login curl -X POST ${API_URL}/dna_service/auth/login \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#39;\\\u0026#39;\u0026#39; OR \u0026#39;\\\u0026#39;\u0026#39;1\u0026#39;\\\u0026#39;\u0026#39;=\u0026#39;\\\u0026#39;\u0026#39;1\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;anything\u0026#34; }\u0026#39; # Expected: 401 Unauthorized (not SQL error) Test XSS Protection Trong browser console:\n// Try XSS in input fields document.querySelector(\u0026#39;input[name=\u0026#34;username\u0026#34;]\u0026#39;).value = \u0026#39;\u0026lt;script\u0026gt;alert(\u0026#34;XSS\u0026#34;)\u0026lt;/script\u0026gt;\u0026#39;; Expected: Script không được execute, được escape hoặc sanitize.\nBước 7: Performance Testing Measure Page Load Time Mở Chrome DevTools → Network tab:\nFirst Contentful Paint (FCP): \u0026lt; 1.5s Largest Contentful Paint (LCP): \u0026lt; 2.5s Time to Interactive (TTI): \u0026lt; 3.5s Total Page Size: \u0026lt; 2MB Test API Response Time # Measure API response time time curl -s ${API_URL}/dna_service/actuator/health \u0026gt; /dev/null # Expected: \u0026lt; 200ms Test CloudFront Caching # First request (MISS) curl -I https://${CLOUDFRONT_URL}/assets/index.js # Second request (HIT) curl -I https://${CLOUDFRONT_URL}/assets/index.js # Check X-Cache header: Hit from cloudfront Troubleshooting Common Issues API Returns 502 Bad Gateway # Check backend health curl http://${ALB_DNS}/dna_service/actuator/health # Check target group health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;arn\u0026gt; \\ --region ap-southeast-1 # Check EC2 logs aws ssm start-session --target \u0026lt;instance-id\u0026gt; tail -f /opt/workshop/application.log Frontend Shows CORS Error Verify API Gateway CORS configuration Check backend CORS settings in application.properties Ensure CloudFront origin is whitelisted Database Connection Timeout Check RDS Security Group allows EC2 traffic Verify RDS endpoint in application.properties Test connection from EC2: telnet ${RDS_ENDPOINT} 3306 Slow Page Load Check CloudFront cache hit ratio Optimize images and assets Enable gzip compression Review CloudWatch metrics Test Results Documentation Tạo file test-results.md:\n# Workshop Test Results ## Date: 2025-12-08 ## Tester: [Your Name] ### Infrastructure Tests - [x] CloudFormation stack: CREATE_COMPLETE - [x] EC2 instances: Running - [x] RDS database: Available - [x] Load Balancer: Active ### Backend API Tests - [x] Health endpoint: OK - [x] User registration: OK - [x] User login: OK - [x] Protected endpoints: OK ### Frontend Tests - [x] Page load: OK - [x] User registration: OK - [x] User login: OK - [x] DNA analysis: OK - [x] Responsive design: OK ### Performance Tests - [x] Page load time: 1.2s - [x] API response time: 150ms - [x] CloudFront cache: Working ### Security Tests - [x] HTTPS enforcement: OK - [x] CORS: OK - [x] SQL injection protection: OK - [x] XSS protection: OK ## Issues Found None ## Recommendations - Enable CloudFront compression - Add more CloudWatch alarms - Implement rate limiting Xác nhận Testing hoàn thành Checklist:\nTất cả infrastructure services đang chạy Backend API endpoints hoạt động Frontend load và hoạt động đúng Database connection hoạt động User authentication flow hoạt động DNA analysis features hoạt động Performance đạt yêu cầu Security tests pass Test results được document Tiếp theo Sau khi testing hoàn thành:\n➡️ Giám sát và Xử lý sự cố\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại First Cloud AI Journey Office (FCJ) từ tháng 9 năm 2025 đến tháng 12 năm 2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức về cloud computing vào môi trường AWS thực tế.\nTôi đã tham gia chương trình thực tập AWS Cloud Journey, nơi tôi hoàn thành hành trình học tập 12 tuần và triển khai một kiến trúc web application production-ready trên AWS. Qua dự án này, tôi đã cải thiện kỹ năng về thiết kế cloud architecture, AWS services, Infrastructure as Code (CloudFormation), CI/CD pipelines, monitoring và observability, security best practices, và giải quyết vấn đề trong môi trường cloud.\nDự án chính bao gồm thiết kế và triển khai một kiến trúc AWS web application hoàn chỉnh gồm:\nEdge Layer: Route 53, CloudFront CDN, AWS WAF, ACM Certificate, S3 static hosting Networking: VPC, subnets, Internet Gateway, NAT Gateway, Security Groups, VPC Flow Logs Compute \u0026amp; Database: EC2 với Auto Scaling, RDS, API Gateway, Amazon Cognito CI/CD: GitLab, CodePipeline, CodeBuild với automated deployments Monitoring \u0026amp; Security: CloudWatch, CloudTrail, SNS alerts, IAM, Secrets Manager Về tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với mentors và đồng nghiệp để nâng cao hiệu quả công việc. Tôi đã duy trì worklogs chi tiết ghi lại tiến độ, các thách thức gặp phải, và các giải pháp đã triển khai trong suốt 12 tuần.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ☐ ✅ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ☐ ✅ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ☐ ✅ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Điểm mạnh Khả năng học hỏi mạnh: Tôi đã thể hiện khả năng thích ứng nhanh với các AWS services và khái niệm mới. Khi gặp các services chưa quen như API Gateway VPC Link hoặc CloudFront OAC, tôi chủ động nghiên cứu tài liệu và triển khai giải pháp hiệu quả.\nTính chủ động: Tôi đã chủ động khám phá các tính năng nâng cao vượt quá yêu cầu cơ bản, chẳng hạn như triển khai SSH-less deployment sử dụng AWS Systems Manager và tự động hóa CloudFront cache invalidation trong CI/CD pipelines.\nTài liệu kỹ thuật: Tôi đã duy trì worklogs toàn diện với tài liệu chi tiết về các quyết định kiến trúc, thách thức gặp phải, và giải pháp đã triển khai, điều này sẽ có giá trị cho tham khảo tương lai và chia sẻ kiến thức.\nTrách nhiệm và chất lượng: Tôi đã hoàn thành nhất quán các nhiệm vụ hàng tuần đúng lịch trình và đảm bảo chất lượng bằng cách kiểm tra kỹ lưỡng ở mỗi giai đoạn của dự án, từ thiết lập edge layer đến kiểm tra end-to-end cuối cùng.\nCần cải thiện Quản lý thời gian và kỷ luật: Mặc dù tôi đã hoàn thành tất cả các nhiệm vụ, đôi khi tôi gặp khó khăn với quản lý thời gian khi xử lý các vấn đề phức tạp như cấu hình API Gateway VPC Link hoặc troubleshooting CloudWatch alarms. Tôi cần cải thiện khả năng ước tính thời gian thực hiện nhiệm vụ chính xác hơn và phân bổ thời gian hiệu quả hơn.\nHiệu quả giải quyết vấn đề: Khi đối mặt với các thách thức kỹ thuật (như vấn đề kết nối RDS hoặc xác thực Cognito JWT token), đôi khi tôi dành quá nhiều thời gian troubleshooting trước khi tìm kiếm sự giúp đỡ hoặc tham khảo tài liệu. Tôi nên phát triển một cách tiếp cận có hệ thống hơn để giải quyết vấn đề: đầu tiên kiểm tra tài liệu, sau đó kiểm tra có hệ thống, và cuối cùng tìm kiếm hướng dẫn khi cần thiết.\nKỹ năng giao tiếp: Tôi cần cải thiện khả năng giao tiếp các vấn đề kỹ thuật và giải pháp rõ ràng hơn, đặc biệt là khi trình bày các quyết định kiến trúc hoặc giải thích các cấu hình phức tạp cho các thành viên trong nhóm. Điều này bao gồm tài liệu hóa tốt hơn các bước troubleshooting và giao tiếp bằng lời nói hiệu quả hơn trong các cuộc thảo luận nhóm.\nNhận thức về tối ưu hóa chi phí: Ban đầu, tôi tập trung nhiều hơn vào chức năng hơn là tối ưu hóa chi phí. Ví dụ, VPC Flow Logs tạo ra chi phí CloudWatch cao trước khi tôi triển khai retention policies và S3 storage. Tôi nên xem xét các tác động chi phí sớm hơn trong giai đoạn thiết kế.\nSuy ngẫm Kỳ thực tập này đã cung cấp kinh nghiệm thực hành vô giá với AWS cloud services và best practices. Các thách thức tôi gặp phải, chẳng hạn như cấu hình API Gateway VPC Links, triển khai SSH-less deployments, và troubleshooting CloudWatch alarms, đã tăng cường đáng kể kỹ năng giải quyết vấn đề và kiến thức kỹ thuật của tôi.\nDự án đã dạy tôi tầm quan trọng của:\nInfrastructure as Code: Sử dụng CloudFormation cho reproducible deployments Security First: Triển khai least-privilege IAM policies và network segmentation Monitoring và Observability: Thiết lập logging và alerting toàn diện Automation: Giảm lỗi thủ công thông qua CI/CD pipelines Documentation: Duy trì hồ sơ chi tiết cho troubleshooting và knowledge transfer Tôi biết ơn vì cơ hội được làm việc trên dự án AWS toàn diện này và mong muốn áp dụng những kỹ năng này trong các vai trò cloud architecture và DevOps trong tương lai.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.7-monitoring/","title":"Giám sát và Xử lý sự cố","tags":[],"description":"","content":"Tổng quan Trong bước này, bạn sẽ học cách giám sát ứng dụng, xem logs, và xử lý các sự cố thường gặp sử dụng CloudWatch, CloudWatch Logs, và các công cụ AWS khác.\nCloudWatch Metrics EC2 Metrics # CPU Utilization aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # Memory Utilization (nếu có CloudWatch Agent) aws cloudwatch get-metric-statistics \\ --namespace CWAgent \\ --metric-name mem_used_percent \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 RDS Metrics # Database Connections aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name DatabaseConnections \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # CPU Utilization aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name CPUUtilization \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 Application Load Balancer Metrics # Request Count aws cloudwatch get-metric-statistics \\ --namespace AWS/ApplicationELB \\ --metric-name RequestCount \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum \\ --region ap-southeast-1 # Target Response Time aws cloudwatch get-metric-statistics \\ --namespace AWS/ApplicationELB \\ --metric-name TargetResponseTime \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average \\ --region ap-southeast-1 CloudWatch Logs Xem Application Logs # List log streams aws logs describe-log-streams \\ --log-group-name /aws/workshop-aws/dev/application \\ --order-by LastEventTime \\ --descending \\ --max-items 5 \\ --region ap-southeast-1 # Tail logs (real-time) aws logs tail /aws/workshop-aws/dev/application \\ --follow \\ --region ap-southeast-1 # Filter logs by pattern aws logs filter-log-events \\ --log-group-name /aws/workshop-aws/dev/application \\ --filter-pattern \u0026#34;ERROR\u0026#34; \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s)000 \\ --region ap-southeast-1 # Search for specific errors aws logs filter-log-events \\ --log-group-name /aws/workshop-aws/dev/application \\ --filter-pattern \u0026#34;NullPointerException\u0026#34; \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s)000 \\ --region ap-southeast-1 Xem EC2 System Logs # Get instance ID INSTANCE_ID=$(aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ \u0026#34;Name=instance-state-name,Values=running\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[0].Instances[0].InstanceId\u0026#39; \\ --output text) # Get console output aws ec2 get-console-output \\ --instance-id $INSTANCE_ID \\ --region ap-southeast-1 \\ --output text CloudWatch Alarms Xem Existing Alarms # List all alarms aws cloudwatch describe-alarms \\ --alarm-name-prefix workshop-aws-dev \\ --region ap-southeast-1 # Get alarm history aws cloudwatch describe-alarm-history \\ --alarm-name workshop-aws-dev-cpu-high \\ --max-records 10 \\ --region ap-southeast-1 Tạo Custom Alarms # Alarm cho High Error Rate aws cloudwatch put-metric-alarm \\ --alarm-name workshop-aws-dev-high-error-rate \\ --alarm-description \u0026#34;Alert when error rate exceeds 5%\u0026#34; \\ --metric-name 5XXError \\ --namespace AWS/ApplicationELB \\ --statistic Sum \\ --period 300 \\ --evaluation-periods 2 \\ --threshold 10 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=LoadBalancer,Value=app/workshop-aws-dev-alb/xxxxx \\ --alarm-actions arn:aws:sns:ap-southeast-1:123456789012:workshop-aws-dev-alarms \\ --region ap-southeast-1 # Alarm cho Database Connections aws cloudwatch put-metric-alarm \\ --alarm-name workshop-aws-dev-high-db-connections \\ --alarm-description \u0026#34;Alert when DB connections exceed 80\u0026#34; \\ --metric-name DatabaseConnections \\ --namespace AWS/RDS \\ --statistic Average \\ --period 300 \\ --evaluation-periods 2 \\ --threshold 80 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --alarm-actions arn:aws:sns:ap-southeast-1:123456789012:workshop-aws-dev-alarms \\ --region ap-southeast-1 CloudWatch Dashboards Tạo Dashboard # Tạo dashboard JSON cat \u0026gt; dashboard.json \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; { \u0026#34;widgets\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/EC2\u0026#34;, \u0026#34;CPUUtilization\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;EC2 CPU Utilization\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/RDS\u0026#34;, \u0026#34;DatabaseConnections\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;RDS Connections\u0026#34; } }, { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/ApplicationELB\u0026#34;, \u0026#34;RequestCount\u0026#34;, {\u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;}] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Sum\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;ALB Request Count\u0026#34; } } ] } EOF # Create dashboard aws cloudwatch put-dashboard \\ --dashboard-name workshop-aws-dev-dashboard \\ --dashboard-body file://dashboard.json \\ --region ap-southeast-1 Xem Dashboard Mở CloudWatch Console → Dashboards → workshop-aws-dev-dashboard\nTroubleshooting Common Issues Issue 1: High CPU Usage Symptoms:\nEC2 CPU \u0026gt; 80% Slow response times CloudWatch alarm triggered Diagnosis:\n# Check CPU metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/EC2 \\ --metric-name CPUUtilization \\ --dimensions Name=AutoScalingGroupName,Value=workshop-aws-dev-asg \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # SSH vào EC2 và check processes aws ssm start-session --target $INSTANCE_ID top -bn1 | head -20 Solutions:\nScale up: Tăng instance type Scale out: Tăng số lượng instances Optimize code: Profile và optimize application Add caching: Implement Redis/ElastiCache Issue 2: Database Connection Pool Exhausted Symptoms:\n\u0026ldquo;Too many connections\u0026rdquo; errors Slow database queries Application timeouts Diagnosis:\n# Check DB connections aws cloudwatch get-metric-statistics \\ --namespace AWS/RDS \\ --metric-name DatabaseConnections \\ --dimensions Name=DBInstanceIdentifier,Value=workshop-aws-dev-db \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 60 \\ --statistics Average,Maximum \\ --region ap-southeast-1 # Connect to DB and check mysql -h $RDS_ENDPOINT -u admin -p SHOW PROCESSLIST; SHOW STATUS LIKE \u0026#39;Threads_connected\u0026#39;; Solutions:\nIncrease connection pool size trong application.properties Fix connection leaks trong code Scale up RDS instance Implement connection pooling best practices Issue 3: High Memory Usage Symptoms:\nOut of memory errors Application crashes Slow performance Diagnosis:\n# Check memory on EC2 aws ssm start-session --target $INSTANCE_ID free -h ps aux --sort=-%mem | head -10 # Check Java heap usage jstat -gc \u0026lt;java-pid\u0026gt; Solutions:\nIncrease JVM heap size: -Xmx1024m Fix memory leaks Scale up instance type Implement proper garbage collection tuning Issue 4: 502 Bad Gateway Symptoms:\nUsers receive 502 errors ALB cannot reach backend Health checks failing Diagnosis:\n# Check target health aws elbv2 describe-target-health \\ --target-group-arn \u0026lt;arn\u0026gt; \\ --region ap-southeast-1 # Check backend logs aws logs tail /aws/workshop-aws/dev/application --follow # Check Security Groups aws ec2 describe-security-groups \\ --group-ids \u0026lt;ec2-sg-id\u0026gt; \\ --region ap-southeast-1 Solutions:\nVerify backend is running: systemctl status workshop Check Security Group allows ALB traffic Verify health check path is correct Check application logs for errors Issue 5: Slow Page Load Symptoms:\nFrontend takes \u0026gt; 3s to load Poor user experience High bounce rate Diagnosis:\n# Check CloudFront metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/CloudFront \\ --metric-name BytesDownloaded \\ --dimensions Name=DistributionId,Value=$DIST_ID \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum \\ --region us-east-1 # Check cache hit ratio curl -I https://$CLOUDFRONT_URL/assets/index.js | grep X-Cache Solutions:\nEnable CloudFront compression Optimize images and assets Implement lazy loading Increase cache TTL Use CDN for static assets Performance Monitoring Application Performance Monitoring (APM) Thêm Spring Boot Actuator metrics:\n# application.properties management.endpoints.web.exposure.include=health,info,metrics,prometheus management.metrics.export.cloudwatch.enabled=true management.metrics.export.cloudwatch.namespace=WorkshopApp management.metrics.export.cloudwatch.step=1m Custom Metrics Publish custom metrics từ application:\n@Autowired private MeterRegistry meterRegistry; public void recordDNAAnalysis() { Counter.builder(\u0026#34;dna.analysis.count\u0026#34;) .tag(\u0026#34;type\u0026#34;, \u0026#34;sequence\u0026#34;) .register(meterRegistry) .increment(); } Query Custom Metrics aws cloudwatch get-metric-statistics \\ --namespace WorkshopApp \\ --metric-name dna.analysis.count \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum \\ --region ap-southeast-1 Log Analysis CloudWatch Logs Insights # Query error logs aws logs start-query \\ --log-group-name /aws/workshop-aws/dev/application \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s) \\ --end-time $(date +%s) \\ --query-string \u0026#39;fields @timestamp, @message | filter @message like /ERROR/ | sort @timestamp desc | limit 20\u0026#39; \\ --region ap-southeast-1 # Get query results aws logs get-query-results \\ --query-id \u0026lt;query-id\u0026gt; \\ --region ap-southeast-1 Common Log Queries 1. Top 10 errors:\nfields @timestamp, @message\r| filter @message like /ERROR/\r| stats count() by @message\r| sort count desc\r| limit 10 2. Slow queries:\nfields @timestamp, @message\r| filter @message like /Hibernate/\r| filter @message like /ms/\r| parse @message /(?\u0026lt;duration\u0026gt;\\d+)ms/\r| filter duration \u0026gt; 1000\r| sort @timestamp desc 3. API response times:\nfields @timestamp, @message\r| filter @message like /Request processed/\r| parse @message /in (?\u0026lt;duration\u0026gt;\\d+)ms/\r| stats avg(duration), max(duration), min(duration) Best Practices 1. Set Up Alerts CPU \u0026gt; 80% for 5 minutes Memory \u0026gt; 85% for 5 minutes Disk \u0026gt; 90% 5XX errors \u0026gt; 10 in 5 minutes Database connections \u0026gt; 80% of max 2. Regular Health Checks # Daily health check script #!/bin/bash echo \u0026#34;=== Daily Health Check ===\u0026#34; echo \u0026#34;Date: $(date)\u0026#34; # Check stack status echo \u0026#34;CloudFormation Stack:\u0026#34; aws cloudformation describe-stacks --stack-name workshop-aws-dev --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Check EC2 echo \u0026#34;EC2 Instances:\u0026#34; aws ec2 describe-instances --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name]\u0026#39; # Check RDS echo \u0026#34;RDS Database:\u0026#34; aws rds describe-db-instances --db-instance-identifier workshop-aws-dev-db --query \u0026#39;DBInstances[0].DBInstanceStatus\u0026#39; # Check API echo \u0026#34;API Health:\u0026#34; curl -s $API_URL/dna_service/actuator/health | jq . 3. Log Retention Development: 3-7 days Production: 30-90 days Compliance: 1-7 years 4. Cost Monitoring # Check CloudWatch costs aws ce get-cost-and-usage \\ --time-period Start=2025-12-01,End=2025-12-08 \\ --granularity DAILY \\ --metrics BlendedCost \\ --filter file://filter.json Monitoring Checklist CloudWatch metrics được thu thập CloudWatch Logs được cấu hình Alarms được thiết lập SNS notifications hoạt động Dashboard được tạo Log retention được cấu hình Custom metrics được publish Health checks hoạt động Performance baseline được thiết lập Tiếp theo Sau khi thiết lập monitoring:\n➡️ Dọn dẹp tài nguyên\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi em gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp em tập trung tốt hơn. Tuy nhiên, em nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi em chưa hiểu và luôn khuyến khích em đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để em làm việc thuận lợi. Em đánh giá cao việc mentor cho phép em thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc em được giao phù hợp với kiến thức em đã học ở trường, đồng thời mở rộng thêm những mảng mới mà em chưa từng được tiếp cận. Nhờ vậy, em vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, em học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp em định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp em cảm thấy em là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nĐiều làm em hài lòng nhất là thành công triển khai một kiến trúc AWS cloud hoàn chỉnh, production-ready cho Hệ thống Hỗ trợ Hiến máu. Từ việc thiết kế kiến trúc ban đầu với VPC, subnets, và security groups, đến triển khai CI/CD pipelines với CodePipeline và CodeBuild, và cuối cùng thấy ứng dụng chạy mượt mà trên EC2 với kết nối RDS database—mỗi cột mốc đều cảm thấy như một thành tựu lớn. Đặc biệt thỏa mãn là giải quyết các thách thức phức tạp như cấu hình API Gateway VPC Links, triển khai SSH-less deployments sử dụng Systems Manager, và tự động hóa CloudFront cache invalidation. Khoảnh khắc khi em thành công kết nối đến EC2 instance qua Session Manager mà không cần SSH keys và deploy ứng dụng Spring Boot là vô cùng thỏa mãn. Ngoài ra, nhận được phản hồi tích cực từ mentors trong buổi presentation giữa kỳ và thấy hệ thống xử lý các kịch bản thực tế đã xác nhận tất cả công sức bỏ ra.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nChắc chắn, em sẽ rất khuyến khích bạn bè tham gia chương trình thực tập này nếu họ quan tâm đến cloud computing và AWS. Đây là lý do:\nƯu điểm:\nKinh nghiệm thực hành: Khác với nhiều chương trình thực tập tập trung vào học lý thuyết, chương trình này cung cấp các dự án thực tế, production-level mà bạn có thể showcase trong portfolio. Hỗ trợ từ mentor: Các mentors có kiến thức sâu, kiên nhẫn, và thực sự đầu tư vào sự phát triển của bạn. Họ hướng dẫn mà không spoon-feed, điều này xây dựng kỹ năng giải quyết vấn đề. Học tập toàn diện: Chương trình 12 tuần bao gồm mọi thứ từ thiết lập EC2 cơ bản đến các chủ đề nâng cao như CI/CD, monitoring, và security best practices. Kỹ năng liên quan đến ngành: Các kỹ năng học được ở đây (CloudFormation, CodePipeline, Systems Manager, v.v.) trực tiếp áp dụng cho các vai trò DevOps và cloud engineering thực tế. Dự án Portfolio: Bạn kết thúc với một dự án hoàn chỉnh, có thể deploy được chứng minh chuyên môn AWS của bạn cho nhà tuyển dụng tương lai. Cần lưu ý:\nYêu cầu động lực tự thân và học tập chủ động—không lý tưởng cho những người thích hướng dẫn có cấu trúc cao, từng bước. Đường cong học tập có thể dốc, đặc biệt đối với người mới bắt đầu trong cloud computing. Nhìn chung, chương trình thực tập này hoàn hảo cho sinh viên muốn chuyển đổi từ kiến thức học thuật sang kỹ năng sẵn sàng cho ngành trong cloud computing.\nĐề xuất \u0026amp; mong muốn Bạn có muốn tiếp tục chương trình này trong tương lai?\nCó, em rất quan tâm đến việc tiếp tục chương trình này trong tương lai, có thể là:\nMột thực tập sinh quay lại để làm việc trên các dự án nâng cao hơn hoặc mentor các thực tập sinh mới Một contributor bán thời gian để giúp duy trì và cải thiện tài liệu workshop Một collaborator trên các cải tiến open-source cho infrastructure templates Trải nghiệm này đã vô cùng quý giá, và em rất muốn đóng góp lại cho chương trình đã giúp em phát triển rất nhiều.\nGóp ý khác (tự do chia sẻ):\nKỳ thực tập này đã là một trải nghiệm biến đổi. Bước vào với kiến thức AWS cơ bản từ các khóa học đại học, em rời đi với sự tự tin trong việc thiết kế, triển khai và quản lý hạ tầng cloud production-grade. Dự án Hệ thống Hỗ trợ Hiến máu đã dạy em không chỉ kỹ năng kỹ thuật, mà còn tầm quan trọng của tài liệu hóa, tư duy security-first, tối ưu hóa chi phí, và giải quyết vấn đề có hệ thống.\nCác thách thức em đối mặt—từ debugging API Gateway VPC Links đến triển khai SSH-less deployments—đã buộc em suy nghĩ phê phán và phát triển khả năng phục hồi. Cách tiếp cận của mentor là hướng dẫn thay vì đưa đáp án ban đầu khó chịu nhưng cuối cùng đã làm em trở thành một kỹ sư tốt hơn.\nEm đặc biệt biết ơn về:\nSự tự do để khám phá và triển khai các giải pháp vượt quá yêu cầu cơ bản Phản hồi mang tính xây dựng trong các buổi presentation đã giúp tinh chỉnh cả kỹ năng kỹ thuật và giao tiếp Tiếp xúc với các kịch bản thực tế như xử lý lỗi deployment, tối ưu hóa chi phí, và troubleshooting các vấn đề production Kỳ thực tập này đã củng cố sự quan tâm của em trong việc theo đuổi sự nghiệp trong cloud engineering và DevOps. Kinh nghiệm thực hành với AWS services, kết hợp với mentorship và môi trường hợp tác, đã chuẩn bị tốt cho em cho các vai trò tương lai trong ngành.\nCảm ơn toàn bộ team FCJ vì cơ hội tuyệt vời này!\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.9-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Tổng quan Sau khi hoàn thành workshop, bạn cần xóa tất cả tài nguyên để tránh phát sinh chi phí không mong muốn. CloudFormation sẽ tự động xóa hầu hết các tài nguyên, nhưng một số cần xóa thủ công.\nBước 1: Xóa S3 Bucket Contents CloudFormation không thể xóa S3 buckets có chứa objects. Bạn cần xóa contents trước:\n# Lấy bucket names từ outputs FRONTEND_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`FrontendBucketName`].OutputValue\u0026#39; \\ --output text) # Xóa tất cả objects trong frontend bucket aws s3 rm s3://$FRONTEND_BUCKET --recursive --region ap-southeast-1 # Nếu có backend bucket BACKEND_BUCKET=\u0026#34;workshop-aws-dev-backend-$(aws sts get-caller-identity --query Account --output text)-ap-southeast-1\u0026#34; aws s3 rm s3://$BACKEND_BUCKET --recursive --region ap-southeast-1 2\u0026gt;/dev/null || true Bước 2: Xóa CloudFormation Stack Cách 1: Sử dụng Deploy Script Windows:\ncd aws deploy.bat delete Linux/Mac:\ncd aws ./deploy.sh delete Cách 2: Sử dụng AWS CLI aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 Bước 3: Theo dõi Quá trình Xóa # Kiểm tra status aws cloudformation describe-stacks \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;Stacks[0].StackStatus\u0026#39; # Đợi stack bị xóa hoàn toàn (có thể mất 10-15 phút) aws cloudformation wait stack-delete-complete \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 Qua AWS Console:\nMở CloudFormation Console Chọn stack workshop-aws-dev Tab Events: Xem resources đang bị xóa Stack sẽ biến mất khỏi danh sách khi xóa hoàn tất Bước 4: Xác nhận Tài nguyên đã bị Xóa Kiểm tra VPC # Không nên thấy VPC của workshop aws ec2 describe-vpcs \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 Kiểm tra EC2 Instances # Không nên thấy instances của workshop aws ec2 describe-instances \\ --filters \u0026#34;Name=tag:aws:cloudformation:stack-name,Values=workshop-aws-dev\u0026#34; \\ --region ap-southeast-1 \\ --query \u0026#39;Reservations[*].Instances[*].[InstanceId,State.Name]\u0026#39; Kiểm tra RDS # Không nên thấy RDS instance (có thể có snapshot) aws rds describe-db-instances \\ --region ap-southeast-1 \\ --query \u0026#39;DBInstances[?DBInstanceIdentifier==`workshop-aws-dev-db`]\u0026#39; Kiểm tra S3 Buckets # Buckets nên đã bị xóa aws s3 ls | grep workshop-aws-dev Bước 5: Xóa RDS Snapshots (Optional) CloudFormation tạo snapshot trước khi xóa RDS. Nếu không cần, xóa để tránh phí lưu trữ:\n# List snapshots aws rds describe-db-snapshots \\ --region ap-southeast-1 \\ --query \u0026#39;DBSnapshots[?contains(DBSnapshotIdentifier,`workshop-aws-dev`)].DBSnapshotIdentifier\u0026#39; # Xóa snapshot aws rds delete-db-snapshot \\ --db-snapshot-identifier \u0026lt;snapshot-id\u0026gt; \\ --region ap-southeast-1 Bước 6: Xóa CloudWatch Logs (Optional) Log groups không tự động bị xóa:\n# List log groups aws logs describe-log-groups \\ --log-group-name-prefix \u0026#34;/aws/workshop-aws\u0026#34; \\ --region ap-southeast-1 # Xóa log groups aws logs delete-log-group \\ --log-group-name \u0026#34;/aws/workshop-aws/dev/application\u0026#34; \\ --region ap-southeast-1 Bước 7: Xóa EC2 Key Pair (Optional) Nếu không cần key pair nữa:\naws ec2 delete-key-pair \\ --key-name workshop-aws-key \\ --region ap-southeast-1 # Xóa file .pem local rm workshop-aws-key.pem Troubleshooting Stack Deletion Failed Nếu stack deletion bị lỗi:\nXem lỗi: aws cloudformation describe-stack-events \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --query \u0026#39;StackEvents[?ResourceStatus==`DELETE_FAILED`].[LogicalResourceId,ResourceStatusReason]\u0026#39; \\ --output table Các lỗi thường gặp: Lỗi: \u0026ldquo;S3 bucket is not empty\u0026rdquo;\nXóa tất cả objects trong bucket Thử delete stack lại Lỗi: \u0026ldquo;Network interface is in use\u0026rdquo;\nĐợi vài phút để ENIs được release Thử delete stack lại Lỗi: \u0026ldquo;Resource being used by another resource\u0026rdquo;\nXác định resource dependencies Xóa dependent resources trước Force delete: # Retain problematic resources và xóa stack aws cloudformation delete-stack \\ --stack-name workshop-aws-dev \\ --region ap-southeast-1 \\ --retain-resources \u0026lt;ResourceLogicalId\u0026gt; # Sau đó xóa resources thủ công Checklist Cleanup Đảm bảo tất cả tài nguyên đã bị xóa:\nCloudFormation stack đã bị xóa S3 buckets đã bị xóa EC2 instances đã terminated RDS database đã bị xóa Load Balancer đã bị xóa VPC và subnets đã bị xóa CloudFront distribution đã bị disabled và xóa NAT Gateway đã bị xóa Elastic IPs đã bị released RDS snapshots đã bị xóa (optional) CloudWatch log groups đã bị xóa (optional) EC2 Key Pair đã bị xóa (optional) Xác nhận Không còn Chi phí Sau 24-48 giờ, kiểm tra AWS Cost Explorer để đảm bảo không còn chi phí phát sinh từ workshop.\nKết luận Bạn đã hoàn thành workshop và dọn dẹp tất cả tài nguyên thành công!\nNhững gì bạn đã học: ✅ Triển khai full-stack application trên AWS ✅ Infrastructure as Code với CloudFormation ✅ AWS networking và security best practices ✅ Cost optimization strategies ✅ Monitoring và troubleshooting\nTài nguyên tiếp theo:\nAWS Well-Architected Framework AWS Solutions Library AWS Workshops Cảm ơn bạn đã tham gia workshop! 🎉\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.8-cicd-pipeline/","title":"Thiết lập CI/CD Pipeline","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ thiết lập một CI/CD pipeline hoàn chỉnh sử dụng AWS CodePipeline, CodeBuild và GitLab CI/CD để tự động hóa quá trình build và deploy cho cả backend và frontend.\nKiến trúc GitLab → S3 (Artifacts) → CodePipeline → CodeBuild (Backend) → EC2\r↓\rCodeBuild (Frontend) → S3/CloudFront Các thành phần CI/CD 1. GitLab CI/CD Tự động build và đóng gói source code Upload artifacts lên S3 Kích hoạt AWS CodePipeline 2. AWS CodePipeline Điều phối toàn bộ quy trình deployment Giám sát S3 để phát hiện artifacts mới Kích hoạt các CodeBuild projects 3. AWS CodeBuild Backend Build: Biên dịch ứng dụng Spring Boot thành JAR Frontend Build: Build ứng dụng React với Vite Deploy lên các dịch vụ AWS tương ứng Bước 1: Cấu hình GitLab CI/CD 1.1. Thiết lập GitLab CI/CD Variables Trong GitLab project, vào Settings → CI/CD → Variables và thêm:\nVariable Value Protected Masked AWS_ACCESS_KEY_ID AWS Access Key của bạn ✅ ✅ AWS_SECRET_ACCESS_KEY AWS Secret Key của bạn ✅ ✅ 1.2. Xem lại cấu hình GitLab CI File .gitlab-ci.yml trong thư mục gốc project:\nstages: - deploy deploy-to-aws: stage: deploy image: amazon/aws-cli:latest before_script: - | aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY aws configure set region ap-southeast-1 script: - echo \u0026#34;📦 Đang tạo source.zip...\u0026#34; - | apk add zip zip -r source.zip . \\ -x \u0026#34;*.git*\u0026#34; \\ -x \u0026#34;node_modules/*\u0026#34; \\ -x \u0026#34;.idea/*\u0026#34; \\ -x \u0026#34;target/*\u0026#34; \\ -x \u0026#34;*.zip\u0026#34; - echo \u0026#34;📤 Đang upload lên S3...\u0026#34; - | aws s3 cp source.zip \\ s3://workshop-aws-dev-artifacts-502310717700-ap-southeast-1/source.zip - echo \u0026#34;✅ Upload hoàn tất! CodePipeline sẽ tự động kích hoạt.\u0026#34; only: - main when: on_success Chức năng:\nĐóng gói toàn bộ project thành source.zip Upload lên S3 artifacts bucket Tự động kích hoạt CodePipeline Bước 2: Deploy CodePipeline với CloudFormation 2.1. Xem lại Pipeline Template Template CloudFormation cicd-pipeline.yaml tạo:\nCodePipeline với S3 source CodeBuild project cho backend CodeBuild project cho frontend IAM roles và permissions 2.2. Deploy Pipeline Stack aws cloudformation create-stack \\ --stack-name workshop-aws-dev-cicd \\ --template-body file://aws/cicd-pipeline.yaml \\ --parameters \\ ParameterKey=ProjectName,ParameterValue=workshop-aws \\ ParameterKey=Environment,ParameterValue=dev \\ ParameterKey=SourceProvider,ParameterValue=S3 \\ ParameterKey=ArtifactBucketName,ParameterValue=workshop-aws-dev-artifacts-502310717700-ap-southeast-1 \\ --capabilities CAPABILITY_NAMED_IAM \\ --region ap-southeast-1 2.3. Chờ Stack tạo xong aws cloudformation wait stack-create-complete \\ --stack-name workshop-aws-dev-cicd \\ --region ap-southeast-1 Thời gian dự kiến: 3-5 phút\nBước 3: Cấu hình CodeBuild Projects 3.1. Backend BuildSpec CodeBuild sử dụng buildspec-backend.yml:\nversion: 0.2 phases: pre_build: commands: - echo \u0026#34;Đang cài đặt Maven...\u0026#34; - yum install -y maven build: commands: - echo \u0026#34;Đang build Backend JAR...\u0026#34; - cd BE/workshop_BE - mvn clean package -DskipTests post_build: commands: - echo \u0026#34;Đang upload JAR lên S3...\u0026#34; - aws s3 cp target/workshop-0.0.1-SNAPSHOT.jar \\ s3://workshop-aws-dev-backend-502310717700-ap-southeast-1/jars/ - echo \u0026#34;Đang deploy lên EC2...\u0026#34; - aws ssm send-command \\ --instance-ids i-09fdbf7739ee37b32 \\ --document-name \u0026#34;AWS-RunShellScript\u0026#34; \\ --parameters commands=[ \u0026#34;cd /opt/workshop\u0026#34;, \u0026#34;aws s3 cp s3://workshop-aws-dev-backend-502310717700-ap-southeast-1/jars/workshop-0.0.1-SNAPSHOT.jar .\u0026#34;, \u0026#34;sudo systemctl restart workshop.service\u0026#34; ] artifacts: files: - \u0026#39;**/*\u0026#39; 3.2. Frontend BuildSpec CodeBuild sử dụng buildspec-frontend.yml:\nversion: 0.2 phases: pre_build: commands: - echo \u0026#34;Đang cài đặt Node.js...\u0026#34; - curl -sL https://rpm.nodesource.com/setup_18.x | bash - - yum install -y nodejs build: commands: - echo \u0026#34;Đang build Frontend...\u0026#34; - cd FE - npm install - npm run build post_build: commands: - echo \u0026#34;Đang deploy lên S3...\u0026#34; - aws s3 sync dist/ \\ s3://workshop-aws-dev-frontend-502310717700-ap-southeast-1/ \\ --delete - echo \u0026#34;Đang invalidate CloudFront...\u0026#34; - aws cloudfront create-invalidation \\ --distribution-id E3K48K7CPOOLHZ \\ --paths \u0026#34;/*\u0026#34; artifacts: files: - \u0026#39;FE/dist/**/*\u0026#39; Bước 4: Test CI/CD Pipeline 4.1. Kích hoạt Pipeline từ GitLab Thực hiện thay đổi code và push lên branch main:\ngit add . git commit -m \u0026#34;Test CI/CD pipeline\u0026#34; git push origin main 4.2. Theo dõi GitLab Pipeline Vào GitLab → CI/CD → Pipelines Xem job deploy-to-aws Xác nhận upload lên S3 thành công 4.3. Theo dõi AWS CodePipeline Vào AWS Console → CodePipeline Chọn workshop-aws-dev-pipeline Xem các giai đoạn pipeline: Source: Phát hiện source.zip mới trong S3 Build-Backend: Build JAR và deploy lên EC2 Build-Frontend: Build React app và deploy lên S3/CloudFront 4.4. Kiểm tra Build Logs Để xem logs chi tiết:\nClick vào Details ở bất kỳ stage nào Xem Build logs trong CodeBuild Kiểm tra lỗi hoặc cảnh báo Bước 5: Xác nhận Deployment 5.1. Test Backend API curl https://98385v3jef.execute-api.ap-southeast-1.amazonaws.com/dev/dna_service/actuator/health Kết quả mong đợi:\n{\u0026#34;status\u0026#34;:\u0026#34;UP\u0026#34;} 5.2. Test Frontend Mở trình duyệt và truy cập:\nhttps://d3gmmg22uirq0t.cloudfront.net Xác nhận ứng dụng load với các thay đổi mới nhất.\nSơ đồ luồng Pipeline ┌─────────────┐\r│ GitLab │\r│ Commit │\r└──────┬──────┘\r│\r▼\r┌─────────────┐\r│ GitLab CI │\r│ Build \u0026amp; Zip │\r└──────┬──────┘\r│\r▼\r┌─────────────┐\r│ S3 Bucket │\r│ source.zip │\r└──────┬──────┘\r│\r▼\r┌─────────────────────┐\r│ CodePipeline │\r│ Phát hiện thay đổi│\r└──────┬──────────────┘\r│\r├─────────────────┬─────────────────┐\r▼ ▼ ▼\r┌─────────────┐ ┌─────────────┐ ┌─────────────┐\r│ CodeBuild │ │ CodeBuild │ │ CloudWatch │\r│ Backend │ │ Frontend │ │ Logs │\r└──────┬──────┘ └──────┬──────┘ └─────────────┘\r│ │\r▼ ▼\r┌─────────────┐ ┌─────────────┐\r│ EC2 │ │ S3 + CDN │\r│ Backend │ │ Frontend │\r└─────────────┘ └─────────────┘ Xử lý sự cố Pipeline không kích hoạt Vấn đề: CodePipeline không chạy sau khi push GitLab\nGiải pháp:\nKiểm tra S3 bucket có file source.zip Xác minh cấu hình source của CodePipeline Kiểm tra IAM permissions cho CodePipeline Backend Build thất bại Vấn đề: CodeBuild backend lỗi Maven\nGiải pháp:\nKiểm tra cú pháp buildspec-backend.yml Xác minh Maven dependencies trong pom.xml Xem CodeBuild logs để tìm lỗi cụ thể Đảm bảo EC2 instance có SSM Agent đang chạy Frontend Build thất bại Vấn đề: CodeBuild frontend lỗi npm\nGiải pháp:\nKiểm tra cú pháp buildspec-frontend.yml Xác minh dependencies trong package.json Kiểm tra tương thích phiên bản Node.js Đảm bảo S3 bucket permissions đúng Deployment thất bại Vấn đề: Build thành công nhưng deployment lỗi\nGiải pháp:\nKiểm tra EC2 Security Groups cho phép SSM Xác minh tên S3 bucket đúng Kiểm tra CloudFront distribution ID Xem lại IAM role permissions Best Practices 1. Environment Variables Lưu dữ liệu nhạy cảm trong GitLab CI/CD variables Dùng AWS Systems Manager Parameter Store cho application configs Không bao giờ commit credentials vào Git 2. Tối ưu Build Cache dependencies (Maven .m2, npm node_modules) Dùng Docker images nhỏ hơn để build nhanh hơn Chạy song song các build stages độc lập 3. Chiến lược Deployment Dùng blue-green deployment cho zero downtime Implement health checks trước khi route traffic Giữ khả năng rollback sẵn sàng 4. Monitoring Bật CloudWatch Logs cho tất cả CodeBuild projects Thiết lập SNS notifications cho pipeline failures Theo dõi build times và tối ưu bottlenecks Tối ưu Chi phí Giá CodeBuild Build minutes: $0.005 mỗi phút (general1.small) Build thông thường: 5-10 phút Chi phí mỗi build: ~$0.025-0.05 Giá CodePipeline Active pipeline: $1.00 mỗi tháng Free tier: 1 active pipeline mỗi tháng Ước tính Chi phí Hàng tháng 10 deployments/ngày: ~$15-20/tháng Bao gồm: CodePipeline + CodeBuild + S3 storage Tóm tắt Bạn đã thiết lập thành công một CI/CD pipeline hoàn chỉnh:\n✅ Tự động build và đóng gói code từ GitLab\n✅ Upload artifacts lên S3\n✅ Kích hoạt AWS CodePipeline khi có thay đổi\n✅ Build backend JAR với Maven\n✅ Build frontend với Vite\n✅ Deploy backend lên EC2\n✅ Deploy frontend lên S3/CloudFront\n✅ Cung cấp monitoring và logging\nTiếp theo: Dọn dẹp Tài nguyên\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]