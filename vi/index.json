[{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;Building Agentic AI: Context Optimization with Amazon Bedrock\u0026rdquo; Mục Đích Của Sự Kiện Giới thiệu về Building Agentic AI và Context Optimization với Amazon Bedrock Xây dựng autonomous AI agents với Amazon Bedrock thông qua hands-on techniques Chia sẻ real-world use cases về agentic workflows Giới thiệu CloudThinker và giải pháp Agentic Orchestration Cung cấp hands-on workshop với môi trường AWS thực tế Kết nối với các chuyên gia AWS và AI practitioners Chi Tiết Sự Kiện Ngày: Thứ Sáu, 05 tháng 12 năm 2025 Thời gian: 9:00 – 12:00 (Check-in từ 8:15) Địa điểm: Tầng 26, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh Thời lượng: 3 giờ (bao gồm tea break, networking và lunch buffet) Chương Trình 9:00 – 9:10 | Khai mạc (10 phút) Nguyen Gia Hung, Head of Solutions Architect, AWS\nChào mừng và giới thiệu sự kiện Tổng quan về Building Agentic AI Context Optimization với Amazon Bedrock 9:10 – 9:40 | AWS Bedrock Agent Core (30 phút) Kien Nguyen, Solutions Architect, AWS\nGiới thiệu AWS Bedrock Agent Kiến trúc và các thành phần chính Cách thức hoạt động của Bedrock Agent Context management và optimization Tích hợp với các dịch vụ AWS khác Demo: Tạo và cấu hình Bedrock Agent cơ bản 9:40 – 10:00 | [Use Case] Building Agentic Workflow on AWS (20 phút) Viet Pham, Founder \u0026amp; CEO, Diaflow\nUse case thực tế về building agentic workflow Kiến trúc và best practices Challenges và solutions Context optimization trong production Demo: Agentic workflow trong thực tế 10:00 – 10:10 | CloudThinker Introduction (10 phút) Thang Ton, Co-founder \u0026amp; COO, CloudThinker\nGiới thiệu về CloudThinker Giải pháp Agentic Orchestration Tầm nhìn và roadmap Integration với Amazon Bedrock 10:10 – 10:40 | CloudThinker Agentic Orchestration, Context Optimization on Amazon Bedrock (L300) (30 phút) Henry Bui, Head of Engineering, CloudThinker\nAgentic orchestration patterns Context optimization techniques nâng cao Tích hợp với Amazon Bedrock Advanced use cases và best practices Performance optimization Cost optimization strategies Demo: CloudThinker platform 10:40 – 11:00 | Tea Break \u0026amp; Networking (20 phút) Nghỉ giải lao Networking với các chuyên gia và participants Q\u0026amp;A không chính thức Complimentary refreshments 11:00 – 12:00 | CloudThinker Hack: Hands-on Workshop (60 phút) Kha Van, Community Leader, AWS\nHands-on workshop với môi trường AWS thực tế Xây dựng Bedrock Agent từ đầu Thực hành context optimization Agentic orchestration patterns Troubleshooting và best practices Q\u0026amp;A và hỗ trợ trực tiếp 12:00 Onwards | Networking \u0026amp; Lunch Buffet Networking mở rộng Lunch buffet Gặp gỡ các chuyên gia Chia sẻ experiences và learnings Meet Our Experts Nguyen Gia Hung Head of Solutions Architect, AWS\nChuyên gia hàng đầu về AWS architecture và solutions Kinh nghiệm sâu rộng trong việc tư vấn và triển khai giải pháp cloud Người dẫn dắt các chương trình AWS tại Việt Nam Kien Nguyen Solutions Architect, AWS\nChuyên gia về AWS Bedrock và AI services Kinh nghiệm trong việc xây dựng AI/ML solutions Expert về agentic AI và context optimization Viet Pham Founder \u0026amp; CEO, Diaflow\nEntrepreneur với kinh nghiệm trong AI và cloud computing Chuyên gia về agentic workflows và automation Founder của Diaflow - giải pháp AI workflow Kha Van Community Leader, AWS\nAWS Community Leader Chuyên gia về hands-on training và workshops Mentor cho AWS community Thang Ton Co-Founder \u0026amp; COO, CloudThinker\nCo-founder của CloudThinker Chuyên gia về cloud orchestration và automation Expert về agentic orchestration platforms Henry Bui Head of Engineering, CloudThinker\nChuyên gia về agentic orchestration Kinh nghiệm trong việc tối ưu hóa context và performance Expert về L300 technical deep-dive sessions Nội Dung Nổi Bật Building Agentic AI Giới thiệu Agentic AI:\nAgentic AI là gì và tại sao quan trọng Autonomous AI agents vs traditional AI Use cases và applications Future of AI với agentic systems Context Optimization:\nTại sao context optimization quan trọng Techniques để optimize context Cost reduction strategies Performance improvement Best practices AWS Bedrock Agent Core Kiến trúc Bedrock Agent:\nAgent: Entity chính thực hiện các tác vụ Knowledge Base: Nguồn thông tin cho agent Action Groups: Các hành động agent có thể thực hiện Orchestration: Quản lý flow và context Context Management: Tối ưu hóa context Tính năng chính:\nNatural language understanding Context management và optimization Multi-step reasoning Integration với AWS services Custom actions và workflows Agentic Workflow Use Case Building Agentic Workflow:\nThiết kế workflow phức tạp với nhiều agents Orchestration và coordination giữa các agents Context optimization trong workflows Error handling và retry logic Monitoring và observability Best Practices:\nDesign patterns cho agentic workflows Context management strategies Performance optimization Cost optimization Security và compliance CloudThinker Agentic Orchestration Agentic Orchestration Patterns:\nSequential workflows Parallel execution Conditional branching Error recovery và fallback Context sharing giữa agents Context Optimization Techniques:\nContext compression và summarization Relevant information extraction Memory management Cost optimization strategies Performance tuning Integration với Amazon Bedrock:\nSeamless integration với Bedrock models Custom model selection Prompt engineering và optimization Response formatting và validation Context optimization APIs Những Gì Học Được Hiểu về Building Agentic AI Agentic AI là gì: Autonomous AI agents có khả năng thực hiện tasks độc lập Context Optimization: Techniques để optimize context và giảm costs Use cases: Các trường hợp sử dụng thực tế cho agentic AI Architecture: Kiến trúc và design patterns AWS Bedrock Agent Bedrock Agent Core: Hiểu cách agent hoạt động và tương tác Context Management: Quản lý và optimize context Integration: Cách tích hợp với các AWS services khác Best Practices: Best practices từ AWS experts Agentic Workflow Design Workflow patterns: Các pattern phổ biến cho agentic workflows Orchestration: Cách quản lý và điều phối nhiều agents Context Optimization: Strategies cho context optimization Error handling: Strategies cho xử lý lỗi và recovery CloudThinker Platform Agentic orchestration: Cách CloudThinker giải quyết orchestration challenges Context optimization: Advanced techniques để optimize context Platform capabilities: Các tính năng và khả năng của CloudThinker Integration patterns: Cách tích hợp CloudThinker vào existing systems Hands-on Experience Practical skills: Kỹ năng thực tế trong việc xây dựng Bedrock Agents Context optimization: Thực hành context optimization techniques Troubleshooting: Cách debug và troubleshoot common issues Real-world scenarios: Làm việc với các scenarios thực tế Ứng Dụng Vào Công Việc Xây dựng Agentic AI: Sử dụng AWS Bedrock Agent để xây dựng autonomous AI agents Context Optimization: Áp dụng context optimization techniques để giảm costs và improve performance Thiết kế Workflows: Áp dụng agentic workflow patterns vào các dự án Tích hợp CloudThinker: Đánh giá và tích hợp CloudThinker vào existing solutions Best Practices: Áp dụng best practices từ workshop vào production systems Trải nghiệm trong event Tham gia workshop \u0026ldquo;Building Agentic AI: Context Optimization with Amazon Bedrock\u0026rdquo; là một trải nghiệm học tập chuyên sâu về agentic AI và context optimization. Sự kiện cung cấp cả kiến thức lý thuyết và hands-on practice, giúp em hiểu rõ về cách xây dựng và tối ưu hóa autonomous AI agents.\nOpening và giới thiệu Opening session của Nguyen Gia Hung tạo không khí chuyên nghiệp và inspiring. Em hiểu về tầm quan trọng của Building Agentic AI và Context Optimization. Overview về event agenda giúp em hình dung rõ hành trình học tập. AWS Bedrock Agent Core Session của Kien Nguyen cung cấp foundation vững chắc về Bedrock Agent. Em học về kiến trúc, components, và cách thức hoạt động của Bedrock Agent. Context management là điểm nhấn quan trọng trong session này. Demo tạo Bedrock Agent cho thấy quy trình thực tế từ đầu đến cuối. Use Case thực tế Use case presentation của Viet Pham minh họa cách agentic workflows được sử dụng trong production. Học về challenges thực tế và cách giải quyết chúng. Context optimization trong production rất practical và insightful. Demo agentic workflow cho thấy performance và capabilities trong thực tế. CloudThinker Platform CloudThinker introduction của Thang Ton giới thiệu về platform và giải pháp. L300 session của Henry Bui đi sâu vào technical details và advanced patterns. Học về context optimization techniques nâng cao để improve performance và reduce costs. Demo CloudThinker platform cho thấy capabilities và ease of use. Hands-on Workshop Hands-on workshop của Kha Van cung cấp cơ hội thực hành trực tiếp. Xây dựng Bedrock Agent từ đầu với guidance từ expert. Thực hành context optimization và agentic orchestration. Troubleshooting session giúp em hiểu cách giải quyết common issues. Q\u0026amp;A trực tiếp cung cấp answers cho specific questions. Networking và kết nối Networking sessions cho phép kết nối với các AWS experts và AI practitioners. Chia sẻ experiences và learnings với other participants. Lunch buffet tạo cơ hội cho informal discussions và connections. Gặp gỡ các chuyên gia và nhận advice về career development. Bài học rút ra Agentic AI là tương lai: Autonomous AI agents sẽ thay đổi cách chúng ta xây dựng AI applications. Context Optimization là key: Optimizing context có thể significantly reduce costs và improve performance. Hands-on practice is essential: Practical experience là crucial để truly understand và apply concepts. Platform solutions matter: CloudThinker và các platforms tương tự simplify việc xây dựng agentic systems. Community is valuable: Networking với experts và practitioners cung cấp valuable insights và opportunities. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop này cung cấp cho em kiến thức toàn diện về Building Agentic AI và Context Optimization với Amazon Bedrock. Sự kết hợp giữa lý thuyết, use cases thực tế, và hands-on practice cho em tự tin để bắt đầu xây dựng autonomous AI agents trên AWS. Đặc biệt, phần về context optimization và hands-on workshop cung cấp practical skills có thể áp dụng ngay vào công việc. Workshop này là essential cho bất kỳ ai muốn hiểu sâu về agentic AI và cách optimize context để giảm costs và improve performance.\nWhat\u0026rsquo;s Included: ✓ Technical deep-dive sessions (L300)\n✓ Live demos and use case presentations\n✓ Hands-on workshop with real AWS environments\n✓ Networking with AWS experts and AI practitioners\n✓ Complimentary refreshments and lunch buffet\nIMPORTANT: Please bring your laptop to participate in the hands-on exercises\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; Mục Đích Của Sự Kiện Giới thiệu AWS Well-Architected Framework Security Pillar Trình diễn 5 pillars chính của Security: IAM, Detection, Infrastructure Protection, Data Protection, và Incident Response Chia sẻ best practices và nguyên tắc cốt lõi về cloud security Cung cấp kiến thức thực tế về các threats và cách phòng chống tại Việt Nam Hướng dẫn xây dựng security architecture theo chuẩn AWS Well-Architected Kết nối với các chuyên gia security và cloud practitioners Chi Tiết Sự Kiện Ngày: Thứ Bảy, 29 tháng 11 năm 2025 Thời gian: 08:30 – 12:00 Địa điểm: AWS Vietnam Office, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh Thời lượng: 3.5 giờ (bao gồm coffee break) Chương Trình 8:30 – 8:50 | Khai mạc \u0026amp; Security Foundation (20 phút) Vai trò Security Pillar trong Well-Architected Framework Nguyên tắc cốt lõi: Least Privilege: Cấp quyền tối thiểu cần thiết Zero Trust: Không tin tưởng mặc định, luôn xác minh Defense in Depth: Bảo vệ nhiều lớp Shared Responsibility Model: Trách nhiệm của AWS và khách hàng Top threats trong môi trường cloud tại Việt Nam Q\u0026amp;A ⭐ Pillar 1 — Identity \u0026amp; Access Management 8:50 – 9:30 | Modern IAM Architecture (40 phút) IAM Fundamentals:\nUsers, Roles, Policies – tránh long-term credentials Best practices cho IAM setup Temporary credentials và session management IAM Identity Center:\nSingle Sign-On (SSO) configuration Permission sets và assignment Multi-account management Advanced IAM:\nService Control Policies (SCP) cho multi-account Permission boundaries để giới hạn quyền MFA (Multi-Factor Authentication) requirements Credential rotation strategies Access Analyzer để phát hiện external access Mini Demo: Validate IAM Policy + simulate access\nKiểm tra policy syntax và permissions Mô phỏng access scenarios Troubleshooting common IAM issues ⭐ Pillar 2 — Detection 9:30 – 9:55 | Detection \u0026amp; Continuous Monitoring (25 phút) AWS Security Services:\nCloudTrail: Organization-level logging và audit GuardDuty: Threat detection và intelligent security Security Hub: Centralized security findings Comprehensive Logging:\nVPC Flow Logs: Network traffic monitoring ALB Access Logs: Application layer monitoring S3 Access Logs: Object access tracking Logging tại mọi tầng của infrastructure Alerting \u0026amp; Automation:\nEventBridge rules cho security events Automated response workflows Integration với notification systems Detection-as-Code:\nInfrastructure as Code cho security rules Version control cho detection rules Automated deployment và testing 9:55 – 10:10 | Coffee Break (15 phút) Nghỉ giải lao Networking với các participants Q\u0026amp;A không chính thức ⭐ Pillar 3 — Infrastructure Protection 10:10 – 10:40 | Network \u0026amp; Workload Security (30 phút) Network Security:\nVPC Segmentation: Tách biệt network segments Private vs Public placement strategies Network isolation và security zones Security Groups vs NACLs:\nKhi nào sử dụng Security Groups Khi nào sử dụng NACLs Mô hình áp dụng thực tế Best practices và common mistakes Advanced Network Protection:\nAWS WAF: Web Application Firewall AWS Shield: DDoS protection Network Firewall: Managed network firewall service Workload Protection:\nEC2 Security: Instance hardening, patch management ECS Security: Container security best practices EKS Security: Kubernetes security fundamentals Security baselines và compliance ⭐ Pillar 4 — Data Protection 10:40 – 11:10 | Encryption, Keys \u0026amp; Secrets (30 phút) AWS KMS (Key Management Service):\nKey policies và access control Grants và delegation Key rotation strategies Multi-region key management Encryption at Rest:\nS3: Server-side encryption (SSE-S3, SSE-KMS, SSE-C) EBS: Volume encryption và snapshots RDS: Database encryption DynamoDB: Table encryption Encryption in Transit:\nTLS/SSL best practices Certificate management End-to-end encryption Secrets Management:\nSecrets Manager: Automated rotation patterns Parameter Store: Secure parameter storage Rotation patterns và best practices Integration với applications Data Classification \u0026amp; Access Guardrails:\nData classification frameworks Access controls based on classification Compliance và regulatory requirements ⭐ Pillar 5 — Incident Response 11:10 – 11:40 | IR Playbook \u0026amp; Automation (30 phút) IR Lifecycle theo AWS:\nPrepare: Chuẩn bị và planning Detect: Phát hiện incidents Respond: Phản ứng và containment Recover: Khôi phục và lessons learned IR Playbooks cho Common Scenarios:\n1. Compromised IAM Key:\nPhát hiện compromised credentials Immediate response steps Key rotation và access revocation Investigation và forensics 2. S3 Public Exposure:\nPhát hiện public buckets Immediate remediation Access review và audit Prevention strategies 3. EC2 Malware Detection:\nPhát hiện malware và suspicious activity Isolation procedures Evidence collection Cleanup và recovery Automated Response:\nLambda functions cho automated response Step Functions cho complex workflows Integration với security services Playbook automation patterns Evidence Collection:\nSnapshot creation cho forensics Log preservation Chain of custody Compliance với legal requirements 11:40 – 12:00 | Wrap-Up \u0026amp; Q\u0026amp;A (20 phút) Tổng kết 5 pillars của Security Common pitfalls và mistakes thường gặp Thực tế doanh nghiệp Việt Nam: Security challenges tại Việt Nam Compliance requirements Best practices cho local context Roadmap security learning: AWS Certified Security – Specialty AWS Certified Solutions Architect – Professional Security training paths Q\u0026amp;A session Chụp ảnh lưu niệm Nội Dung Nổi Bật Security Foundation Principles Least Privilege:\nChỉ cấp quyền tối thiểu cần thiết để thực hiện công việc Regular review và audit permissions Sử dụng temporary credentials thay vì long-term keys Principle of least privilege trong mọi layer Zero Trust:\nKhông tin tưởng mặc định, luôn xác minh Verify identity và authorization cho mọi request Network segmentation và micro-segmentation Continuous verification và monitoring Defense in Depth:\nBảo vệ nhiều lớp: Network, Application, Data, Identity Không phụ thuộc vào một lớp bảo vệ duy nhất Layered security controls Fail-safe defaults Shared Responsibility Model:\nAWS: Security OF the cloud (infrastructure) Customer: Security IN the cloud (data, applications, configurations) Hiểu rõ trách nhiệm của mỗi bên Best practices cho customer responsibilities Pillar 1: Identity \u0026amp; Access Management Modern IAM Architecture:\nSử dụng IAM Roles thay vì Users khi có thể Temporary credentials với STS IAM Identity Center cho SSO Permission boundaries và SCPs Best Practices:\nEnable MFA cho tất cả users Regular credential rotation Use Access Analyzer để phát hiện external access Least privilege policies Regular access reviews Pillar 2: Detection Comprehensive Monitoring:\nCloudTrail cho audit trail GuardDuty cho threat detection Security Hub cho centralized view VPC Flow Logs cho network monitoring Detection-as-Code:\nVersion control cho detection rules Automated testing CI/CD cho security rules Infrastructure as Code approach Pillar 3: Infrastructure Protection Network Security:\nVPC segmentation Security Groups và NACLs WAF, Shield, Network Firewall Private subnets và NAT gateways Workload Security:\nEC2 hardening Container security Kubernetes security Patch management Pillar 4: Data Protection Encryption:\nEncryption at rest với KMS Encryption in transit với TLS Key management best practices Secrets management Data Classification:\nClassify data by sensitivity Apply appropriate controls Access guardrails Compliance requirements Pillar 5: Incident Response IR Lifecycle:\nPrepare: Planning và tools Detect: Monitoring và alerting Respond: Containment và investigation Recover: Restoration và lessons learned Automation:\nAutomated response với Lambda Step Functions cho workflows Integration với security services Playbook automation Những Gì Học Được Security Foundation Well-Architected Framework: Hiểu về Security Pillar và vai trò Core Principles: Least Privilege, Zero Trust, Defense in Depth Shared Responsibility: Trách nhiệm của AWS và customer Threat Landscape: Top threats tại Việt Nam và cách phòng chống IAM Best Practices Modern IAM: Sử dụng roles, temporary credentials IAM Identity Center: SSO và permission management Advanced Features: SCPs, permission boundaries, Access Analyzer Security: MFA, credential rotation, least privilege Detection \u0026amp; Monitoring Security Services: CloudTrail, GuardDuty, Security Hub Comprehensive Logging: VPC Flow Logs, ALB logs, S3 logs Alerting: EventBridge và automation Detection-as-Code: Infrastructure as Code cho security Infrastructure Protection Network Security: VPC segmentation, Security Groups, NACLs Advanced Protection: WAF, Shield, Network Firewall Workload Security: EC2, ECS, EKS security Best Practices: Hardening và patch management Data Protection Encryption: At rest và in transit KMS: Key management và rotation Secrets Management: Secrets Manager và Parameter Store Data Classification: Access guardrails và compliance Incident Response IR Lifecycle: Prepare, Detect, Respond, Recover Playbooks: Common scenarios và response procedures Automation: Lambda và Step Functions Forensics: Evidence collection và preservation Ứng Dụng Vào Công Việc Thiết kế Security Architecture: Áp dụng 5 pillars vào architecture design Implement IAM Best Practices: Sử dụng modern IAM patterns Setup Detection: Triển khai comprehensive monitoring Protect Infrastructure: Áp dụng network và workload security Protect Data: Implement encryption và secrets management Prepare IR: Xây dựng incident response playbooks và automation Security Reviews: Regular security assessments và improvements Trải nghiệm trong event Tham gia workshop \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; là một trải nghiệm học tập chuyên sâu về cloud security. Sự kiện cung cấp kiến thức toàn diện về 5 pillars của Security và best practices thực tế, giúp em hiểu rõ cách xây dựng secure cloud architecture.\nSecurity Foundation Opening session giới thiệu về Security Pillar trong Well-Architected Framework. Em học về các nguyên tắc cốt lõi: Least Privilege, Zero Trust, Defense in Depth. Shared Responsibility Model giúp em hiểu rõ trách nhiệm của AWS và customer. Top threats tại Việt Nam cung cấp context thực tế cho security challenges. Modern IAM Architecture IAM session đi sâu vào modern IAM patterns và best practices. Học về IAM Identity Center cho SSO và multi-account management. Advanced features như SCPs và permission boundaries rất hữu ích. Demo validate IAM policy cho thấy practical approach để test policies. Detection \u0026amp; Continuous Monitoring Detection session bao phủ comprehensive monitoring strategy. CloudTrail, GuardDuty, và Security Hub tạo thành security monitoring stack mạnh mẽ. Logging tại mọi tầng giúp em hiểu về defense in depth. Detection-as-Code approach rất innovative và practical. Network \u0026amp; Workload Security Infrastructure Protection session đi sâu vào network security. Hiểu rõ khi nào sử dụng Security Groups vs NACLs. Advanced protection với WAF, Shield, Network Firewall. Workload security cho EC2, ECS, EKS cung cấp practical guidance. Data Protection Data Protection session bao phủ encryption và secrets management. KMS key management và rotation strategies rất quan trọng. Encryption at rest và in transit cho tất cả services. Secrets Manager patterns cho automated rotation. Incident Response IR session cung cấp practical playbooks cho common scenarios. Học về IR lifecycle và best practices. Automated response với Lambda và Step Functions rất powerful. Evidence collection procedures cho forensics và compliance. Wrap-up và Q\u0026amp;A Wrap-up session tổng kết 5 pillars một cách comprehensive. Common pitfalls giúp em tránh những mistakes thường gặp. Thực tế doanh nghiệp Việt Nam cung cấp local context. Roadmap learning cho security certifications rất hữu ích. Bài học rút ra Security là foundation: Phải thiết kế security từ đầu, không phải add-on sau. Defense in Depth: Không phụ thuộc vào một lớp bảo vệ duy nhất. Automation is key: Automated detection và response giảm response time. Continuous improvement: Security là ongoing process, không phải one-time setup. Compliance matters: Hiểu về regulatory requirements và best practices. Practice makes perfect: Cần thực hành và review thường xuyên. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop này cung cấp cho em kiến thức toàn diện về AWS Well-Architected Security Pillar. Sự kết hợp giữa lý thuyết, best practices, và practical demos cho em foundation vững chắc để xây dựng secure cloud architecture. Đặc biệt, phần về incident response và automation cung cấp practical skills có thể áp dụng ngay vào công việc. Workshop này là essential cho bất kỳ ai muốn hiểu sâu về cloud security trên AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Thiết lập CI/CD Pipeline: Kết nối GitLab repository với AWS CodePipeline cho automated deployments. Cấu hình AWS CodeBuild cho frontend và backend builds với automatic S3 upload và CloudFront invalidation. Triển khai SSH-less deployment cho backend sử dụng AWS Systems Manager hoặc CodeDeploy. Thiết lập monitoring toàn diện với CloudWatch logs, metrics, và enhanced monitoring cho EC2 và RDS. Cấu hình AWS CloudTrail cho audit logging và security compliance. Thiết lập SNS Alerts với CloudWatch alarms cho critical metrics (EC2 CPU, RDS connections, API 5xx errors). Thực hiện end-to-end testing và tạo final project documentation với complete architecture diagram. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 19 - Tích hợp GitLab với CodePipeline: + Tạo GitLab repository cho dự án (nếu chưa tạo). + Thiết lập AWS CodePipeline với source stage kết nối với GitLab repository. + Cấu hình webhook hoặc polling cho automatic pipeline triggers trên code commits. + Tạo S3 bucket cho pipeline artifacts storage. + Kiểm tra pipeline trigger bằng cách tạo test commit vào GitLab repository. + Xác minh CodePipeline có thể kết nối thành công với GitLab và retrieve source code. 16/11/2025 16/11/2025 Tài liệu CodePipeline 20 - CodeBuild cho Frontend: + Tạo CodeBuild project cho frontend build process. + Cấu hình buildspec.yml file cho frontend build steps (install dependencies, build assets, optimize). + Thiết lập CodeBuild environment với Docker image phù hợp (Node.js, npm, v.v.). + Cấu hình build output để upload built files lên S3 bucket (FE Bucket). + Thiết lập automatic CloudFront invalidation sau khi upload S3 (invalidate cache cho updated files). + Kiểm tra frontend build process và xác minh files được upload lên S3 và CloudFront cache được invalidate. 17/11/2025 17/11/2025 Tài liệu CodeBuild 21 - CodeBuild cho Backend \u0026amp; SSH-less Deployment: + Tạo CodeBuild project cho backend build process. + Cấu hình buildspec.yml cho backend build steps (compile, test, package artifacts). + Thiết lập CodeBuild environment cho backend (Java/Python/Node.js dựa trên application). + Cấu hình artifact upload lên S3 hoặc CodeDeploy. + Triển khai SSH-less deployment sử dụng AWS Systems Manager (SSM) hoặc CodeDeploy: - Option 1: Sử dụng SSM Run Command để deploy lên EC2 instances mà không cần SSH. - Option 2: Sử dụng CodeDeploy để deploy application lên Auto Scaling Group. + Kiểm tra backend build và deployment process end-to-end. 18/11/2025 18/11/2025 Tài liệu CodeDeploy / SSM 22 - Thiết lập CloudWatch Logs \u0026amp; Metrics: + Tạo CloudWatch log groups cho EC2 application logs. + Cấu hình CloudWatch agent trên EC2 instances để gửi logs và custom metrics. + Thiết lập CloudWatch metrics cho EC2: CPU utilization, memory, disk I/O, network. + Bật RDS Enhanced Monitoring cho detailed database metrics. + Cấu hình API Gateway access logs vào CloudWatch Logs. + Tạo CloudWatch dashboards cho monitoring application health và performance. + Cấu hình log retention policies cho cost optimization. 19/11/2025 19/11/2025 Tài liệu CloudWatch 23 - CloudTrail \u0026amp; Audit Dashboard: + Bật AWS CloudTrail cho API call logging trên tất cả AWS services. + Tạo CloudTrail trail với S3 bucket cho log storage. + Cấu hình CloudTrail log file validation và encryption. + Thiết lập CloudWatch Logs integration cho CloudTrail events (tùy chọn). + Tạo CloudWatch dashboard cho audit và security monitoring. + Xem xét CloudTrail logs để xác minh API call logging hoạt động đúng. + Tài liệu hóa CloudTrail configuration và log retention policies. 20/11/2025 20/11/2025 Tài liệu CloudTrail 24 - SNS Alerts \u0026amp; CloudWatch Alarms: + Tạo SNS topic cho alarm notifications. + Subscribe email/SMS endpoints vào SNS topic. + Tạo CloudWatch alarm cho EC2 CPU utilization (threshold: \u0026gt;80% trong 5 phút). + Tạo CloudWatch alarm cho RDS database connections (threshold: \u0026gt;80% của max connections). + Tạo CloudWatch alarm cho API Gateway 5xx errors (threshold: \u0026gt;10 errors trong 5 phút). + Cấu hình alarm actions để gửi notifications qua SNS. + Kiểm tra alarms bằng cách trigger conditions và xác minh email/SMS notifications được nhận. 21/11/2025 21/11/2025 CloudWatch Alarms \u0026amp; SNS 25 - End-to-End Testing \u0026amp; Tài liệu Cuối cùng: + Thực hiện comprehensive end-to-end testing: Users → Route 53 → CloudFront → WAF → API Gateway → EC2 → RDS. + Kiểm tra CI/CD pipeline với code changes: xác minh automated frontend và backend deployments. + Kiểm tra monitoring và alerting: trigger alarms và xác minh SNS notifications được nhận. + Kiểm tra security: xác minh IAM permissions, Cognito authentication, Secrets Manager access, WAF protection. + Kiểm tra scalability: xác minh Auto Scaling Group phản hồi với load changes. + Tạo final architecture diagram với tất cả components, data flows, và resource relationships. + Viết comprehensive project documentation: deployment procedures, troubleshooting guides, runbooks, và architecture overview. + Chuẩn bị Worklog summary cho tất cả 4 tuần (Tuần 8-11). - Tóm tắt tuần 11: Complete AWS web application architecture được triển khai với CI/CD, monitoring, security, và automation. Dự án sẵn sàng cho production use. 22/11/2025 22/11/2025 Tài liệu dự án Kết quả đạt được trong tuần 11: Thiết lập thành công CI/CD Pipeline:\nKết nối GitLab repository với AWS CodePipeline cho automated deployments. Cấu hình automatic pipeline triggers trên code commits (webhook hoặc polling). Tạo S3 bucket cho pipeline artifacts storage. Xác minh end-to-end pipeline connectivity và source code retrieval. Cấu hình CodeBuild cho Frontend:\nTạo CodeBuild project với buildspec.yml cho frontend build automation. Cấu hình build environment với Docker image và dependencies phù hợp. Thiết lập automatic S3 upload của built frontend files. Triển khai automatic CloudFront cache invalidation sau deployments. Xác minh frontend build và deployment process hoạt động đúng. Triển khai CodeBuild cho Backend với SSH-less Deployment:\nTạo CodeBuild project cho backend build automation. Cấu hình buildspec.yml cho backend compilation, testing, và packaging. Triển khai SSH-less deployment sử dụng AWS Systems Manager (SSM) hoặc CodeDeploy. Loại bỏ nhu cầu SSH keys và cải thiện security posture. Xác minh backend build và deployment process hoạt động end-to-end. Thiết lập CloudWatch Monitoring toàn diện:\nTạo CloudWatch log groups cho EC2 application logs. Cấu hình CloudWatch agent trên EC2 instances cho logs và custom metrics. Thiết lập CloudWatch metrics cho EC2 (CPU, memory, disk, network). Bật RDS Enhanced Monitoring cho detailed database insights. Cấu hình API Gateway access logs vào CloudWatch Logs. Tạo CloudWatch dashboards cho real-time monitoring. Cấu hình log retention policies cho cost optimization. Cấu hình CloudTrail cho Audit và Compliance:\nBật CloudTrail cho comprehensive API call logging. Tạo CloudTrail trail với S3 bucket cho secure log storage. Cấu hình log file validation và encryption. Thiết lập CloudWatch dashboard cho audit monitoring. Thiết lập audit trail cho security và compliance requirements. Triển khai SNS Alerts và CloudWatch Alarms:\nTạo SNS topic cho alarm notifications với email/SMS subscriptions. Tạo CloudWatch alarm cho EC2 CPU utilization monitoring. Tạo CloudWatch alarm cho RDS database connection monitoring. Tạo CloudWatch alarm cho API Gateway 5xx error detection. Cấu hình alarm actions để gửi notifications qua SNS. Kiểm tra alarms và xác minh notification delivery. Thực hiện comprehensive end-to-end testing:\nXác minh complete application flow: Users → Route 53 → CloudFront → WAF → API Gateway → EC2 → RDS. Kiểm tra CI/CD pipeline với code changes và xác minh automated deployments. Kiểm tra monitoring và alerting: trigger alarms và xác minh SNS notifications. Kiểm tra security: xác minh IAM permissions, Cognito authentication, Secrets Manager, WAF protection. Kiểm tra scalability: xác minh Auto Scaling Group phản hồi với load changes. Tạo final project documentation:\nTạo comprehensive architecture diagram với tất cả components, data flows, và resource relationships. Tài liệu hóa deployment procedures, troubleshooting guides, và runbooks. Chuẩn bị architecture overview và system design documentation. Hoàn tất Worklog summary cho tất cả 4 tuần (Tuần 8-11). Sau tuần 11, complete AWS web application architecture đã được triển khai đầy đủ, monitored, secured, và automated:\nEdge Layer: Route 53, CloudFront, AWS WAF, ACM Certificate, S3 (Frontend). Networking Layer: VPC, public/private subnets, Internet Gateway, NAT Gateway, Security Groups, VPC Flow Logs. Compute \u0026amp; Database Layer: EC2 (với Auto Scaling), RDS, API Gateway, Cognito. CI/CD Pipeline: GitLab, CodePipeline, CodeBuild (Frontend \u0026amp; Backend), SSH-less deployment. Monitoring \u0026amp; Security: CloudWatch (Logs, Metrics, Dashboards, Alarms), CloudTrail, SNS Alerts, IAM, Secrets Manager. Dự án thể hiện một AWS architecture production-ready, scalable, secure, và well-monitored theo best practices với complete automation và observability.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Triển khai Backend Layer: EC2 instances trong private subnet với application runtime và cấu hình Auto Scaling. Thiết lập Amazon RDS database trong private subnet với cấu hình và parameter groups phù hợp. Deploy backend application và thiết lập kết nối giữa EC2 và RDS sử dụng Secrets Manager. Cấu hình API Gateway REST API với tích hợp EC2 backend. Tích hợp Amazon Cognito User Pool với API Gateway cho authentication và authorization. Cấu hình Auto Scaling Group cho EC2 instances với Launch Template cho scalability. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 13 - Thiết lập RDS Database: + Tạo RDS subnet group bao phủ private subnet (10.0.2.0/24). + Launch RDS instance (MySQL/PostgreSQL) trong private subnet với instance class phù hợp. + Cấu hình RDS parameter group với database-specific settings (character set, timezone, v.v.). + Thiết lập automated backups, encryption at rest, và Multi-AZ deployment (tùy chọn cho cost optimization). + Cấu hình RDS security group để chỉ cho phép kết nối từ EC2 Security Group. + Lưu trữ database credentials ban đầu trong AWS Secrets Manager. 09/11/2025 09/11/2025 Tài liệu RDS 14 - Thiết lập EC2 Backend Instance: + Launch EC2 instance trong private subnet (10.0.2.0/24) với instance type phù hợp. + Cài đặt application runtime environment: Java/Python/Node.js dựa trên yêu cầu application. + Cài đặt và cấu hình application dependencies và libraries. + Cấu hình EC2 instance với IAM role (đã tạo trong tuần 9) cho AWS service access. + Tạo base AMI từ EC2 instance đã cấu hình cho Auto Scaling Group (sẽ sử dụng ở Ngày 18). + Tài liệu hóa cấu hình EC2 và application setup steps. 10/11/2025 10/11/2025 Tài liệu EC2 15 - Deployment Backend Application: + Deploy backend application code lên EC2 instance (manual deployment cho initial setup). + Cấu hình application để kết nối với RDS database sử dụng credentials từ Secrets Manager. + Kiểm tra database connectivity từ EC2 instance (xác minh connection string, credentials retrieval). + Cấu hình application environment variables và configuration files. + Kiểm tra basic application functionality và database operations (CRUD operations). + Tài liệu hóa deployment process và application configuration. 11/11/2025 11/11/2025 Hướng dẫn deployment 16 - Cấu hình API Gateway REST API: + Tạo REST API trong API Gateway với tên và mô tả phù hợp. + Định nghĩa API resources và methods (GET, POST, PUT, DELETE) dựa trên yêu cầu application. + Cấu hình API Gateway integration với EC2 backend (HTTP/HTTPS integration hoặc VPC Link cho private resources). + Thiết lập API Gateway VPC Link để kết nối với private subnet resources (EC2). + Bật CORS cho frontend access (cấu hình CORS headers: Access-Control-Allow-Origin, v.v.). + Kiểm tra API endpoints và xác minh tích hợp với EC2 backend. 12/11/2025 12/11/2025 Tài liệu API Gateway 17 - Tích hợp Amazon Cognito: + Tạo Cognito User Pool cho user authentication với tên phù hợp. + Cấu hình user pool settings: password policies (minimum length, complexity), MFA (tùy chọn), email verification. + Tạo Cognito User Pool App Client cho application integration. + Cấu hình Cognito Authorizer trong API Gateway cho authenticated API access. + Kiểm tra user registration flow: tạo test user trong Cognito User Pool. + Kiểm tra login flow: authenticate user và obtain JWT tokens. + Kiểm tra authenticated API access: sử dụng JWT token để truy cập protected API endpoints. 13/11/2025 13/11/2025 Tài liệu Cognito 18 - Cấu hình Auto Scaling Group: + Tạo Launch Template dựa trên base AMI đã tạo ở Ngày 14. + Cấu hình Launch Template với instance type, security groups, IAM role, và user data scripts. + Tạo Auto Scaling Group với Launch Template trong private subnet. + Cấu hình Auto Scaling policies: target tracking (CPU utilization, network in/out), step scaling, hoặc scheduled scaling. + Thiết lập minimum, desired, và maximum capacity cho Auto Scaling Group. + Kiểm tra scale-out: trigger scaling bằng cách tăng load (hoặc manually adjust desired capacity). + Kiểm tra scale-in: giảm load và xác minh instances được terminate tự động. - Tóm tắt tuần 10: Backend và database layer hoàn tất, sẵn sàng cho CI/CD và monitoring setup trong tuần 11. 14/11/2025 14/11/2025 Tài liệu Auto Scaling Kết quả đạt được trong tuần 10: Triển khai thành công Amazon RDS database:\nTạo RDS subnet group trong private subnet để cô lập database. Launch RDS instance (MySQL/PostgreSQL) với instance class và cấu hình phù hợp. Cấu hình RDS parameter group với database-specific settings. Thiết lập automated backups, encryption at rest, và monitoring. Cấu hình RDS security group để chỉ cho phép kết nối từ EC2 Security Group. Lưu trữ database credentials an toàn trong AWS Secrets Manager. Thiết lập EC2 backend infrastructure:\nLaunch EC2 instance trong private subnet với instance type phù hợp. Cài đặt và cấu hình application runtime environment (Java/Python/Node.js). Cấu hình EC2 instance với IAM role cho AWS service access. Tạo base AMI từ EC2 instance đã cấu hình cho Auto Scaling Group. Tài liệu hóa cấu hình EC2 và application setup procedures. Deploy backend application:\nDeploy backend application code lên EC2 instance. Cấu hình application để kết nối với RDS sử dụng credentials từ Secrets Manager. Kiểm tra database connectivity và xác minh connection functionality. Kiểm tra basic application functionality và database operations (CRUD). Tài liệu hóa deployment process và application configuration. Cấu hình API Gateway REST API:\nTạo REST API với resources, methods, và integration points. Thiết lập API Gateway VPC Link để kết nối với private subnet resources (EC2). Cấu hình API Gateway integration với EC2 backend sử dụng HTTP/HTTPS. Bật CORS cho frontend access với proper headers. Kiểm tra API endpoints và xác minh tích hợp với EC2 backend. Tích hợp Amazon Cognito cho authentication:\nTạo Cognito User Pool với password policies, MFA, và email verification. Tạo Cognito User Pool App Client cho application integration. Cấu hình Cognito Authorizer trong API Gateway cho authenticated API access. Kiểm tra user registration, login, và authenticated API access flows. Thiết lập secure user authentication và authorization. Cấu hình Auto Scaling Group cho scalability:\nTạo Launch Template dựa trên base AMI cho consistent instance configuration. Tạo Auto Scaling Group với Launch Template trong private subnet. Cấu hình Auto Scaling policies (target tracking, step scaling) cho automatic scaling. Thiết lập capacity limits phù hợp (minimum, desired, maximum). Kiểm tra scale-out và scale-in functionality để xác minh automatic scaling. Sau tuần 10, backend và database layer đã hoạt động với scalable infrastructure. Application sẵn sàng cho CI/CD automation và comprehensive monitoring trong tuần 11.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Xây dựng VPC và Networking Core: Tạo VPC với public và private subnets, Internet Gateway, và NAT Gateway. Thiết lập ranh giới mạng an toàn với routing và subnet segmentation phù hợp. Cấu hình Security Groups cho EC2, RDS, và ALB theo nguyên tắc least-privilege. Thiết lập IAM roles và policies cho EC2 instances với custom permissions. Bật VPC Flow Logs cho network traffic monitoring và auditing. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 7 - Tạo VPC \u0026amp; Cấu hình Subnet: + Tạo VPC với CIDR block 10.0.0.0/16 trong AWS region đã chọn. + Tạo public subnet (10.0.1.0/24) trong một Availability Zone với tags phù hợp. + Tạo private subnet (10.0.2.0/24) trong cùng Availability Zone với tags phù hợp. + Áp dụng tagging strategy nhất quán (Name, Environment, Project, v.v.) cho tất cả resources. + Tài liệu hóa subnet allocation và IP addressing scheme. 02/11/2025 02/11/2025 Tài liệu AWS VPC 8 - Thiết lập Internet Gateway: + Tạo và gắn Internet Gateway vào VPC. + Cấu hình public subnet route table để route internet-bound traffic (0.0.0.0/0) đến Internet Gateway. + Xác minh cấu hình public subnet route table. + Kiểm tra internet connectivity từ public subnet (launch test EC2 instance nếu cần). + Tài liệu hóa routing configuration và gateway associations. 03/11/2025 03/11/2025 Hướng dẫn Internet Gateway 9 - Cấu hình NAT Gateway: + Cấp phát Elastic IP address cho NAT Gateway. + Tạo NAT Gateway trong public subnet (10.0.1.0/24). + Cấu hình private subnet route table để route internet-bound traffic (0.0.0.0/0) qua NAT Gateway. + Xác minh cấu hình private subnet route table. + Kiểm tra outbound internet connectivity từ private subnet (launch test EC2 instance trong private subnet). + Xác minh private subnet instances có thể truy cập internet trong khi vẫn bị cô lập khỏi inbound connections. 04/11/2025 04/11/2025 Tài liệu NAT Gateway 10 - Thiết kế \u0026amp; Triển khai Security Groups: + Tạo Security Group cho EC2 instances: cho phép inbound từ API Gateway/ALB, outbound đến RDS và internet qua NAT. + Tạo Security Group cho RDS: chỉ cho phép inbound từ EC2 Security Group trên database port (3306/5432). + Tạo Security Group cho ALB (nếu sử dụng): cho phép inbound HTTP/HTTPS từ internet, outbound đến EC2 Security Group. + Áp dụng nguyên tắc least-privilege: cấp minimum permissions cần thiết. + Tài liệu hóa security group rules và relationships. 05/11/2025 05/11/2025 Hướng dẫn Security Groups 11 - IAM Roles \u0026amp; Policies cho EC2: + Tạo IAM role cho EC2 instances với tên mô tả. + Tạo custom IAM policy cho EC2 để truy cập các AWS services cần thiết (S3, Secrets Manager, CloudWatch, v.v.). + Gắn IAM role vào EC2 instance profile. + Kiểm tra IAM role permissions từ EC2 instance (sử dụng AWS CLI hoặc SDK). + Xác minh EC2 có thể truy cập Secrets Manager để retrieve database credentials. + Tài liệu hóa IAM roles và permissions của chúng. 06/11/2025 06/11/2025 IAM best practices 12 - Network ACLs \u0026amp; VPC Flow Logs: + Xem xét và cấu hình Network ACLs (tùy chọn, default ACLs thường đủ). + Kiểm tra Network ACL rules nếu custom rules được triển khai. + Bật VPC Flow Logs để capture IP traffic flow information. + Cấu hình Flow Logs destination (CloudWatch Logs hoặc S3 bucket). + Xem xét Flow Logs để audit network traffic patterns. + Audit và tài liệu hóa tất cả cấu hình mạng cho security review. - Tóm tắt tuần 9: VPC và networking core hoàn tất, sẵn sàng cho backend và database deployment trong tuần 10. 07/11/2025 07/11/2025 Tài liệu VPC Flow Logs Kết quả đạt được trong tuần 9: Tạo thành công VPC và subnet infrastructure:\nTạo VPC với CIDR block 10.0.0.0/16 trong AWS region đã chọn. Cấu hình public subnet (10.0.1.0/24) cho internet-facing resources với tagging phù hợp. Cấu hình private subnet (10.0.2.0/24) cho application servers với tagging phù hợp. Áp dụng tagging strategy nhất quán trên tất cả network resources để quản lý tốt hơn. Thiết lập Internet Gateway cho public subnet connectivity:\nTạo và gắn Internet Gateway vào VPC. Cấu hình public subnet route table để route internet traffic (0.0.0.0/0) đến Internet Gateway. Xác minh public subnet instances có thể truy cập internet trực tiếp. Tài liệu hóa routing configuration và gateway associations. Cấu hình NAT Gateway cho private subnet outbound access:\nCấp phát Elastic IP address và tạo NAT Gateway trong public subnet. Cấu hình private subnet route table để route internet traffic qua NAT Gateway. Xác minh private subnet instances có thể truy cập internet cho outbound connections (updates, downloads, API calls). Xác nhận private subnet vẫn bị cô lập khỏi inbound internet connections (security best practice). Triển khai Security Groups theo nguyên tắc least-privilege:\nTạo Security Group cho EC2: cho phép inbound từ API Gateway/ALB, outbound đến RDS và internet. Tạo Security Group cho RDS: chỉ cho phép inbound từ EC2 Security Group trên database port. Tạo Security Group cho ALB (nếu sử dụng): cho phép inbound HTTP/HTTPS, outbound đến EC2. Áp dụng nguyên tắc least-privilege: cấp minimum permissions cần thiết cho mỗi component. Tài liệu hóa security group rules và relationships cho maintainability. Cấu hình IAM roles và policies cho EC2:\nTạo IAM role cho EC2 instances với naming mô tả. Tạo custom IAM policy cho EC2 để truy cập các AWS services cần thiết (S3, Secrets Manager, CloudWatch). Gắn IAM role vào EC2 instance profile. Kiểm tra IAM permissions từ EC2 instance và xác minh truy cập Secrets Manager. Tài liệu hóa IAM roles và permissions cho security audit. Bật VPC Flow Logs cho network monitoring:\nBật VPC Flow Logs để capture IP traffic flow information. Cấu hình Flow Logs destination (CloudWatch Logs hoặc S3 bucket). Xem xét Flow Logs để audit network traffic patterns và xác định anomalies. Audit tất cả cấu hình mạng cho security compliance. Sau tuần 9, VPC và networking core infrastructure đã hoàn tất với secure network boundaries, proper routing, và monitoring capabilities. Hệ thống sẵn sàng cho backend và database deployment trong tuần 10.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Hoàn thiện Edge Layer và Frontend Storage: Route 53, S3, CloudFront, AWS WAF, và ACM Certificate. Thiết lập quản lý DNS với Route 53 hosted zone và cấu hình domain. Cấu hình S3 bucket cho static frontend hosting với access policies phù hợp. Triển khai CloudFront distribution cho global content delivery với Origin Access Control. Triển khai AWS WAF protection với các quy tắc bảo mật (SQL injection, XSS, bot control). Thiết lập ACM Certificate và bật HTTPS cho secure content delivery. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Phân tích Yêu cầu Hệ thống \u0026amp; Thiết kế Kiến trúc: + Phân tích yêu cầu hệ thống và xem xét sơ đồ kiến trúc hoàn chỉnh. + Xác định tất cả các thành phần: Route 53, S3, CloudFront, WAF, ACM, VPC, EC2, RDS, API Gateway. + Tạo tài liệu High-Level Design (HLD) với tổng quan kiến trúc. + Tài liệu hóa data flow: Users → Route 53 → CloudFront → WAF → S3 (Frontend). + Lập kế hoạch IP addressing scheme và resource naming conventions. 26/10/2025 26/10/2025 Sơ đồ kiến trúc 2 - Thiết lập Route 53: + Tạo Route 53 hosted zone cho quản lý domain. + Tạo A record trỏ đến CloudFront distribution (dự kiến cho Ngày 4). + Tạo CNAME records cho subdomains nếu cần. + Cấu hình DNS settings và xác minh domain ownership. + Tài liệu hóa cấu hình DNS và record types. 27/10/2025 27/10/2025 Tài liệu Route 53 3 - Cấu hình S3 Frontend Bucket: + Tạo S3 bucket cho frontend static assets (FE Bucket) với tên phù hợp. + Bật static website hosting trên S3 bucket. + Cấu hình public access policy cho CloudFront access (block public access, allow CloudFront via OAC). + Upload test frontend files (HTML, CSS, JS, images) lên S3 bucket. + Kiểm tra static website hosting endpoint và xác minh file accessibility. 28/10/2025 28/10/2025 Tài liệu S3 4 - Thiết lập CloudFront Distribution: + Tạo CloudFront distribution với S3 bucket làm origin. + Cấu hình Origin Access Control (OAC) cho secure S3 access (thay thế OAI). + Thiết lập cache policies (CachingOptimized, CachingDisabled, v.v.). + Cấu hình default root object (index.html). + Map Route 53 domain vào CloudFront distribution (cập nhật A record từ Ngày 2). + Kiểm tra CloudFront distribution và xác minh content delivery. 29/10/2025 29/10/2025 Tài liệu CloudFront 5 - Tích hợp AWS WAF: + Tạo AWS WAF WebACL cho CloudFront protection. + Thêm managed rules: AWS Managed Rules cho SQL injection protection. + Thêm managed rules: AWS Managed Rules cho XSS (Cross-Site Scripting) protection. + Cấu hình bot control rules để chặn common bots và scrapers. + Liên kết WAF WebACL với CloudFront distribution. + Kiểm tra WAF rules bằng cách thử các mẫu tấn công phổ biến và xác minh blocking. 30/10/2025 30/10/2025 Tài liệu AWS WAF 6 - Cấu hình ACM Certificate \u0026amp; HTTPS: + Request ACM Certificate trong us-east-1 region (bắt buộc cho CloudFront). + Validate certificate sử dụng DNS validation method (thêm CNAME records vào Route 53). + Chờ certificate validation và issuance. + Bind ACM certificate vào CloudFront distribution. + Cấu hình CloudFront để sử dụng HTTPS only (redirect HTTP to HTTPS). + Kiểm tra HTTPS connection và xác minh SSL/TLS certificate hoạt động đúng. - Tóm tắt tuần 8: Edge layer và frontend storage hoàn tất, sẵn sàng cho VPC và networking setup trong tuần 9. 31/10/2025 31/10/2025 Tài liệu ACM Kết quả đạt được trong tuần 8: Hoàn thành thành công phân tích hệ thống và thiết kế kiến trúc:\nPhân tích yêu cầu hệ thống và xem xét sơ đồ kiến trúc hoàn chỉnh. Tạo tài liệu High-Level Design (HLD) với tổng quan kiến trúc và mối quan hệ các thành phần. Tài liệu hóa data flow từ users qua edge services đến frontend storage. Thiết lập resource naming conventions và planning documentation. Thiết lập quản lý DNS Route 53:\nTạo Route 53 hosted zone cho quản lý domain. Cấu hình A và CNAME records cho domain routing. Thiết lập nền tảng DNS để kết nối domain với CloudFront distribution. Cấu hình S3 cho static frontend hosting:\nTạo S3 bucket cho frontend static assets với naming conventions phù hợp. Bật static website hosting trên S3 bucket. Cấu hình public access policies: block public access, allow CloudFront access qua Origin Access Control. Upload test frontend files và xác minh static website hosting functionality. Triển khai CloudFront distribution:\nTạo CloudFront distribution với S3 bucket làm origin. Cấu hình Origin Access Control (OAC) cho secure S3 access (thay thế hiện đại cho OAI). Thiết lập cache policies cho optimized content delivery. Map Route 53 domain vào CloudFront distribution. Xác minh content delivery qua CloudFront CDN globally. Triển khai AWS WAF protection:\nTạo AWS WAF WebACL với các quy tắc bảo mật toàn diện. Thêm AWS Managed Rules cho SQL injection protection. Thêm AWS Managed Rules cho XSS (Cross-Site Scripting) protection. Cấu hình bot control rules để chặn malicious bots và scrapers. Liên kết WAF WebACL với CloudFront distribution. Kiểm tra WAF rules và xác minh protection chống lại các mẫu tấn công phổ biến. Bật HTTPS với ACM Certificate:\nRequest và validate ACM Certificate trong us-east-1 region (bắt buộc cho CloudFront). Sử dụng DNS validation method với CNAME records trong Route 53. Bind ACM certificate vào CloudFront distribution. Cấu hình CloudFront để enforce HTTPS (redirect HTTP to HTTPS). Xác minh SSL/TLS certificate hoạt động đúng và secure connections được thiết lập. Sau tuần 8, edge layer và frontend storage đã hoàn tất với secure, global content delivery. Hệ thống sẵn sàng cho VPC và networking core setup trong tuần 9.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Hiểu Amazon DynamoDB như một dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn: mô hình dữ liệu key-value và document, partition keys, sort keys, global secondary indexes (GSI), và các chế độ dung lượng on-demand vs provisioned. Học cách xây dựng và quản lý Data Lakes trên AWS sử dụng các dịch vụ như Amazon S3, AWS Glue, Amazon Athena, và Amazon QuickSight cho các workload phân tích. Khám phá các dịch vụ Analytics của AWS: Amazon Athena cho truy vấn SQL serverless trên S3, AWS Glue cho các thao tác ETL, và Amazon QuickSight cho business intelligence và visualization. Thực hành các quy trình ingestion, transformation, và phân tích dữ liệu trong môi trường đám mây AWS. Hiểu các chiến lược tối ưu hóa chi phí và hiệu năng cho analytics workloads trên AWS. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thực hành Lab: Data Lake on AWS. + Hiểu kiến trúc data lake trên AWS sử dụng S3 làm lớp lưu trữ data lake. + Học về các mẫu ingestion, cataloging, và querying dữ liệu. + Khám phá tích hợp giữa S3, Glue, và Athena cho analytics. 20/10/2025 20/10/2025 https://000035.awsstudygroup.com/ 3 - Thực hành Lab: Amazon DynamoDB Immersion Day. + Đi sâu vào các khái niệm cốt lõi của DynamoDB: tables, items, attributes, primary keys, và indexes. + Thực hành tạo tables, chèn dữ liệu, và query với partition keys và sort keys. + Hiểu các chế độ dung lượng DynamoDB (on-demand vs provisioned) và mô hình định giá. 21/10/2025 21/10/2025 https://000039.awsstudygroup.com/ 4 - Thực hành Lab: Cost and performance analysis with AWS Glue and Amazon Athena. + Sử dụng AWS Glue để catalog dữ liệu lưu trữ trong S3 và tạo data catalogs. + Chạy các truy vấn SQL trên dữ liệu S3 sử dụng Amazon Athena. + Phân tích tác động chi phí và tối ưu hóa hiệu năng truy vấn. + Hiểu các chiến lược phân vùng cho analytics hiệu quả về chi phí. 22/10/2025 22/10/2025 https://000040.awsstudygroup.com/ 5 - Thực hành Lab: Work with Amazon DynamoDB. + Tạo DynamoDB tables với key schemas phù hợp. + Thực hiện các thao tác CRUD (Create, Read, Update, Delete) trên DynamoDB items. + Làm việc với Global Secondary Indexes (GSI) và Local Secondary Indexes (LSI). + Thực hành các thao tác querying và scanning, hiểu sự khác biệt. 23/10/2025 23/10/2025 https://000060.awsstudygroup.com/ 6 - Thực hành Lab: Building a Datalake with Your Data. + Xây dựng giải pháp data lake hoàn chỉnh sử dụng các dịch vụ AWS. + Triển khai các pipeline ingestion dữ liệu. + Thiết lập các workflow transformation dữ liệu với AWS Glue. + Tạo datasets sẵn sàng cho analytics để tiêu thụ downstream. 24/10/2025 24/10/2025 https://000070.awsstudygroup.com/ 7 - Thực hành Lab: Analytics on AWS workshop. + Workshop toàn diện bao gồm toàn bộ analytics stack trên AWS. + Tích hợp nhiều dịch vụ: S3, Glue, Athena, và các công cụ visualization. + Xây dựng các giải pháp analytics end-to-end từ dữ liệu thô đến insights. 25/10/2025 25/10/2025 https://000072.awsstudygroup.com/ 8 - Thực hành Lab: Get started with QuickSight. + Tạo visualizations và dashboards sử dụng Amazon QuickSight. + Kết nối QuickSight với các nguồn dữ liệu khác nhau (S3, Athena, RDS, v.v.). + Xây dựng các báo cáo tương tác và chia sẻ insights với các bên liên quan. - Tóm tắt và ôn tập tất cả AWS Analytics and Data Lake Services đã học trong tuần 7. 26/10/2025 26/10/2025 https://000073.awsstudygroup.com/ Kết quả đạt được trong tuần 7: Hiểu toàn diện về Amazon DynamoDB:\nDynamoDB như một dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn, serverless với độ trễ millisecond đơn lẻ. Các khái niệm chính: tables, items, attributes, primary keys (partition key + sort key tùy chọn), và best practices về data modeling. Global Secondary Indexes (GSI) và Local Secondary Indexes (LSI) cho các mẫu truy vấn linh hoạt. Chế độ dung lượng: on-demand (trả theo yêu cầu) vs provisioned (dung lượng dự trữ) và khi nào sử dụng mỗi loại. DynamoDB Streams cho xử lý dữ liệu real-time và change data capture. Xây dựng kinh nghiệm thực tế với kiến trúc Data Lake trên AWS:\nAmazon S3 làm nền tảng cho lưu trữ data lake với lifecycle policies, versioning, và encryption. Các mẫu kiến trúc data lake: raw zone, processed zone, và curated zone. Chiến lược ingestion dữ liệu: batch uploads, streaming data, và tích hợp với các nguồn dữ liệu khác nhau. Best practices cho tổ chức dữ liệu trong S3: partitioning, naming conventions, và cấu trúc thư mục. Thành thạo các dịch vụ Analytics của AWS:\nAWS Glue: Dịch vụ ETL serverless để khám phá, catalog, và transform dữ liệu. Glue Data Catalog như một kho lưu trữ metadata tập trung. Glue ETL jobs cho data transformation sử dụng Apache Spark. Glue Crawlers cho automatic schema discovery. Amazon Athena: Dịch vụ truy vấn SQL tương tác serverless để phân tích dữ liệu trong S3. Mô hình định giá trả theo truy vấn và chiến lược tối ưu hóa chi phí. Tích hợp với Glue Data Catalog cho schema-on-read queries. Tối ưu hóa hiệu năng truy vấn thông qua partitioning và định dạng cột (Parquet, ORC). Amazon QuickSight: Dịch vụ business intelligence và visualization cloud-native. Tạo dashboards, visualizations, và reports. Kết nối với các nguồn dữ liệu khác nhau (S3, Athena, RDS, Redshift, v.v.). Chia sẻ insights với teams và embedding analytics trong applications. Hoàn thành các phiên thực hành lab toàn diện:\nData Lake on AWS (Lab 35): Xây dựng hiểu biết nền tảng về kiến trúc data lake và các mẫu lưu trữ dựa trên S3. Amazon DynamoDB Immersion Day (Lab 39): Đi sâu vào các thao tác DynamoDB, data modeling, và best practices. Cost and performance analysis with AWS Glue and Amazon Athena (Lab 40): Học cách tối ưu hóa analytics workloads cho chi phí và hiệu năng. Work with Amazon DynamoDB (Lab 60): Thực hành các thao tác CRUD, chiến lược indexing, và query patterns. Building a Datalake with Your Data (Lab 70): Triển khai giải pháp data lake end-to-end với ingestion và transformation pipelines. Analytics on AWS workshop (Lab 72): Workshop toàn diện tích hợp nhiều dịch vụ analytics. Get started with QuickSight (Lab 73): Tạo visualizations và dashboards cho business intelligence. Sau tuần 7, thiết lập hiểu biết hoàn chỉnh về hệ sinh thái AWS Analytics và Data Lake:\nTừ NoSQL databases (DynamoDB) → Data Lake storage (S3) → ETL và cataloging (Glue) → Query và analysis (Athena) → Visualization (QuickSight), sẵn sàng thiết kế và triển khai các giải pháp analytics hiện đại trên AWS. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Ôn tập lại các khái niệm cơ bản về Database: mô hình quan hệ, khóa chính/khóa ngoại, ACID, chuẩn hóa, OLTP vs OLAP. Hiểu Amazon RDS như một dịch vụ quản lý cơ sở dữ liệu quan hệ trên AWS: engines, Multi-AZ, read replicas, backup, và scaling. Tìm hiểu lợi ích của Amazon Aurora so với các engine RDS tiêu chuẩn: hiệu năng, tính sẵn sàng cao, tự động mở rộng storage, tương thích MySQL/PostgreSQL. Làm quen với Amazon Redshift như một data warehouse quy mô petabyte cho phân tích, và phân biệt nó với RDS (OLTP workloads). Học cách Amazon ElastiCache (Redis / Memcached) cung cấp lớp cache trong bộ nhớ để giảm độ trễ và giảm tải cho cơ sở dữ liệu backend. Thực hành Database Schema Conversion \u0026amp; Migration sử dụng AWS DMS và AWS Schema Conversion Tool (SCT) để di chuyển cơ sở dữ liệu lên AWS. Các công việc trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Ôn tập Database Concepts (Module 06-01): mô hình quan hệ, ACID, transactions, indexing, normalization, OLTP vs OLAP. - Ánh xạ khái niệm cơ sở dữ liệu on-premises truyền thống sang dịch vụ đám mây AWS. 13/10/2025 13/10/2025 Tài liệu lớp học – Module 06-01 3 - Học lý thuyết về Amazon RDS \u0026amp; Amazon Aurora (Module 06-02). - Tìm hiểu về các engines được hỗ trợ, Multi-AZ, automated backups, snapshots, read replicas, và scaling. - So sánh RDS vs Aurora về hiệu năng, tính sẵn sàng, và chi phí. 14/10/2025 14/10/2025 https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html, https://aws.amazon.com/rds/aurora/ 4 - Học về Amazon Redshift \u0026amp; Amazon ElastiCache (Module 06-03). - Phân biệt OLTP (RDS/Aurora) vs OLAP (Redshift) và lớp cache trong bộ nhớ (ElastiCache). - Khám phá các use case phổ biến: data warehouse \u0026amp; BI, caching sessions, leaderboard, rate limiting, v.v. 15/10/2025 15/10/2025 https://aws.amazon.com/redshift/, https://aws.amazon.com/elasticache/ 5 - Thực hành Lab: Module 06-Lab 5 – Amazon Relational Database Service (Amazon RDS). + Tạo RDS instance, cấu hình security group, parameter group, backups. + Kết nối từ client, chạy queries, và kiểm tra behavior (ví dụ: failover/Multi-AZ nếu có trong lab). 16/10/2025 16/10/2025 https://000005.awsstudygroup.com/ 6 - Thực hành Lab: Module 06-Lab 43 – Database Schema Conversion \u0026amp; Migration. + Sử dụng AWS Schema Conversion Tool (SCT) để phân tích và chuyển đổi schema từ source DB sang target RDS/Aurora/Redshift. + Sử dụng AWS Database Migration Service (DMS) để di chuyển dữ liệu (full load và change data capture nếu được hỗ trợ trong lab). - Tóm tắt và ôn tập tất cả AWS Database Services đã học trong tuần 6. 17/10/2025 17/10/2025 https://000043.awsstudygroup.com/ Kết quả đạt được trong tuần 6: Củng cố hiểu biết về các khái niệm cơ sở dữ liệu cốt lõi:\nBảng quan hệ, khóa chính/khóa ngoại, tính toàn vẹn quan hệ, và indexing cơ bản. Các thuộc tính ACID của transactions và tại sao chúng quan trọng trong OLTP workloads. Phân biệt rõ ràng giữa OLTP vs OLAP và cách ánh xạ này sang các dịch vụ AWS. Làm quen thực tế với Amazon RDS:\nTạo và quản lý RDS instances qua AWS Management Console. Xem xét các engines được hỗ trợ (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, Aurora) và các use case điển hình của chúng. Thực hành cấu hình Multi-AZ, automated backups, snapshots, monitoring, và các tùy chọn scaling cơ bản. Hiểu điểm mạnh của Amazon Aurora:\nAurora như một cơ sở dữ liệu cloud-native, tương thích MySQL/PostgreSQL với hiệu năng cải thiện đáng kể so với các engine tiêu chuẩn. Kiến trúc Aurora DB cluster, với lớp storage phân tán trên nhiều AZs. Reader và writer endpoints, tự động mở rộng storage, và thiết kế tính sẵn sàng cao. Xây dựng bức tranh tổng thể về Amazon Redshift \u0026amp; ElastiCache:\nRedshift như một data warehouse cột, quy mô petabyte được tối ưu cho analytics và BI workloads. Cách Redshift khác với RDS/Aurora: được tối ưu cho các truy vấn phức tạp trên dataset lớn thay vì transactional workloads. ElastiCache (Redis/Memcached) như một lớp cache trong bộ nhớ được quản lý đầy đủ, độ trễ thấp để tăng throughput và giảm tải cho cơ sở dữ liệu backend. Hoàn thành các lab chính của tuần:\nModule 06-Lab 5 – Amazon RDS: Triển khai RDS instance, kết nối từ client, thực thi các SQL queries cơ bản. Quan sát tác động của các thay đổi cấu hình (instance class, storage, backup settings) lên behavior và quản lý. Module 06-Lab 43 – Database Schema Conversion \u0026amp; Migration: Sử dụng AWS Schema Conversion Tool (SCT) để đánh giá và chuyển đổi schemas, xác định những gì có thể tự động chuyển đổi vs những gì cần điều chỉnh thủ công. Sử dụng AWS Database Migration Service (DMS) để di chuyển dữ liệu từ source database sang các target RDS/Aurora/Redshift theo kịch bản lab. Sau tuần 6, thiết lập mô hình tinh thần rõ ràng về hệ sinh thái cơ sở dữ liệu AWS:\nTừ các khái niệm cơ sở dữ liệu truyền thống → RDS/Aurora cho OLTP → Redshift cho OLAP → ElastiCache cho caching → DMS/SCT cho migration, sẵn sàng áp dụng trong các kiến trúc thực tế. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Trong tuần này, mục tiêu chính của tôi là nắm vững các khái niệm và dịch vụ bảo mật trong AWS, bao gồm các mô hình chia sẻ trách nhiệm, quản lý truy cập, mã hóa và bảo mật tài nguyên. Tôi cũng đã làm quen với các công cụ và dịch vụ của AWS, từ đó có thể áp dụng vào các bài thực hành cụ thể.\nCác mục tiêu cụ thể bao gồm:\nHiểu mô hình Share Responsibility của AWS. Nắm vững các dịch vụ bảo mật chủ chốt của AWS: IAM, Cognito, Security Hub, KMS, Identity Center. Cải thiện kỹ năng quản lý tài nguyên và bảo mật qua IAM Permissions Boundary, Resource Tags, và các kỹ thuật mã hóa. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu lý thuyết về Share Responsibility Model và các nguyên lý bảo mật của AWS. - Đọc tài liệu về các dịch vụ bảo mật của AWS: + Amazon IAM + Amazon Cognito + AWS Identity Center + AWS KMS + AWS Security Hub 04/10/2025 04/10/2025 AWS Study Group 3 - Thực hành: + Cấu hình và sử dụng AWS Security Hub để theo dõi và phát hiện các vấn đề bảo mật. + Tạo và quản lý IAM Users, Roles và Policies cho các tài khoản trong AWS. + Tạo IAM Groups và quản lý quyền truy cập cho các nhóm người dùng. 05/10/2025 05/10/2025 AWS Study Group 4 - Thực hành: + Tối ưu hóa chi phí EC2 với Lambda để tự động hóa các thao tác dừng hoặc khởi động EC2 instances. + Quản lý quyền truy cập EC2 qua Resource Tags thông qua IAM. + Cấu hình IAM Permission Boundaries để giới hạn quyền người dùng. + Mã hóa dữ liệu sử dụng AWS KMS. 06/10/2025 06/10/2025 AWS Study Group 5 - Thực hành nâng cao: + Tìm hiểu và áp dụng các phương pháp bảo mật trong AWS Organizations để quản lý nhiều tài khoản AWS. + Nâng cao khả năng sử dụng AWS Identity Center để quản lý và đồng bộ người dùng và nhóm trên nhiều dịch vụ AWS. 07/10/2025 07/10/2025 AWS Study Group Kết quả đạt được tuần 5: Tuần này, tôi đã đạt được những kết quả quan trọng trong việc nắm bắt các dịch vụ bảo mật của AWS và áp dụng lý thuyết vào thực tế. Cụ thể:\nHiểu và áp dụng mô hình Share Responsibility của AWS:\nTôi đã nắm rõ mô hình này, trong đó AWS chịu trách nhiệm bảo mật hạ tầng và nền tảng, còn người dùng chịu trách nhiệm bảo mật dữ liệu và ứng dụng của mình. Điều này giúp tôi hiểu rõ vai trò của mình khi triển khai các dịch vụ trên AWS. Lý thuyết về các dịch vụ bảo mật chủ chốt của AWS:\nAmazon IAM: Học cách tạo và quản lý IAM Users, Roles, và Policies, giúp tôi kiểm soát quyền truy cập cho người dùng và nhóm. Amazon Cognito: Tìm hiểu cách quản lý người dùng và xác thực trong các ứng dụng của AWS. AWS Identity Center: Khám phá cách kết nối người dùng với các dịch vụ AWS qua Identity Center. AWS Security Hub: Cấu hình và sử dụng để giám sát bảo mật và phát hiện các mối đe dọa. AWS KMS: Thực hành mã hóa dữ liệu khi lưu trữ (at rest) và bảo vệ dữ liệu quan trọng với các khóa mã hóa. Thực hành và áp dụng các dịch vụ AWS bảo mật:\nĐã hoàn thành việc cài đặt và cấu hình AWS Security Hub để giám sát các vấn đề bảo mật, giúp phát hiện sớm các lỗ hổng bảo mật. IAM Permissions Boundary: Cấu hình để hạn chế quyền của người dùng, đảm bảo quyền truy cập chỉ được cấp trong phạm vi cần thiết. Optimizing EC2 Costs with Lambda: Tối ưu hóa chi phí EC2 bằng cách sử dụng Lambda để tự động tắt các instances không sử dụng, giảm chi phí cho tổ chức. Quản lý quyền truy cập EC2 với IAM và Resource Tags: Thiết lập các IAM Policies để kiểm soát quyền truy cập vào các tài nguyên EC2 thông qua việc gắn Tags. Nâng cao kỹ năng quản lý tài nguyên AWS:\nTạo và quản lý IAM Groups, Policies, giúp tôi quản lý quyền truy cập của các nhóm người dùng một cách hiệu quả. Học cách sử dụng AWS Organizations để quản lý nhiều tài khoản và đảm bảo rằng các chính sách bảo mật được áp dụng một cách nhất quán trong toàn bộ tổ chức. LAB PRACTICE Mục lục Lab 18 Lab 22 VPC EC2 Slack Lambda + EventBridge Kết quả kiểm thử (Test Result) Lab 27 Lab 28 Vùng (Regions) \u0026amp; EC2 Thẻ (Tags) Lab 30 Lab 33 Lab 18 Hình minh họa:\nLab 22 VPC Hình minh họa cấu hình VPC:\nEC2 Hình minh họa cấu hình EC2:\nSlack Lưu ý (UI mới): Cần chọn lại kênh (channel) trong phần cấu hình để lấy đúng Webhook URL.\nLambda + EventBridge Hình minh họa cấu hình Lambda và EventBridge:\nKết quả kiểm thử (Test Result) Lab 27 Hình minh họa:\nLab 28 Hình minh họa:\nVùng (Regions) \u0026amp; EC2 EC2 tại ap-northeast-1 (Tokyo)\nEC2 tại us-east-1 (North Virginia)\nThẻ (Tags) Các cặp key/value mẫu được sử dụng:\nKey Value Name Example Team Beta Team Alpha Team TEST Minh họa trên giao diện:\nName = Example, Team = Beta\nName = Example, Team = Alpha\nTeam = TEST\nLab 30 Policies : IAM : Check Permission : Lab 33 Policies Role User KMS S3 CloudTrail Athena TEST sau khi make ACLs Kết luận: Trong tuần 5, tôi đã nâng cao khả năng sử dụng các công cụ bảo mật và quản lý truy cập của AWS. Những kiến thức và kỹ năng này là cơ sở quan trọng để tiếp tục triển khai các giải pháp bảo mật và tối ưu hóa chi phí trong các dự án AWS sắp tới. Các bài thực hành giúp tôi củng cố lý thuyết và nâng cao khả năng sử dụng AWS trong môi trường thực tế.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4 Hiểu sâu về dịch vụ lưu trữ cốt lõi của AWS là Amazon S3. Nắm vững các khái niệm: bucket, object, storage class, access point, static website hosting, và CORS. Tìm hiểu các giải pháp lưu trữ lai (hybrid storage) và di chuyển dữ liệu như AWS Storage Gateway và AWS Snow Family. Làm quen với Amazon FSx for Windows File Server và dịch vụ sao lưu tự động AWS Backup. Thực hành triển khai, quản lý và kết nối các dịch vụ lưu trữ AWS trong môi trường thực tế. Công việc cần thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Nghiên cứu lý thuyết Dịch vụ Lưu trữ trên AWS (S3) – Module 04-01.\n- Làm quen với khái niệm Bucket, Object và cơ chế lưu trữ. 29/09/2025 29/09/2025 https://docs.aws.amazon.com/s3/ 3 - Học về Access Point và Storage Class trong S3 – Module 04-02.\n- Phân biệt các loại storage class: Standard, IA, Glacier, Deep Archive. 30/09/2025 30/09/2025 https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html 4 - Tìm hiểu S3 Static Website \u0026amp; CORS, quyền truy cập (Access Control), Object Key, Performance, Glacier – Module 04-03. 01/10/2025 01/10/2025 https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html 5 - Thực hành: Module 04-Lab13 – Deploy AWS Backup to the System.\n- Thực hành: Module 04-Lab14 – VM Import/Export. 02/10/2025 02/10/2025 Lab13, Lab14 6 - Thực hành: Module 04-Lab24 – Using File Storage Gateway.\n- Thực hành: Module 04-Lab25 – Amazon FSx for Windows File Server.\n- Ôn tập và tổng hợp toàn bộ nội dung về dịch vụ lưu trữ AWS. 03/10/2025 03/10/2025 Lab24, Lab25 Kết quả đạt được trong Tuần 4 Hiểu rõ kiến trúc và nguyên lý hoạt động của Amazon S3, bao gồm:\nCách tạo và quản lý Bucket, Object, và chính sách truy cập (Access Policy). Các Storage Classes khác nhau và chiến lược tối ưu chi phí lưu trữ. Cấu hình S3 Static Website Hosting và xử lý CORS cho ứng dụng web. Làm quen với S3 Glacier – dịch vụ lưu trữ lạnh, tiết kiệm chi phí cho dữ liệu ít truy cập.\nNắm vững khái niệm Hybrid Storage \u0026amp; Data Migration thông qua:\nAWS Snow Family (Snowcone, Snowball, Snowmobile). AWS Storage Gateway – giải pháp kết nối giữa hệ thống on-premises và đám mây AWS. Thực hành thành công các lab sau:\nLab 13 – AWS Backup Mục tiêu: Cấu hình và triển khai sao lưu tài nguyên với AWS Backup. Step 1:\nStep 2:\nStep 3:\nStep 4:\nSuccess:\nLab 14 – VM Import/Export Mục tiêu: Thực hiện VM Import/Export – chuyển đổi máy ảo giữa môi trường cục bộ và AWS. Step 1:\nSuccess:\nStep 2:\nStep 3:\nStep 4:\nStep 5:\nStep 6 (thành công tải máy ảo lên EC2 (AMIs)):\nStep 7:\nStep 8 (Test Internet):\nStep 9:\nStep 10 (Done):\nLab 24 – File Storage Gateway Mục tiêu: Cấu hình File Storage Gateway – tạo và liên kết lưu trữ file giữa on-premises và AWS. Lưu ý: Phải nâng cấp tài khoản.\nStep 1 – Sau khi tạo S3 thì vào tạo File Storage Gateway (FSG):\nStep 2 – EC2 setting:\nStep 3:\nLab 25 – Amazon FSx for Windows File Server Mục tiêu: Triển khai hệ thống lưu trữ file cho Windows với Amazon FSx for Windows File Server. Step 1 (lỗi Lambda – Node.js version):\nStep 2:\nHoàn thành toàn bộ Module 04 – AWS Storage Services, tạo nền tảng vững chắc để chuyển sang các dịch vụ tính toán, cơ sở dữ liệu và bảo mật trong các tuần tiếp theo. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu rõ về Amazon EC2 và các thành phần liên quan (AMI, Backup, Key Pair, EBS, Instance Store, User Data, Metadata). Tìm hiểu Auto Scaling của EC2 và vai trò của nó trong việc mở rộng linh hoạt và tối ưu chi phí. Khám phá các dịch vụ tính toán liên quan: EFS, FSx, Lightsail, và AWS MGN. Củng cố kiến thức lưu trữ AWS qua các bài lab thực hành với S3, AWS Backup, và Storage Gateway. Phát triển kỹ năng thực tế trong việc cấu hình, quản lý và mở rộng workload trên EC2. Công việc trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Lý thuyết: + Tổng quan EC2: AMI, Backup, Key Pair 22/09/2025 22/09/2025 AWS EC2 Documentation 2 - Lý thuyết: + EBS (Elastic Block Store) + Instance Store 23/09/2025 23/09/2025 AWS EBS Documentation 3 - Lý thuyết: + EC2 User Data + EC2 Metadata 24/09/2025 24/09/2025 AWS EC2 User Guide 4 - Lý thuyết: + EC2 Auto Scaling + Các dịch vụ liên quan: EFS, FSx, Lightsail, MGN 25/09/2025 25/09/2025 AWS Auto Scaling 5 - Thực hành: + Lab 57: Làm quen với Amazon S3 26/09/2025 26/09/2025 AWS Study Group - Lab57 6 - Thực hành: + Lab 13: Triển khai AWS Backup để bảo vệ workload 27/09/2025 27/09/2025 AWS Study Group - Lab13 7 - Thực hành: + Lab 24: Sử dụng AWS Storage Gateway tích hợp với hệ thống on-premises 28/09/2025 28/09/2025 AWS Study Group - Lab24 Kết quả đạt được Tuần 3: Kiến thức lý thuyết vững chắc về Amazon EC2, bao gồm:\nAMI và chiến lược backup để tăng độ tin cậy. Cách dùng Key Pair cho xác thực SSH an toàn. Sự khác biệt giữa EBS (lưu trữ bền vững) và Instance Store (lưu trữ tạm thời). Vai trò của EC2 User Data (chạy script tự động khi khởi tạo instance) và EC2 Metadata (cung cấp thông tin động về instance). Cách EC2 Auto Scaling giúp duy trì hiệu năng và tối ưu chi phí. Mở rộng hiểu biết về các dịch vụ liên quan:\nAmazon EFS và FSx cho lưu trữ chia sẻ và hiệu năng cao. Amazon Lightsail như một giải pháp đơn giản cho workload nhỏ. AWS MGN để di chuyển workload từ on-premises lên AWS. Hoàn thành các bài lab thực hành:\nTạo và quản lý bucket S3 (Lab57). Triển khai AWS Backup để bảo vệ workload (Lab13). Tích hợp hệ thống on-premises với AWS bằng Storage Gateway (Lab24). Kỹ năng then chốt đã đạt được:\nPhân biệt các loại lưu trữ (EBS, Instance Store, EFS, FSx). Tự động hóa vòng đời EC2 bằng User Data và Auto Scaling. Kết hợp giải pháp backup và hybrid storage để xây dựng kiến trúc có độ tin cậy cao. Định hướng:\nTuần này đào sâu về nền tảng compute và storage. Việc kết hợp lý thuyết với bài tập thực hành giúp tăng khả năng không chỉ triển khai và quản lý EC2 mà còn thiết kế kiến trúc linh hoạt, tin cậy và tối ưu chi phí, tích hợp với các dịch vụ lưu trữ và di trú của AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Làm quen, kết nối với các thành viên trong First Cloud Journey. Hiểu các dịch vụ AWS cơ bản, cách thao tác qua Console \u0026amp; CLI. Các công việc triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Gặp gỡ và làm quen thành viên FCJ.\n- Đọc và ghi nhớ các nội quy, quy định tại đơn vị thực tập. 02/09/2025 02/09/2025 3 - Tìm hiểu AWS và các nhóm dịch vụ chính:\n+ Compute + Storage + Networking + Database + \u0026hellip; 03/09/2025 03/09/2025 https://000001.awsstudygroup.com/vi/ 4 - Đăng ký AWS Free Tier account.\n- Làm quen AWS Console \u0026amp; AWS CLI.\n- Thực hành:\n+ Tạo AWS account + Cài đặt \u0026amp; cấu hình AWS CLI + Thao tác cơ bản với CLI 04/09/2025 04/09/2025 https://000001.awsstudygroup.com/vi/ 5 - Cấu hình bảo mật cơ bản:\n+ Setup Virtual MFA Device + Tạo nhóm admin \u0026amp; user admin + Account authentication support + Tạo Budget từ template 05/09/2025 06/09/2025 https://000007.awsstudygroup.com/vi/ 6 - Thực hành quản lý chi phí:\n+ Tạo Cost Budget + Tạo Usage Budget + Reservation Instance (RI) + Savings Plans Budget 06/09/2025 06/09/2025 https://000007.awsstudygroup.com/vi/ 7 - Gửi yêu cầu và quản lý AWS support.\n- Viết worklog \u0026amp; tự đánh giá mức độ hiểu AWS cơ bản.\n- Chuẩn bị cho mục tiêu tuần 2. 07/09/2025 07/09/2025 https://000009.awsstudygroup.com/vi/ Kết quả đạt được tuần 1: Hoàn thành bước khởi động tại đơn vị thực tập:\nLàm quen với các thành viên trong nhóm FCJ. Nắm rõ nội quy, quy định cơ bản. Kiến thức nền tảng AWS:\nHiểu AWS là gì, nắm được các nhóm dịch vụ cơ bản: Compute Storage Networking Database \u0026hellip; Thực hành tạo \u0026amp; cấu hình tài khoản:\nĐăng ký thành công AWS Free Tier account. Thiết lập bảo mật cơ bản: bật MFA, tạo nhóm admin và user admin. Thiết lập ngân sách (Budget) để theo dõi chi phí: Cost Budget, Usage Budget, RI, Savings Plans. Làm quen công cụ quản lý:\nTrải nghiệm AWS Management Console: tìm kiếm, truy cập, và thao tác với dịch vụ qua giao diện web. Cài đặt và cấu hình AWS CLI trên máy tính cá nhân với: Access Key, Secret Key, Region mặc định. Thao tác với AWS CLI:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình. Lấy danh sách region. Xem thông tin dịch vụ EC2. Tạo và quản lý key pair. Kiểm tra dịch vụ đang chạy. Kết nối song song GUI \u0026amp; CLI:\nQuản lý tài nguyên AWS đồng thời qua Console và CLI. So sánh cách thao tác, rút kinh nghiệm cho việc chọn công cụ phù hợp với từng tình huống. Tổng kết cá nhân:\nHoàn tất ôn tập, viết worklog tuần 1 (nộp chậm sang tuần sau). Đánh giá mức độ hiểu biết và xác định mục tiêu cho tuần tiếp theo. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Võ Trường Thành Phát\nSố điện thoại: 0707712750\nEmail: phatvttse171823@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Thực nghiệm ML nhanh cho doanh nghiệp với Amazon SageMaker AI và Comet Bởi: Vikesh Pandey, Naufal Mir và Sarah Ostermeier \u0026ndash; Ngày: 22/9/2025\nChủ đề: Amazon SageMaker AI, SageMaker Unified Studio, Partner solutions ,Sarah Ostermeier\nTrong quá trình mở rộng hoạt động machine learning (ML) của doanh nghiệp từ giai đoạn proof-of-concept sang sản xuất, việc quản lý các thực nghiệm, theo dõi dòng kế thừa mô hình (model lineage), và đảm bảo tái tạo kết quả (reproducibility) trở nên phức tạp hơn rất nhiều. Nguyên nhân chính là các nhà khoa học dữ liệu và kỹ sư ML thường thử nghiệm nhiều phép kết hợp hyperparameter, kiến trúc mô hình và phiên bản dataset, sinh ra một lượng metadata lớn cần được theo dõi để đảm bảo khả năng tái tạo và tuân thủ quy định. Khi quy mô mô hình ML lan rộng qua nhiều đội, yêu cầu về quy định (regulation) gia tăng, việc theo dõi thực nghiệm trở thành điều bắt buộc chứ không chỉ là \u0026ldquo;best practice\u0026rdquo;.\nAmazon SageMaker AI cung cấp cơ sở hạ tầng được quản lý để doanh nghiệp mở rộng workloads ML, xử lý việc cấp phát computer , huấn luyện phân tán, deployment mà không cần lo hạ tầng. Tuy nhiên, các đội vẫn cần một hệ thống theo dõi thực nghiệm mạnh mẽ, khả năng so sánh mô hình và hợp tác vượt lên những logging cơ bản.\nComet là một nền tảng quản lý thực nghiệm ML (ML experiment management) toàn diện, tự động theo dõi, so sánh và tối ưu các thực nghiệm ML suốt vòng đời mô hình. Nó cung cấp cho các nhà khoa học dữ liệu và kỹ sư ML các công cụ mạnh về tracking, monitoring mô hình, tối ưu hyperparameter và phát triển mô hình hợp tác. Nó cũng có Opik \u0026mdash; nền tảng mã nguồn mở của Comet cho quan sát và phát triển LLM (large language model).\nComet có sẵn trong SageMaker AI như một Partner AI App, như một khả năng được quản lý đầy đủ cho thực nghiệm, với bảo mật cấp doanh nghiệp, tích hợp mượt vào workflow, và quy trình mua đơn giản qua AWS Marketplace.\nSự kết hợp này đáp ứng nhu cầu của quy trình ML doanh nghiệp end-to-end: SageMaker AI xử lý hạ tầng và compute, Comet cung cấp khả năng quản lý thực nghiệm, đăng ký mô hình (model registry) và giám sát sản xuất mà các đội cần cho tuân thủ quy định và hiệu quả vận hành. Trong bài viết này, chúng tôi minh hoạ một workflow phát hiện gian lận (fraud detection) hoàn chỉnh dùng SageMaker AI + Comet, minh chứng khả năng tái tạo và logging sẵn sàng audit mà doanh nghiệp ngày nay cần.\nComet \u0026ldquo;Enterprise-ready\u0026rdquo; trên SageMaker AI Trước khi đi vào hướng dẫn triển khai, các tổ chức cần xác định mô hình vận hành (operating model) và từ đó quyết định cách triển khai Comet. AWS khuyến nghị thiết lập Comet theo mô hình liên bang (federated operating model): Comet được quản lý trung tâm trong tài khoản shared services, và mỗi đội dữ liệu ML có môi trường tự chủ riêng. Mỗi mô hình vận hành có lợi \u0026mdash; hại riêng. (Tham khảo SageMaker Studio Administration Best Practices để biết chi tiết).\nTrong kiến trúc này, thường có hai vai:\nAdministrator \u0026ndash; người chịu trách nhiệm thiết lập hạ tầng chung và môi trường cho các đội use-case\nUser (Người dùng) \u0026ndash; nhà thực nghiệm ML từ các đội use-case, sử dụng môi trường đã thiết lập để giải quyết bài toán doanh nghiệp\nComet hoạt động tốt với cả SageMaker AI và Amazon SageMaker (SageMaker AI dùng môi trường tích hợp trong SageMaker Studio IDE; SageMaker dùng Unified Studio IDE). Ở đây, chúng ta dùng SageMaker Studio trong ví dụ.\nHành trình của Administrator Khi một đội muốn triển khai use-case phát hiện gian lận, admin thực hiện:\nThực hiện các bước prerequisite để thiết lập Partner AI Apps \u0026mdash; cấp phép để Comet có thể giả danh role SageMaker AI của người dùng và quản lý đăng ký Comet qua AWS Marketplace.\nTrong console SageMaker AI, vào phần Applications and IDEs → Partner AI Apps → Comet để xem chi tiết.\nHiển thị chi tiết hợp đồng, mô hình pricing, ước tính chi phí hạ tầng Comet. Chọn Go to Marketplace để đăng ký Comet từ AWS Marketplace.\nChọn \u0026ldquo;View purchase options\u0026rdquo; và điền thông tin đăng ký.\nSau khi đăng ký xong, admin bắt đầu cấu hình Comet.\nKhi deploy Comet, thêm project lead của đội phát hiện gian lận làm admin quản lý dashboard Comet. Quá trình deploy Comet mất vài phút. (Tham khảo hướng dẫn Partner AI App provisioning để biết chi tiết).\nThiết lập domain SageMaker AI theo hướng dẫn *Use custom setup for Amazon SageMaker AI *. Theo best practice, cung cấp URL domain có pre-signed để đội use-case truy cập Comet UI mà không cần đăng nhập console SageMaker.\nThêm thành viên đội vào domain và bật quyền truy cập Comet khi cấu hình domain.\nSau các bước này, domain SageMaker AI đã sẵn sàng để user đăng nhập và bắt đầu làm việc.\nHành trình của User (nhà ML) Khi môi trường đã sẵn sàng, user thực hiện:\nĐăng nhập domain SageMaker AI qua URL đã được pre-signed.\nTự động chuyển tới IDE SageMaker Studio, user name và IAM execution role đã được admin cấu hình sẵn. Tạo một JupyterLab Space theo hướng dẫn JupyterLab user guide.\nBắt đầu làm use-case phát hiện gian lận bằng cách khởi chạy notebook.\nAdmin đã cấp quyền truy cập dữ liệu qua bucket S3 cần thiết. Để dùng API của Comet, cài gói comet_ml và cấu hình biến môi trường (environment variables) theo hướng dẫn Set up Partner AI Apps SDKs.\nTrong SageMaker Studio, chọn Partner AI Apps → Open Comet để truy cập giao diện Comet UI.\nBắt đầu workflow thực nghiệm. Tổng quan giải pháp (Solution overview) Use-case này nhấn mạnh các thách thức thường gặp trong doanh nghiệp:\nDataset mất cân bằng (ví dụ ở đây chỉ ~0,17% giao dịch là gian lận)\nNhiều vòng thực nghiệm (iterations)\nYêu cầu tái tạo hoàn chỉnh (reproducibility) và tuân thủ audit\nDòng kế thừa dữ liệu \u0026amp; mô hình (lineage) cần được ghi lại chi tiết\nSử dụng dataset Credit Card Fraud Detection, với nhãn nhị phân \u0026mdash; 1 là gian lận, 0 là hợp lệ. Các bước sau đây minh họa các phần quan trọng của triển khai (toàn bộ mã có trong repo GitHub của Comet).\nPrerequisites (Cài đặt trước) Cấu hình các import và biến môi trường Comet + SageMaker:\n# Comet ML for experiment tracking\nimport comet_ml\nfrom comet_ml import Experiment, API, Artifact\nfrom comet_ml.integration.sagemaker import log_sagemaker_training_job_v1\nAWS_PARTNER_APP_AUTH = True\nAWS_PARTNER_APP_ARN = \u0026lt;Your_AWS_PARTNER_APP_ARN\u0026gt;\nCOMET_API_KEY = \u0026lt;Your_Comet_API_Key\u0026gt;\nCOMET_WORKSPACE = '\u0026lt;your-comet-workspace-name\u0026gt;'\nCOMET_PROJECT_NAME = '\u0026lt;your-comet-project-name\u0026gt;'\nBiến AWS_PARTNER_APP_ARN và COMET_API_KEY lấy từ trang chi tiết Comet trong SageMaker.\nCOMET_WORKSPACE và COMET_PROJECT_NAME là tên workspace và project bạn sẽ dùng để nhóm các thực nghiệm.\nChuẩn bị dataset Một tính năng quan trọng của Comet là versioning dataset tự động \u0026amp; theo dõi lineage. Điều này cho phép audit đầy đủ dữ liệu nào được dùng để huấn luyện mỗi mô hình \u0026mdash; rất quan trọng trong các môi trường quy định (regulation).\nVí dụ:\n# Tạo Artifact dataset để theo dõi dataset gốc\ndataset_artifact = Artifact(\nname=\u0026quot;fraud-dataset\u0026quot;,\nartifact_type=\u0026quot;dataset\u0026quot;,\naliases=[\u0026quot;raw\u0026quot;]\n)\ndataset_artifact.add_remote(s3_data_path, metadata={\n\u0026quot;dataset_stage\u0026quot;: \u0026quot;raw\u0026quot;,\n\u0026quot;dataset_split\u0026quot;: \u0026quot;not_split\u0026quot;,\n\u0026quot;preprocessing\u0026quot;: \u0026quot;none\u0026quot;\n})\nArtifact cho phép đánh dấu file dataset và metadata kèm theo\nDữ liệu gốc được thêm vào artifact để Comet theo dõi nguồn dataset\nBắt đầu một experiment Comet Sau khi artifact đã được log, bạn bắt đầu một experiment và Comet sẽ tự động ghi lại metadata nền, environment, thư viện, code, v.v.\nexperiment_1 = comet_ml.Experiment(\nproject_name=COMET_PROJECT_NAME,\nworkspace=COMET_WORKSPACE,\n)\nexperiment_1.log_artifact(dataset_artifact)\nExperiment tự động bắt đầu ghi thông tin\nlog_artifact để ghi dataset artifact vào experiment cho truy vết\nTiền xử lý dữ liệu (Preprocess) Các bước tiền xử lý bao gồm:\nLoại bỏ bản ghi trùng\nBỏ các cột không cần thiết\nChia dữ liệu thành các tập train/validation/test\nChuẩn hoá các đặc trưng (standardization) dùng StandardScaler của scikit-learn\nMã tiền xử lý được viết trong file preprocess.py và chạy như SageMaker Processing Job:\nprocessor = SKLearnProcessor(\nframework_version='1.0-1',\nrole=sagemaker.get_execution_role(),\ninstance_count=1,\ninstance_type='ml.t3.medium'\n)\nprocessor.run(\ncode='preprocess.py',\ninputs=[ProcessingInput(source=s3_data_path, destination='/opt/ml/processing/input')],\noutputs=[ProcessingOutput(source='/opt/ml/processing/output', destination=f's3://{bucket_name}/{processed_data_prefix}')]\n)\nKhi job bắt đầu, SageMaker AI tạo instance, xử lý dữ liệu, và sau đó giải phóng resource.\nKết quả tiền xử lý được lưu lên S3.\nSau khi hoàn tất, bạn tạo phiên bản mới của artifact dataset để theo dõi dữ liệu đã được xử lý:\npreprocessed_dataset_artifact = Artifact(\nname=\u0026quot;fraud-dataset\u0026quot;,\nartifact_type=\u0026quot;dataset\u0026quot;,\naliases=[\u0026quot;preprocessed\u0026quot;],\nmetadata={\n\u0026quot;description\u0026quot;: \u0026quot;Credit card fraud detection dataset\u0026quot;,\n\u0026quot;fraud_percentage\u0026quot;: f\u0026quot;{fraud_percentage:.3f}%\u0026quot;,\n\u0026quot;dataset_stage\u0026quot;: \u0026quot;preprocessed\u0026quot;,\n\u0026quot;preprocessing\u0026quot;: \u0026quot;StandardScaler + train/val/test split\u0026quot;,\n}\n)\npreprocessed_dataset_artifact.add_remote(\nuri=f's3://{bucket_name}/{processed_data_prefix}',\nlogical_path='split_data'\n)\nexperiment_1.log_artifact(preprocessed_dataset_artifact)\nArtifact cùng tên nhưng alias khác cho phép Comet quản lý versioning\nMetadata bổ sung giúp ghi chú những gì đã làm (split, preprocessing\u0026hellip;)\nWorkflow thực nghiệm Comet + SageMaker AI Để thúc đẩy thực nghiệm nhanh, bạn nên tổ chức workflow thành các hàm tiện ích (utility functions) có thể gọi lại nhiều lần với các hyperparameters khác nhau mà vẫn đảm bảo logging và đánh giá thống nhất.\nCác hàm quan trọng:\ntrain() \u0026mdash; tạo job huấn luyện XGBoost trên SageMaker:\nestimator = Estimator(\nimage_uri=xgboost_image,\nrole=execution_role,\ninstance_count=1,\ninstance_type='ml.m5.large',\noutput_path=model_output_path,\nsagemaker_session=sagemaker_session_obj,\nhyperparameters=hyperparameters_dict,\nmax_run=1800 # thời gian tối đa (giây)\n)\nestimator.fit({\n'train': train_channel,\n'validation': val_channel\n})\nlog_training_job() \u0026mdash; ghi metadata huấn luyện vào Comet và liên kết mô hình: \\log_sagemaker_training_job_v1(\nestimator=training_estimator,\nexperiment=api_experiment\n)\nlog_model_to_comet() \u0026mdash; ghi artifact mô hình lên Comet: experiment.log_remote_model(\nmodel_name=model_name,\nuri=model_artifact_path,\nmetadata=metadata\n)\ndeploy_and_evaluate_model() \u0026mdash; triển khai endpoint và đánh giá,log metrics: predictor = estimator.deploy(initial_instance_count=1, instance_type=\u0026quot;ml.m5.xlarge\u0026quot;)\nexperiment.log_metrics(metrics)\nexperiment.log_confusion_matrix(matrix=cm, labels=['Normal', 'Fraud'])\nfpr, tpr, _ = roc_curve(y_test, y_pred_prob_as_np_array)\nexperiment.log_curve(\u0026quot;roc_curve\u0026quot;, x=fpr, y=tpr)\nToàn bộ mã dự đoán và đánh giá chi tiết có trong repo GitHub. Chạy các thực nghiệm (Run the experiments) Bạn có thể thử nhiều experiment bằng cách gọi hàm tiện ích với các cấu hình hyperparameter khác nhau và so sánh kết quả để chọn cấu hình tối ưu cho use-case.\nVí dụ, experiment đầu tiên (baseline):\nhyperparameters_v1 = {\n'objective': 'binary:logistic',\n'num_round': 100,\n'eval_metric': 'auc',\n'learning_rate': 0.15,\n'booster': 'gbtree'\n}\nestimator_1 = train(\nmodel_output_path=f\u0026quot;s3://{bucket_name}/{model_output_prefix}/1\u0026quot;,\nexecution_role=role,\nsagemaker_session_obj=sagemaker_session,\nhyperparameters_dict=hyperparameters_v1,\ntrain_channel_loc=train_channel_location,\nval_channel_loc=validation_channel_location\n)\nlog_training_job(experiment_key = experiment_1.get_key(), training_estimator=estimator_1)\nlog_model_to_comet(\nexperiment = experiment_1,\nmodel_name=\u0026quot;fraud-detection-xgb-v1\u0026quot;,\nmodel_artifact_path=estimator_1.model_data,\nmetadata=metadata\n)\ndeploy_and_evaluate_model(\nexperiment=experiment_1,\nestimator=estimator_1,\nX_test_scaled=X_test_scaled,\ny_test=y_test\n)\nKhi chạy một Comet experiment từ notebook Jupyter, bạn cần gọi experiment_1.end() để đảm bảo mọi thông tin được ghi lại và lưu trên máy chủ Comet.\nSau khi experiment baseline hoàn thành, bạn có thể khởi chạy experiment kế tiếp với hyperparameter khác và so sánh hai experiment trong giao diện Comet UI.\nXem experiment trong giao diện Comet Để truy cập UI, bạn có thể lấy URL từ SageMaker Studio IDE hoặc in ra từ notebook bằng experiment_2.url.\nẢnh chụp màn hình giao diện Comet cho thấy các experiment được so sánh \u0026mdash; chi tiết này dùng để minh họa, không đại diện cho experiment thực tế.\n(Note: chèn ảnh màn hình UI Comet tại đây)\nClean up (Dọn dẹp tài nguyên) Do tính chất ephemeral của hạ tầng SageMaker (processing, training) \u0026mdash; nó tự shut down sau khi job kết thúc. Nhưng bạn vẫn cần:\nTắt JupyterLab Space khi không dùng (theo hướng dẫn Idle shutdown).\nHủy đăng ký Comet nếu không tiếp tục dùng (tránh phí) \u0026mdash; hợp đồng sẽ tự gia hạn nếu không huỷ.\nLợi ích của tích hợp SageMaker + Comet Streamlined model development Sự kết hợp SageMaker \u0026ndash; Comet giảm bớt gánh nặng thủ công khi chạy experiment. Trong khi SageMaker lo cấp phát hạ tầng, Comet tự động logging hyperparameters, metrics, code, thư viện, thông tin hệ thống \u0026mdash; không cần cấu hình thêm.\nComet hỗ trợ trực quan hóa vượt mức đồ thị metric đơn giản: các biểu đồ tích hợp giúp so sánh experiment nhanh chóng; panels Python tuỳ chỉnh giúp bạn debug hành vi mô hình, tối ưu hyperparameter, hoặc tạo visual riêng khi tool mặc định không đáp ứng.\nHợp tác doanh nghiệp \u0026amp; quản trị Trong môi trường doanh nghiệp, sự kết hợp này tạo ra nền tảng mạnh để mở rộng dự án ML trong môi trường có quy định nghiêm ngặt. SageMaker đảm bảo môi trường ML nhất quán, an toàn; Comet hỗ trợ hợp tác với dòng artifact và lineage hoàn chỉnh. Điều này giúp tránh lỗi khi các đội không thể tái tạo kết quả trước đó.\nTích hợp vòng đời ML hoàn chỉnh Khác với các giải pháp rời rạc chỉ hỗ trợ training hay monitoring, SageMaker + Comet hỗ trợ toàn bộ vòng đời ML.\nMô hình có thể được đăng ký trong model registry của Comet với version, quản lý.\nSageMaker lo deployment.\\rkflow phê duyệt promotion.\nComet giữ lineage và wo\nComet giám sát hiệu suất mô hình, theo dõi drift dữ liệu sau khi deployment \u0026mdash; tạo vòng feedback, nơi thông tin từ production ảnh hưởng đến experiment tiếp theo.\nKết luận Trong bài viết này, chúng tôi đã trình bày cách tích hợp SageMaker và Comet để tạo môi trường ML được quản lý hoàn chỉnh, hỗ trợ khả năng tái tạo và theo dõi experiment. Để bổ sung cho workflow SageMaker, bạn có thể triển khai Comet ngay trong môi trường SageMaker qua AWS Marketplace.\nVề các tác giả "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" Sử dụng workflow Apache Airflow để điều phối xử lý dữ liệu trên Amazon SageMaker Unified Studio của Vinod Jayendra , Kamen Sharlandjiev , Sean Bjurstrom và Suba Palanisamy\n22 THÁNG 9 NĂM 2025\nĐiều phối pipeline machine learning là công việc phức tạp, đặc biệt khi phần xử lý dữ liệu, huấn luyện mô hình và triển khai được thực hiện trên nhiều dịch vụ và công cụ khác nhau. Trong bài viết này, chúng tôi sẽ đi qua ví dụ thực tế “end-to-end” — xây dựng, thử nghiệm và chạy một pipeline ML sử dụng workflow của SageMaker thông qua giao diện SageMaker Unified Studio. Các workflow này được hỗ trợ bởi Amazon Managed Workflows for Apache Airflow (Amazon MWAA).\nMặc dù SageMaker Unified Studio có trình xây dựng trực quan (low-code) để tạo workflow, bài viết này tập trung vào cách làm bằng code: viết và quản lý workflow như các DAG (Directed Acyclic Graph) bằng Python trong Apache Airflow.\nChúng ta sẽ cùng xem ví dụ pipeline gồm các bước: ingest dữ liệu thời tiết và dữ liệu taxi, chuyển đổi \u0026amp; gộp dữ liệu, rồi dùng ML để dự đoán giá cước taxi — toàn bộ được điều phối qua SageMaker Unified Studio workflow.\nTổng quan giải pháp (Solution overview) Giải pháp này minh họa cách dùng workflows trong SageMaker Unified Studio để điều phối pipeline từ dữ liệu đến mô hình ML trong một môi trường tập trung. Pipeline gồm các tác vụ sau:\nIngest \u0026amp; tiền xử lý dữ liệu thời tiết\nSử dụng notebook trong SageMaker Unified Studio để ingest dữ liệu thời tiết giả lập, xử lý các thuộc tính như thời gian, nhiệt độ, lượng mưa, độ ẩm, tốc độ gió.\nIngest, xử lý và hợp nhất dữ liệu taxi\nSử dụng notebook thứ hai để ingest dữ liệu taxi NYC (bao gồm pickup time, drop-off time, khoảng cách, số lượng khách, tiền cước). Sau đó xử lý và join dữ liệu taxi \u0026amp; thời tiết, lưu kết quả lên Amazon S3 để dùng cho bước tiếp theo.\nHuấn luyện và dự đoán mô hình ML\nNotebook thứ ba áp dụng kỹ thuật hồi quy (regression) để xây dựng mô hình dự đoán giá taxi dựa trên dữ liệu gộp. Mô hình sau đó được dùng để dự đoán giá cho các dữ liệu mới.\nQua cách tiếp cận này, ETL (extract, transform, load) và các bước ML được điều phối trong cùng workflow, với khả năng theo dõi đầy đủ quá trình dữ liệu và đảm bảo tính tái tạo (reproducibility) thông qua workflow quản lý trong SageMaker Unified Studio.\nChuẩn bị trước (Prerequisites) Trước khi xây workflow, bạn cần:\nTạo một domain SageMaker Unified Studio — làm theo hướng dẫn của AWS.\n( mục Tạo miền Amazon SageMaker Unified Studio – thiết lập nhanh )\nĐăng nhập domain SageMaker Unified Studio — dùng domain bạn đã tạo.\n( Truy cập Amazon SageMaker Unified Studio )\nTạo một project trong SageMaker Unified Studio — trong phần tạo project, chọn profile “All capabilities” để hỗ trợ đầy đủ công năng workflow.\n( hướng dẫn tạo dự án. )\nThiết lập workflow environment Bạn có thể dùng workflow trong SageMaker Unified Studio để thiết lập và chạy chuỗi tác vụ như notebooks, querybooks, jobs. Workflow được viết bằng code Python (Airflow DAG), sau đó bạn có thể truy cập UI Airflow từ SageMaker để theo dõi.\nCác bước cụ thể:\nTrong project của bạn, vào mục Compute → Workflow environment.\nChọn Create environment để thiết lập môi trường workflow mới.\nTheo mặc định, SageMaker Unified Studio sẽ dùng loại môi trường mw1.micro — phù hợp cho thử nghiệm nhỏ.\nNếu cần, bạn có thể override cấu hình mặc định (ví dụ tăng tài nguyên) khi tạo project hoặc chỉnh trong blueprint deployment settings.\nPhát triển workflow (Develop workflows) Workflow cho phép bạn điều phối notebooks, querybooks, v.v. trong dự án. Bạn có thể viết DAG Python, test và chia sẻ với các thành viên khác.\nVí dụ:\nTải 3 notebook mẫu: Weather Data Ingestion, Taxi Ingest \u0026amp; Join, Prediction về máy bạn.\nTrong SageMaker Unified Studio, vào Build → JupyterLab, upload 3 notebook trên.\nCấu hình space: dừng space hiện tại → đổi loại instance (ví dụ ml.m5.8xlarge) → khởi động lại space.\nVào Build → Orchestration → Workflows, chọn “Create new workflow” → chọn “Create in code editor”.\nTrong editor, tạo file Python mới multinotebook_dag.py trong thư mục src/workflows/dags. Dán đoạn mã DAG ví dụ sau (sửa \u0026lt;REPLACE-OWNER\u0026gt; và các đường dẫn notebook cho phù hợp):\nfrom airflow.decorators import dag\nfrom airflow.utils.dates import days_ago\nfrom workflows.airflow.providers.amazon.aws.operators.sagemaker_workflows import NotebookOperator\nWORKFLOW_SCHEDULE = \u0026lsquo;@daily\u0026rsquo;\nNOTEBOOK_PATHS = [\n\u0026lsquo;\u0026lt;FULL_PATH/Weather_Data_Ingestion.ipynb\u0026gt;\u0026rsquo;,\n\u0026lsquo;\u0026lt;FULL_PATH/Taxi_Weather_Data_Collection.ipynb\u0026gt;\u0026rsquo;,\n\u0026lsquo;\u0026lt;FULL_PATH/Prediction.ipynb\u0026gt;\u0026rsquo;\n]\ndefault_args = {\n\u0026lsquo;owner\u0026rsquo;: \u0026lsquo;\u0026lt;REPLACE-OWNER\u0026gt;\u0026rsquo;,\n}\n@dag(\ndag_id=\u0026lsquo;workflow-multinotebooks\u0026rsquo;,\ndefault_args=default_args,\nschedule_interval=WORKFLOW_SCHEDULE,\nstart_date=days_ago(2),\nis_paused_upon_creation=False,\ntags=[\u0026lsquo;MLPipeline\u0026rsquo;],\ncatchup=False\n)\ndef multi_notebook():\nprevious_task = None\nfor idx, notebook_path in enumerate(NOTEBOOK_PATHS, 1):\ncurrent_task = NotebookOperator(\ntask_id=f\u0026quot;Notebook{idx}task\u0026quot;,\ninput_config={\u0026lsquo;input_path\u0026rsquo;: notebook_path, \u0026lsquo;input_params\u0026rsquo;: {}},\noutput_config={\u0026lsquo;output_formats\u0026rsquo;: [\u0026lsquo;NOTEBOOK\u0026rsquo;]},\nwait_for_completion=True,\npoll_interval=5\n)\nif previous\\_task: previous\\_task \\\u0026gt;\\\u0026gt; current\\_task previous\\_task \\= current\\_task multi_notebook()\nNotebookOperator được dùng để chạy từng notebook, với dependencies để đảm bảo thứ tự thực thi.\nBạn có thể tùy chỉnh WORKFLOW_SCHEDULE (ví dụ @daily, @hourly, hoặc cron expression).\nSau khi workflow environment được tạo và file DAG được sync vào dự án, các thành viên trong dự án có thể xem và chạy workflow chung.\nKiểm thử và giám sát workflow Vào Build → Orchestration → Workflows, bạn sẽ thấy workflow đang chạy theo schedule hoặc được kích hoạt.\nKhi workflow hoàn thành, trạng thái chuyển sang “success”.\nBạn có thể vào từng execution để xem chi tiết, logs từng task.\nTruy cập Airflow UI từ SageMaker để xem DAGs, lịch sử chạy, logs chi tiết.\nKết quả \u0026amp; đầu ra Kết quả của mô hình được ghi ra thư mục kết quả trên Amazon S3. Bạn cần kiểm tra:\nĐộ chính xác dự đoán (prediction accuracy)\nSự nhất quán về quan hệ giữa các biến\nNếu có kết quả bất thường, cần xem lại bước xử lý dữ liệu, pipeline, giả định mô hình.\nDọn dẹp tài nguyên (Clean up) Để tránh phát sinh chi phí không cần thiết, bạn nên xóa các tài nguyên tạo ra:\nDomain SageMaker Unified Studio\nBucket S3 liên quan tới domain\nCác workflow environment, project nếu không dùng nữa\nKết luận Trong bài viết này, chúng tôi đã minh họa cách bạn có thể sử dụng SageMaker Unified Studio để xây dựng workflow ML tích hợp, bao gồm:\nTạo project SageMaker Unified Studio\nDùng multi-compute notebook để xử lý dữ liệu\nXây workflow DAG bằng Python để điều phối toàn bộ pipeline\nChạy, giám sát workflow trong SageMaker Unified Studio\nSageMaker cung cấp bộ công cụ toàn diện để thực thi các bước từ chuẩn bị dữ liệu, huấn luyện mô hình đến deployment. Khi sử dụng qua SageMaker Unified Studio, các công cụ này được hợp nhất trong một môi trường làm việc duy nhất, giúp loại bỏ ma sát giữa các công cụ rời rạc.\nKhi các tổ chức xây dựng các ứng dụng dữ liệu phức tạp, các đội có thể dùng SageMaker + Unified Studio để hợp tác hiệu quả và vận hành AI/ML với độ tin cậy cao. Bạn có thể phát hiện dữ liệu, xây mô hình và điều phối workflow trong một môi trường được quản lý và có kiểm soát.\nVề phần tác giả "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Di chuyển tìm kiếm toàn văn từ SQL Server sang Amazon Aurora PostgreSQL-Compatible Edition hoặc Amazon RDS for PostgreSQL Tác giả: Sivaprasad Appana , Surya Nallu , và Saumitra Das\nNgày đăng: 19 tháng 8, 2024\nTrong thế giới dữ liệu ngày nay, khả năng tìm và truy xuất thông tin từ các tập dữ liệu lớn là rất quan trọng. Mặc dù một số hệ quản trị cơ sở dữ liệu (cả thương mại và mã nguồn mở) nổi trội trong xử lý dữ liệu cấu trúc, PostgreSQL cũng cung cấp các công cụ mạnh mẽ để tìm kiếm dữ liệu không cấu trúc hoặc bán cấu trúc. PostgreSQL có sẵn full-text search (FTS) tích hợp, và còn hỗ trợ các extension như pg_trgm và pg_bigm cho việc tìm kiếm văn bản.\nCác truy vấn truyền thống dùng toán tử LIKE, ILIKE hoặc biểu thức chính quy rất phù hợp để tìm chuỗi chính xác hoặc dữ liệu cấu trúc, nhưng có hạn chế nếu cần tìm trong các vùng văn bản lớn như tài liệu, bài viết hoặc mô tả sản phẩm.\nKhi di chuyển từ một cơ sở dữ liệu thương mại như SQL Server sang PostgreSQL (như Amazon Aurora PostgreSQL-Compatible hoặc Amazon RDS for PostgreSQL), việc di chuyển full-text search đòi hỏi phải sửa đổi các truy vấn và cấu trúc schema, vì cách triển khai FTS giữa hai hệ thống khác nhau. Công cụ AWS Schema Conversion Tool (AWS SCT) không tự động chuyển đổi mã liên quan full-text search.\nSQL Server FTS được thiết kế để tìm từ, cụm từ hay các dạng từ (stemming) trong dữ liệu văn bản không cấu trúc. Nó hỗ trợ tìm nhanh, xếp hạng và lập chỉ mục văn bản, giúp ứng dụng xử lý lượng lớn thông tin dạng văn bản hiệu quả.\nTrong bài viết này, chúng tôi sẽ hướng dẫn cách di chuyển full-text search từ SQL Server sang Amazon Aurora PostgreSQL bằng cách sử dụng các kiểu dữ liệu tsvector và tsquery. Đồng thời, chúng tôi cũng chỉ cách triển khai FTS bằng extension pg_trgm và pg_bigm.\nYêu cầu chuẩn bị (Prerequisites) Trong bài này, chúng tôi sử dụng cơ sở dữ liệu mẫu AdventureWorks2019 để minh họa cách di chuyển FTS từ SQL Server 2019 Standard sang PostgreSQL.\nCác bước chính để thiết lập FTS trong SQL Server:\nKích hoạt full-text search cho database AdventureWorks2019: USE [AdventureWorks2019]\nGO\nEXEC sp_fulltext_database \u0026rsquo;enable\u0026rsquo;\nGO\nTạo một full-text catalog: CREATE FULLTEXT CATALOG DescFTSCatalog;\nGO\nFull-text catalog là thành phần logic để quản lý các chỉ mục full-text, xác định các word breakers và stemmers theo ngôn ngữ.\nĐịnh nghĩa một full-text index cho các cột chứa dữ liệu văn bản mà bạn muốn tìm: CREATE FULLTEXT INDEX\nON\n[AdventureWorks2019].[Production].[ProductDescription]([Description])\nKEY INDEX [PK_ProductDescription_ProductDescriptionID]\nON DescFTSCatalog\nGO\nSử dụng AWS SCT và AWS Database Migration Service (AWS DMS) để chuyển cơ sở dữ liệu AdventureWorks 2019 từ SQL Server sang Amazon Aurora PostgreSQL. Trong bài, chúng tôi chuyển bảng Product Description. PostgreSQL có vài lựa chọn để tìm kiếm trong văn bản: tìm chính xác, pattern matching, biểu thức chính quy và full-text search. Trong phần tiếp theo, chúng tôi hướng dẫn cách sử dụng FTS trong PostgreSQL trên database đã chuyển để đạt kết quả tương tự.\nFull-text search trong PostgreSQL Toán tử LIKE, ILIKE và biểu thức chính quy được dùng trong mệnh đề WHERE cho tìm theo mẫu. Tuy nhiên, LIKE / ILIKE không hỗ trợ xếp hạng và thường bỏ qua các từ như “the”, “is”, v.v. PostgreSQL cung cấp FTS bằng cách sử dụng tsvector và tsquery, cùng các hàm, toán tử và tham số liên quan.\ntsvector: kiểu dữ liệu đại diện cho phiên bản đã xử lý của văn bản (tách từ, loại bỏ stop words, giảm về lexeme), tối ưu cho tìm kiếm text nhanh. Hàm to_tsvector chuyển văn bản sang tsvector.\ntsquery: chứa một hoặc nhiều lexeme dùng để tìm. Lexeme có thể được kết hợp với các toán tử để tạo điều kiện tìm phức tạp. Hàm to_tsquery hoặc plainto_ts query chuyển truy vấn tìm kiếm sang tsquery.\nVí dụ: “He is running in the park” → các từ “he”, “run”, “park” sau khi loại bỏ stop words và stemming.\nCONTAINS predicate với toán tử AND Truy vấn FTS đơn giản trong SQL Server sử dụng thuật ngữ CONTAINS . CONTAINS Thuật ngữ này trong Transact-SQL cung cấp một cách linh hoạt để thực hiện FTS nâng cao trong cơ sở dữ liệu SQL Server. Nó hỗ trợ nhiều điều kiện tìm kiếm, tìm kiếm gần đúng, ký tự đại diện và các tính năng từ điển đồng nghĩa, cho phép bạn tùy chỉnh truy vấn để đáp ứng các yêu cầu cụ thể.\nTrong truy vấn mẫu sau, thuật ngữ CONTAINS kiểm tra các từ “entry” và “level” trong cột Mô tả:\nSELECT ProductDescriptionID,Description\nFROM [AdventureWorks2019].[Production].[ProductDescription]\nWHERE CONTAINS([Description], \u0026rsquo;entry \u0026amp; level\u0026rsquo;);\nChứa vị ngữ với toán tử OR Điều này tương tự như trường hợp sử dụng trước đó sử dụng CONTAINS vị ngữ, ngoại trừ việc kiểm tra được thực hiện bằng OR toán tử. Trong truy vấn mẫu sau, vị ngữ kiểm tra \u0026ldquo;mục nhập\u0026rdquo;, \u0026ldquo;mức\u0026rdquo; hoặc cả hai:\nSELECT ProductDescriptionID,Description\nFROM [AdventureWorks2019].[Production].[ProductDescription]\nWHERE CONTAINS([Description], \u0026rsquo;entry | level\u0026rsquo;);\nBạn có thể viết lại truy vấn trong PostgreSQL bằng cách sử dụng các hàm to_tsvector và to_tsquery như sau và sử dụng giá trị từ điển tìm kiếm văn bản tích hợp mặc định là pg_catalog.simple .\nVị ngữ FREETEXT Thuật FREETEXT ngữ vị ngữ trong Transact-SQL (T-SQL) được sử dụng để thực hiện tìm kiếm toàn văn bản trong cơ sở dữ liệu SQL Server. Không giống như CONTAINS hàm, vốn yêu cầu các điều khoản và điều kiện cụ thể, thuật ngữ này FREETEXT cho phép tìm kiếm linh hoạt hơn và dựa trên ngôn ngữ tự nhiên.\nTrong các truy vấn mẫu sau, FREETEXT hãy kiểm tra các từ “entry” hoặc “level” và dạng của chúng (sử dụng phép loại suy) trong cột Mô tả:\nSELECT ProductDescriptionID, Description\nFROM [AdventureWorks2019].[Production].[Product description]\nWHERE FREETEXT([Description], \u0026rsquo;entry level\u0026rsquo;);\nBạn có thể viết lại truy vấn trong PostgreSQL bằng các hàm to_tsvector and to_tsquery như sau với giá trị cấu hình pg_catalog.english. Cấu hình này sử dụng english_stemand một từ điển đơn giản để chuyển đổi token thành lexeme. Do đó, lexeme đại diện cho một dạng chuẩn hóa của một từ hoặc token có thể được lập chỉ mục và sử dụng cho các thao tác tìm kiếm.\nHàm FREETEXTTABLE với RANK FTS trong SQL Server có thể tạo ra một điểm số (hoặc giá trị thứ hạng) tùy chọn, thể hiện mức độ liên quan của dữ liệu được trả về bởi truy vấn toàn văn. Giá trị thứ hạng này được tính toán trên mỗi hàng và có thể được sử dụng làm tiêu chí sắp xếp để sắp xếp tập kết quả của truy vấn theo mức độ liên quan. Giá trị thứ hạng chỉ hiển thị thứ tự liên quan tương đối của các hàng trong tập kết quả. Giá trị thực tế không quan trọng và thường khác nhau mỗi lần bạn chạy truy vấn. Giá trị thứ hạng không có ý nghĩa gì giữa các truy vấn.\nTrong các truy vấn mẫu sau, FREETEXTTABLE kiểm tra các từ “entry” hoặc “level” và dạng của chúng (sử dụng phép loại suy) trong cột Mô tả và cũng lấy thông tin RANK:\nSELECT FT_TBL.[ProductDescriptionID],FT_TBL.[Description], KEY_TBL.[RANK]\nFROM [AdventureWorks2019].[Production].[ProductDescription] FT_TBL\nINNER JOIN FREETEXTTABLE([AdventureWorks2019].[Production].[ProductDescription], [Description], \u0026rsquo;entry OR level\u0026rsquo;,1033) AS KEY_TBL\nON FT\\_TBL.\\[ProductDescriptionID\\] \\=KEY\\_TBL.\\[KEY\\] ORDER BY KEY_TBL.[RANK] DESC,FT_TBL.[ProductDescriptionID];\nTrong PostgreSQL, ts_rank hàm này được sử dụng để tính toán thứ hạng liên quan của kết quả tìm kiếm dựa trên mức độ khớp của chúng với một truy vấn cụ thể. Thứ hạng được tính toán bằng cách sử dụng một giá trị số biểu thị mức độ khớp của tài liệu với các thuật ngữ tìm kiếm trong truy vấn.\nHàm này ts_headlineđược sử dụng để tạo phiên bản tóm tắt văn bản của tài liệu, làm nổi bật các phần liên quan nhất khớp với truy vấn tìm kiếm cụ thể. Hàm này hữu ích để tạo các đoạn trích hoặc tiêu đề kết quả tìm kiếm, cung cấp ngữ cảnh cho người dùng về lý do tại sao một tài liệu nhất định được áp dụng cho tìm kiếm của họ. Ảnh chụp màn hình sau đây hiển thị kết quả của cột tiêu đề truy vấn PostgreSQL được tạo bằng hàm ts_headline.\n![][image5]\nCác hàm CONTAINSTABLE và FORMSOF với RANK Hàm này FORMSOF trong SQL Server được sử dụng để thực hiện tìm kiếm biến tố . Tìm kiếm biến tố bao gồm việc tìm kiếm các dạng khác nhau của một từ, chẳng hạn như dạng số nhiều, thì động từ hoặc các dạng từ liên quan. Điều này có thể giúp bạn tìm thấy các tài liệu liên quan ngay cả khi chúng chứa các biến thể của thuật ngữ tìm kiếm, do đó cải thiện độ chính xác của tìm kiếm.\nTrong các truy vấn mẫu sau, CONTAINSTABLE kiểm tra từ “gear” và dạng của chúng (sử dụng INFLECTIONAL) trong cột Mô tả và cũng lấy RANK thông tin:\nSELECT FT_TBL.[ProductDescriptionID],FT_TBL.[Description], KEY_TBL.[RANK]\nFROM [AdventureWorks2019].[Production].[ProductDescription] FT_TBL\n**INNER JOIN CONTAINSTABLE(\\[AdventureWorks2019\\].\\[Production\\].\\[ProductDescription\\],** **\\[Description\\], 'FORMSOF(INFLECTIONAL,''gear'')',1033)** AS KEY_TBL\nON FT_TBL.[ProductDescriptionID] = KEY_TBL.[KEY]\nORDER BY KEY_TBL.[RANK] DESC,FT_TBL.[ProductDescriptionID];\nTrong các truy vấn PostgreSQL, các cụm từ trước tiên được chia thành các từ hoặc mã thông báo, và các từ này được chuẩn hóa và phân loại thành các từ gốc (lexeme) bằng cách sử dụng pg_catalog.english cấu hình FTS. Các lexeme này sẽ giống nhau cho các dạng khác nhau (phân loại) của một từ. Do đó, tính năng này sẽ tự động xử lý các tìm kiếm biến tố.\nMáy chủ SQL SELECT FT_TBL.[ProductDescriptionID],FT_TBL.[Description], KEY_TBL.[RANK] FROM [AdventureWorks2019].[Production].[ProductDescription] FT_TBL INNER JOIN CONTAINSTABLE([AdventureWorks2019].[Production].[ProductDescription], [Description], \u0026lsquo;FORMSOF(INFLECTIONAL,\u0026lsquo;\u0026lsquo;gear\u0026rsquo;\u0026rsquo;)\u0026rsquo;,1033) AS KEY_TBL ON FT_TBL.[ProductDescriptionID] = KEY_TBL.[KEY] ORDER BY KEY_TBL.[RANK] DESC,FT_TBL.[ProductDescriptionID]; ![][image6] PostgreSQL **SELECT p.productdescriptionid ,p.description, ts_rank(to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;,p.Description), query) AS rank, ts_headline(\u0026lsquo;pg_catalog.english\u0026rsquo;,p.Description,query) headline FROM production.productdescription p, to_tsquery(\u0026lsquo;pg_catalog.english\u0026rsquo;,\u0026lsquo;gear\u0026rsquo;) query WHERE query @@ to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;,p.Description) ORDER BY rank desc,p.productdescriptionid; Cải thiện hiệu suất truy vấn trong PostgreSQL Đối với các truy vấn PostgreSQL mẫu được hiển thị trước đó, to_tsvector hàm này lấy các tsvector giá trị từ cột Mô tả trong productdescription bảng. Trong các phần sau, chúng tôi sẽ giới thiệu cho bạn các tùy chọn khác nhau để cải thiện hiệu suất truy vấn.\nGiải pháp 1: Sử dụng chỉ mục GIN Chỉ mục GIN (Generalized Inverted Index) trong PostgreSQL là một phương pháp lập chỉ mục phổ biến được sử dụng để tăng tốc hiệu quả việc tìm kiếm các kiểu dữ liệu phức tạp như JSON và tìm kiếm toàn văn bản. Chỉ mục cơ sở dữ liệu chuẩn, một cây B, được thiết kế để kiểm tra tính bằng nhau, trong khi GIN được thiết kế cho các mẫu tìm kiếm hoạt động trên các cấu trúc dữ liệu lồng nhau hoặc tổng hợp, cho phép các mẫu tìm kiếm biểu cảm hơn. Bằng cách lập chỉ mục các thành phần của các kiểu dữ liệu phức tạp riêng biệt, chỉ mục GIN cho phép truy vấn nhanh hơn trên các mảng, dữ liệu JSON và các thao tác tìm kiếm văn bản. Điều này khiến chỉ mục GIN trở thành một công cụ hữu ích để cải thiện hiệu suất của các truy vấn liên quan đến các cấu trúc dữ liệu phức tạp trong cơ sở dữ liệu PostgreSQL.\nTrong cách tiếp cận này, bạn tạo chỉ mục GIN dựa trên biểu thức trên cột quan tâm trong bảng mô tả sản phẩm.\nChạy lệnh sau: CREATE INDEX productdescription_gin_idx ON production.productdescription\nUSING GIN (to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;, Description)); Nếu bảng có hàng triệu hàng, bạn có thể tăng maintenance_work_mem tham số cấu hình ở cấp độ phiên để tăng tốc thời gian tạo chỉ mục. maintenance_work_mem chỉ định lượng bộ nhớ tối đa tính bằng MB sẽ được sử dụng cho các hoạt động bảo trì như tạo INDEX—theo mặc định (PostgreSQL), là 64 MB. Chạy truy vấn EXPLAIN ANALYZE sau: EXPLAIN ANALYZE\nSELECT * FROM production.productdescription\nWHERE to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;, Description) @@ to_tsquery(\u0026lsquo;pg_catalog.english\u0026rsquo;,\u0026rsquo;entry | level\u0026rsquo;)\nORDER BY productdescriptionid DESC; Đầu ra hiển thị quá trình quét chỉ mục bitmap đang được thực hiện trên productdescription_gin_index, giúp cải thiện hiệu suất truy vấn. Ảnh chụp màn hình sau đây cho thấy kế hoạch giải thích trước khi tạo chỉ mục.\nẢnh chụp màn hình sau đây cho thấy kế hoạch giải thích sau khi tạo chỉ mục.\nTrong trường hợp này, chúng ta có thể thấy hiệu suất truy vấn được cải thiện khi sử dụng chỉ mục GIN. Mặc dù nhìn chung, việc sử dụng chỉ mục GIN cho tìm kiếm toàn văn trong PostgreSQL có thể giúp cải thiện hiệu suất, bạn cần lưu ý những đánh đổi khác về hiệu suất, bao gồm thời gian cần thiết để xây dựng chỉ mục và dung lượng lưu trữ bổ sung mà chỉ mục yêu cầu.\nGiải pháp 2: Sử dụng cột được tạo đã lưu trữ Trong cách tiếp cận này, bạn tạo một cột tính toán description_tsv chứa tsvector giá trị từ cột mô tả trong bảng theo sau là chỉ mục GIN trên cột tính toán.\nChạy các lệnh sau: ALTER TABLE production.productdescription\nADD COLUMN description_tsv tsvector\nGENERATED ALWAYS AS (to_tsvector(\u0026lsquo;pg_catalog.english\u0026rsquo;,Description )) STORED;\nCREATE INDEX productdescription_gin_idx ON production.productdescription USING GIN(description_tsv); Chạy truy vấn EXPLAIN ANALYZE mẫu sau: EXPLAIN ANALYZE\nSELECT *\nFROM production.productdescription\nWHERE description_tsv @@ to_tsquery(\u0026lsquo;pg_catalog.english\u0026rsquo;,\u0026rsquo;entry | level\u0026rsquo;)\nORDER BY productdescriptionid DESC; Đầu ra cho thấy quá trình quét chỉ mục bitmap đang được thực hiện trên productdescription_gin_index , trong trường hợp này chứng minh sự cải thiện về hiệu suất truy vấn:\nTìm kiếm toàn văn bản trong PostgreSQL bằng tiện ích mở rộng pg_trgm Trong PostgreSQL, pg_trgm phần mở rộng này được triển khai cho các chức năng tìm kiếm văn bản sử dụng trigram. Trigram về cơ bản là tập hợp ba ký tự liên tiếp được trích xuất từ ​​một chuỗi cho trước. Bằng cách sử dụng trigram, người dùng có thể xác định sự tương đồng hoặc trùng khớp trong các mẫu văn bản bên trong chuỗi bằng cách so sánh số lượng trigram trùng khớp giữa các chuỗi, cùng với tham số ngưỡng tương đồng được xác định trước được thiết lập trước khi thực hiện tìm kiếm.\nTiện pg_trgm ích mở rộng cung cấp các toán tử có thể được sử dụng để tạo chỉ mục trigram trên các cột văn bản trong bảng cần tìm kiếm. Chỉ mục này cho phép thực hiện các phép toán tương tự hiệu quả trên các cột được lập chỉ mục. Tiện ích mở rộng cung cấp ba phép toán tương tự: similarity (%), word_similarity (\u0026lt;%), và strict_word_similarity (\u0026lt;\u0026lt;%). Các tham số ngưỡng cho các phép toán tương ứng là pg_trgm.similarity_threshold, pg_trgm.word_similarity_threshold, và pg_trgm.strict_word_similarity_threshold, có thể được đặt thành giá trị từ 0 (không tương tự) đến 1 (khớp hoàn hảo). Các hàm similarity(), word_similarty(), và strict_word_similarity()được sử dụng để tính điểm tương tự. Bạn có thể sử dụng pg_trgmnhư trong đoạn mã sau:\nChạy lệnh sau để tạo phần mở rộng pg_trgm:\nCREATE EXTENSION pg_trgm; Chạy lệnh sau để tạo chỉ mục GIN trên cột productdescription: CREATE INDEX productdescription_trgm_idx ON production.productdescription USING GIN (Description gin_trgm_ops); Chạy lệnh sau để đặt giá trị cấu hình similarity_threshold thành 0,2. Tính năng similarity sẽ kiểm tra các trigram chung giữa hai chuỗi và trả về giá trị từ 0–1. SET pg_trgm.similarity_threshold = 0.2;\nSET enable_seqscan = off;\nSELECT productdescriptionid, Description, similarity(Description, \u0026rsquo;entry level\u0026rsquo;) AS sml\nFROM production.product description\nWHERE Description % \u0026rsquo;entry level\u0026rsquo;\nORDER BY sml DESC, Description; Chạy lệnh sau để đặt giá trị cấu hình word_similarity_threshold thành 0,6. word_similarity kiểm tra các trigram chung giữa các chuỗi ở cấp độ từ. SET pg_trgm.word_similarity_threshold = 0.6;\nSET enable_seqscan = off;\nSELECT productdescriptionid, Description, word_similarity(\u0026rsquo;entry level\u0026rsquo;, Description) AS sml\nFROM production.productdescription\nWHERE \u0026rsquo;entry level\u0026rsquo; \u0026lt;% Description\nORDER BY sml DESC, Description; Chạy lệnh sau để đặt giá trị cấu hình strict_word_similarity_threshold thành 0,6. strict_word_similarity giống như word_similarity nhưng nó chỉ xem xét các trigram chung khi cả hai từ giống hệt nhau. SET pg_trgm.strict_word_similarity_threshold = 0.6;\nSET enable_seqscan = off;\nSELECT productdescriptionid, Description, strict_word_similarity(\u0026lsquo;aluminum cups and hollow axle\u0026rsquo;, Description) AS sml\nFROM production.productdescription\nWHERE \u0026rsquo;entry level\u0026rsquo; \u0026lt;\u0026lt;% Description\nORDER BY sml DESC, Description; Chạy lệnh sau để xóa chỉ mục và kích hoạt quét tuần tự: DROP INDEX production.productdescription_trgm_idx; Tìm kiếm toàn văn bản trong PostgreSQL bằng tiện ích mở rộng pg_bigm Phần pg_bigmmở rộng trong PostgreSQL tăng cường khả năng tìm kiếm toàn văn bản, đặc biệt đối với các ngôn ngữ có bộ ký tự phức tạp như ngôn ngữ châu Á.\nBigram là một nhóm hai ký tự liên tiếp được lấy từ một chuỗi. Phần mở rộng này sử dụng phương pháp lập chỉ mục bigram, bao gồm việc chia văn bản thành các cặp ký tự liên tiếp và xây dựng một chỉ mục dựa trên các bigram này. Phần mởpg_bigm rộng cung cấp bigm_similarity()hàm, toán tử tương tự bigm = %và pg_bigm.similarity_limittham số ngưỡng. Bạn có thể sử dụng pg_bigmnhư sau:\nChạy lệnh sau để tạo phần mở rộng pg_bigm. Để biết hướng dẫn tạo phần mở rộng trong Amazon RDS for PostgreSQL, hãy tham khảo bài viết Sử dụng phần mở rộng PostgreSQL với Amazon RDS for PostgreSQL . CREATE EXTENSION pg_bigm; Chạy lệnh sau để tạo chỉ mục GIN trên cột productdescription: CREATE INDEX productdescription_bigm_idx ON production.productdescription USING gin (Description gin_bigm_ops); Chạy lệnh sau để đặt giá trị cấu hình similarity_limit thành 0,15. Kiểm tra tính tương đồng để tìm các bigram chung giữa hai chuỗi và trả về giá trị từ 0–1. SET pg_bigm.similarity_limit TO 0.15;\nSELECT *,bigm_similarity(Description, \u0026lsquo;%entry level%\u0026rsquo;) rank1\nFROM production.productdescription\nWHERE Description =% \u0026lsquo;%entry level%\u0026rsquo;\nORDER BY rank1 DESC; Chạy lệnh sau để xóa chỉ mục và bật quét tuần tự: DROP INDEX production.productdescription_bigm_idx;\nSET enable_seqscan = on; Phần kết luận Trong bài viết này, chúng tôi đã hướng dẫn bạn cách di chuyển FTS từ SQL Server sang PostgreSQL và so sánh một số trường hợp sử dụng phổ biến. Việc di chuyển tìm kiếm toàn văn bản từ SQL Server sang PostgreSQL đòi hỏi phải viết lại mã thủ công. Để tìm hiểu thêm, vui lòng tham khảo các hạn chế của tính năng tìm kiếm văn bản trong PostgreSQL . Chúng tôi cũng đã hướng dẫn bạn cách sử dụng các phần mở rộng pg_trgm và pg_bigm trong PostgreSQL để triển khai FTS.\nVề các tác giả\n![][image15]\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; Mục Đích Của Sự Kiện Tìm hiểu tác động biến đổi của generative AI trong phát triển phần mềm Hiểu cách tích hợp AI vào vòng đời phát triển phần mềm (SDLC) Giới thiệu các công cụ AI để tự động hóa tác vụ phát triển: Amazon Q Developer và Kiro Học cách tận dụng AI để tăng năng suất và tập trung vào công việc có giá trị cao Diễn Giả \u0026amp; Tổ Chức Giảng viên:\nToan Huynh – Tổng quan về AI-Driven Development Life Cycle và trình diễn Amazon Q Developer My Nguyen – Trình diễn Kiro Điều phối viên:\nDiem My Dai Truong Dinh Nguyen Chi Tiết Sự Kiện Ngày: Thứ Sáu, 3 tháng 10 năm 2025 Thời gian: 14:00 – 16:30 Địa điểm: AWS Event Hall, Tầng 26, Tòa nhà Bitexco, thành phố Hồ Chí Minh Thời lượng: 2.5 giờ Chương Trình 14:00 - 14:15: Đón tiếp 14:15 - 15:30: Tổng quan về AI-Driven Development Life Cycle và trình diễn Amazon Q Developer (bởi Toan Huynh) 15:30 - 15:45: Nghỉ giải lao 15:45 - 16:30: Trình diễn Kiro (bởi My Nguyen) Nội Dung Nổi Bật Sự Nổi Lên Của Generative AI Trong Phát Triển Phần Mềm Sự biến đổi: Generative AI tái tưởng tượng cách các nhà phát triển và tổ chức học hỏi, lập kế hoạch, tạo ra, triển khai và quản lý ứng dụng một cách an toàn Tích hợp SDLC: AI có thể được tích hợp vào toàn bộ vòng đời phát triển phần mềm: kiến trúc, phát triển, kiểm thử, triển khai và bảo trì Lợi ích tự động hóa: Tự động hóa các tác vụ nặng không phân biệt, cho phép các nhà phát triển tập trung vào công việc có giá trị cao và sáng tạo hơn Tăng năng suất: Tăng năng suất đồng thời cho phép các nhà phát triển tập trung vào giải quyết vấn đề sáng tạo và đổi mới AI-Driven Development Life Cycle Bao phủ end-to-end: Từ lập kế hoạch kiến trúc ban đầu thông qua phát triển, kiểm thử, triển khai và bảo trì liên tục Biến đổi workflow: Cách các công cụ AI định hình lại các workflow phát triển truyền thống Best practices: Hướng dẫn để tích hợp AI hiệu quả vào quy trình phát triển hiện có Amazon Q Developer Hỗ trợ SDLC: Công cụ AI toàn diện hỗ trợ toàn bộ vòng đời phát triển phần mềm Khả năng chính: Hỗ trợ tạo mã, gỡ lỗi, kiểm thử, tài liệu hóa và refactoring Tích hợp: Tích hợp mượt mà với các IDE và môi trường phát triển phổ biến Trình diễn thực tế: Ví dụ thực tế về sử dụng Amazon Q Developer để tăng tốc tác vụ phát triển Kiro AI-powered development: Giới thiệu Kiro như một trợ lý phát triển AI Use cases: Các tình huống cụ thể nơi Kiro nâng cao năng suất của nhà phát triển Tính năng: Các tính năng và khả năng chính được trình diễn trong phiên Trải nghiệm thực hành: Trình diễn thực tế về Kiro trong hành động Những Gì Học Được Chiến Lược Tích Hợp AI Áp dụng dần dần: Bắt đầu với các use case cụ thể và mở rộng dần việc tích hợp công cụ AI Đảm bảo chất lượng: Công cụ AI hỗ trợ nhưng giám sát và xem xét của con người vẫn quan trọng Đường cong học tập: Hiểu các công cụ AI cần thời gian và thực hành để tối đa hóa lợi ích Hợp tác nhóm: AI nâng cao năng suất nhóm nhưng đòi hỏi workflow và hướng dẫn rõ ràng Nâng Cao Workflow Phát Triển Tác vụ tự động: Xác định các tác vụ lặp đi lặp lại, giá trị thấp có thể được tự động hóa bằng AI Chất lượng mã: Sử dụng AI cho code review, kiểm thử và tài liệu để duy trì tiêu chuẩn cao Tăng tốc: Tận dụng AI để tăng tốc chu kỳ phát triển mà không hy sinh chất lượng Học tập liên tục: Công cụ AI phát triển nhanh chóng—cập nhật các tính năng và best practices mới Năng Suất Và Tập Trung Tạo giá trị: Giải phóng các nhà phát triển khỏi các tác vụ thường ngày để tập trung vào giải quyết vấn đề phức tạp và đổi mới Tiết kiệm thời gian: Tiết kiệm thời gian đáng kể trong viết mã, gỡ lỗi và tài liệu hóa Bổ sung kiến thức: Công cụ AI giúp thu hẹp khoảng cách kiến thức và cung cấp hỗ trợ theo ngữ cảnh Khả năng mở rộng: AI cho phép các nhóm xử lý các dự án lớn hơn với cùng tài nguyên Ứng Dụng Vào Công Việc Tích hợp Amazon Q Developer: Bắt đầu sử dụng nó trong các tác vụ phát triển hàng ngày để tạo mã và hỗ trợ Khám phá Kiro: Đánh giá Kiro cho các use case cụ thể trong workflow phát triển của bạn Thiết lập AI workflows: Xác định hướng dẫn về khi nào và cách sử dụng công cụ AI trong các dự án nhóm Đo lường năng suất: Theo dõi cải thiện về tốc độ phát triển và chất lượng mã sau khi áp dụng công cụ AI Chia sẻ học hỏi: Tài liệu hóa best practices và chia sẻ kinh nghiệm với các thành viên nhóm Cập nhật liên tục: Theo dõi cập nhật cho các công cụ phát triển AI và tích hợp các tính năng mới khi chúng có sẵn Kết Quả Hoặc Giá Trị Đạt Được Tham gia sự kiện này mang lại giá trị đáng kể thông qua kiến thức mới, kỹ năng và hiểu biết thực tế có thể áp dụng trực tiếp vào các dự án hiện tại và tương lai.\nKiến Thức Mới Thu Được Khái Niệm AI-Driven Development:\nHiểu biết sâu sắc về cách generative AI biến đổi vòng đời phát triển phần mềm từ lập kế hoạch đến bảo trì Kiến thức toàn diện về tích hợp công cụ AI vào các giai đoạn khác nhau: thiết kế kiến trúc, tạo mã, kiểm thử, triển khai và giám sát liên tục Hiểu biết về best practices cho phát triển hỗ trợ AI, bao gồm khi nào nên tận dụng AI và khi nào phán đoán con người là quan trọng Chuyên Môn Amazon Q Developer:\nKiến thức thực tế về sử dụng Amazon Q Developer cho tạo mã, gỡ lỗi, tài liệu hóa và refactoring Hiểu cách tích hợp Amazon Q Developer với các IDE và môi trường phát triển hiện có Học về các khả năng cụ thể: gợi ý mã thông minh, hỗ trợ kiểm thử tự động, và cải thiện chất lượng mã Hiểu Biết Nền Tảng Kiro:\nKhám phá Kiro như một trợ lý phát triển AI và các tính năng độc đáo của nó Kiến thức về các use case cụ thể nơi Kiro có thể nâng cao năng suất của nhà phát triển Hiểu cách Kiro bổ sung cho các công cụ phát triển AI khác trong workflow Kỹ Năng Mới Phát Triển Tích Hợp Công Cụ AI:\nKỹ năng: Khả năng xác định cơ hội tự động hóa AI trong các workflow phát triển Kỹ năng: Thành thạo trong tích hợp công cụ AI như Amazon Q Developer vào các tác vụ phát triển hàng ngày Kỹ năng: Khả năng đánh giá và lựa chọn công cụ AI phù hợp cho nhu cầu dự án cụ thể Nâng Cao Workflow Phát Triển:\nKỹ năng: Cải thiện khả năng tự động hóa các tác vụ lập trình lặp đi lặp lại mà vẫn duy trì chất lượng mã Kỹ năng: Nâng cao khả năng code review bằng phân tích hỗ trợ AI Kỹ năng: Thực hành tài liệu hóa tốt hơn thông qua tạo tài liệu bằng AI Giải Quyết Vấn Đề Hỗ Trợ AI:\nKỹ năng: Tận dụng AI cho gỡ lỗi và xử lý sự cố phức tạp Kỹ năng: Sử dụng gợi ý AI để cải thiện hiệu quả mã và best practices Kỹ năng: Cân bằng hỗ trợ AI với xem xét và phán đoán quan trọng của con người Bài Học Rút Ra Hiểu Biết Thực Tế:\nCông cụ AI là bộ nhân năng suất mạnh mẽ nhưng đòi hỏi hiểu biết và tích hợp workflow phù hợp Chiến lược áp dụng dần dần hiệu quả hơn việc cố gắng tích hợp tất cả công cụ AI cùng một lúc Giám sát con người vẫn cần thiết—AI hỗ trợ nhưng không thay thế chuyên môn và phán đoán của nhà phát triển Đo lường cải thiện năng suất và chất lượng mã giúp biện minh cho việc áp dụng công cụ AI Hiểu Biết Chiến Lược:\nTích hợp AI thành công đòi hỏi sự đồng nhất nhóm và hướng dẫn rõ ràng về cách sử dụng Công cụ AI phát triển nhanh chóng—cập nhật liên tục với tính năng mới tối đa hóa giá trị lâu dài Xác định đúng use case là quan trọng—không phải tất cả tác vụ phát triển đều hưởng lợi như nhau từ hỗ trợ AI Chất lượng mã thực sự có thể cải thiện với công cụ AI khi được sử dụng một cách có suy nghĩ và được xem xét đúng cách Đóng Góp Cho Nhóm/Dự Án Chia Sẻ Kiến Thức:\nTài liệu hóa: Tạo ghi chú và tài liệu về best practices từ sự kiện để chia sẻ với các thành viên nhóm Trình bày: Chuẩn bị chia sẻ hiểu biết về Amazon Q Developer và Kiro với nhóm phát triển Hướng dẫn: Phát triển hướng dẫn ban đầu để tích hợp công cụ AI vào workflow nhóm Ứng Dụng Thực Tế:\nDự án thí điểm: Xác định các dự án cụ thể nơi công cụ AI có thể được thí điểm để đạt được lợi ích năng suất ngay lập tức Cải thiện workflow: Đề xuất tích hợp Amazon Q Developer cho code review và tác vụ tài liệu hóa Đào tạo: Lập kế hoạch tổ chức các phiên nội bộ về thực hành phát triển dựa trên AI cho nhóm Giá Trị Dài Hạn:\nLợi thế cạnh tranh: Có được kiến thức giúp nhóm tận dụng các công cụ phát triển AI tiên tiến Cải thiện hiệu quả: Dự kiến cải thiện 20-30% tốc độ phát triển cho các tác vụ lặp đi lặp lại bằng công cụ AI Nâng cao chất lượng: Tiềm năng cải thiện chất lượng mã thông qua xem xét hỗ trợ AI và gợi ý best practices Đổi mới: Khả năng mới cho phép nhóm giải quyết các vấn đề phức tạp hơn bằng cách giao phó công việc thường ngày cho AI Phát Triển Cá Nhân Phát Triển Kỹ Thuật:\nMở rộng hiểu biết về thực hành phát triển phần mềm hiện đại với tích hợp AI Phát triển quan điểm tư duy tiến bộ về sự tiến hóa của kỹ thuật phần mềm Nâng cao khả năng đánh giá và áp dụng công nghệ mới hiệu quả Phát Triển Nghề Nghiệp:\nTăng tự tin trong làm việc với công cụ phát triển AI Cải thiện khả năng giao tiếp khái niệm kỹ thuật cho cả đối tượng kỹ thuật và phi kỹ thuật Tăng cường kết nối mạng với các nhà phát triển khác quan tâm đến phát triển dựa trên AI Trải nghiệm trong event Tham gia phiên \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; là một trải nghiệm mở mang tầm mắt, cung cấp những hiểu biết sâu sắc về cách generative AI đang biến đổi phát triển phần mềm. Các trải nghiệm chính bao gồm:\nHiểu về sự biến đổi AI Học cách generative AI đánh dấu sự thay đổi biến đổi trong thực hành phát triển phần mềm. Hiểu biết về tích hợp AI vào toàn bộ SDLC: kiến trúc, phát triển, kiểm thử, triển khai và bảo trì. Hiểu cách tự động hóa AI cho phép các nhà phát triển tập trung vào các tác vụ sáng tạo có giá trị cao hơn. Trình diễn công cụ thực hành Chứng kiến Amazon Q Developer trong hành động, xem cách nó có thể hỗ trợ tạo mã, gỡ lỗi và tài liệu hóa. Khám phá Kiro như một trợ lý phát triển AI và tìm hiểu về các khả năng và use case cụ thể của nó. Xem các ví dụ thực tế về cách các công cụ này tăng tốc phát triển đồng thời duy trì chất lượng mã. Học tập thực tế Học về best practices để tích hợp công cụ AI vào các workflow phát triển hiện có. Hiểu tầm quan trọng của giám sát con người và đảm bảo chất lượng khi sử dụng công cụ AI. Hiểu biết về xác định cơ hội cho tự động hóa AI trong quy trình phát triển. Kết nối và thảo luận Kết nối với các nhà phát triển khác quan tâm đến phát triển dựa trên AI. Trao đổi ý tưởng về ứng dụng thực tế của công cụ AI trong các dự án thực tế. Thảo luận về thách thức và cơ hội trong việc áp dụng công cụ phát triển AI. Bài học rút ra Công cụ AI là trợ lý mạnh mẽ nhưng phán đoán và xem xét của con người vẫn cần thiết cho mã chất lượng. Tích hợp AI thành công đòi hỏi áp dụng dần dần và đào tạo nhóm. Công cụ AI phù hợp có thể tăng năng suất đáng kể và giải phóng các nhà phát triển cho công việc sáng tạo hơn. Cập nhật với sự tiến hóa của công cụ AI là rất quan trọng để tối đa hóa lợi ích. Một số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện này mở mang tầm mắt về tiềm năng của phát triển dựa trên AI và cung cấp hướng dẫn thực tế về cách tận dụng những công cụ mạnh mẽ này để nâng cao năng suất, cải thiện chất lượng mã và tập trung vào công việc có giá trị cao trong kỹ thuật phần mềm.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;AI/ML/GenAI on AWS\u0026rdquo; Mục Đích Của Sự Kiện Cung cấp tổng quan toàn diện về dịch vụ và khả năng AI/ML của AWS Giới thiệu Amazon SageMaker như một nền tảng ML end-to-end Khám phá Generative AI với Amazon Bedrock Minh họa các ứng dụng thực tế thông qua demo trực tiếp Chia sẻ best practices cho triển khai AI/ML tại Việt Nam Chi Tiết Sự Kiện Ngày: Thứ Bảy, 15 tháng 11 năm 2025 Thời gian: 8:30 – 12:00 Địa điểm: Văn phòng AWS Vietnam Thời lượng: 3.5 giờ (không bao gồm nghỉ trưa) Chương Trình 8:30 – 9:00 | Đón tiếp \u0026amp; Giới thiệu Đăng ký tham gia và networking Tổng quan workshop và mục tiêu học tập Hoạt động phá băng Tổng quan về thị trường AI/ML tại Việt Nam 9:00 – 10:30 | Tổng quan dịch vụ AWS AI/ML Amazon SageMaker – Nền tảng ML end-to-end Chuẩn bị và gắn nhãn dữ liệu Huấn luyện, tinh chỉnh và triển khai mô hình Khả năng MLOps tích hợp Demo trực tiếp: Hướng dẫn SageMaker Studio 10:30 – 10:45 | Nghỉ giải lao 10:45 – 12:00 | Generative AI với Amazon Bedrock Foundation Models: Claude, Llama, Titan – so sánh \u0026amp; hướng dẫn lựa chọn Prompt Engineering: Kỹ thuật, Chain-of-Thought reasoning, Few-shot learning Retrieval-Augmented Generation (RAG): Kiến trúc \u0026amp; Tích hợp Knowledge Base Bedrock Agents: Multi-step workflows và tích hợp công cụ Guardrails: An toàn và lọc nội dung Demo trực tiếp: Xây dựng chatbot Generative AI sử dụng Bedrock Nội Dung Nổi Bật Nền Tảng Amazon SageMaker Nền Tảng ML Toàn Diện: Giải pháp hoàn chỉnh cho xây dựng, huấn luyện và triển khai mô hình machine learning Chuẩn Bị Dữ Liệu: Công cụ cho gắn nhãn dữ liệu, feature engineering, và validation dữ liệu Huấn Luyện Mô Hình: Hỗ trợ các framework và thuật toán ML khác nhau với khả năng huấn luyện phân tán Triển Khai Mô Hình: Các tùy chọn triển khai linh hoạt bao gồm real-time inference, batch processing, và serverless inference Tích Hợp MLOps: Khả năng tích hợp sẵn cho giám sát mô hình, versioning, và automated workflows Generative AI với Amazon Bedrock Lựa Chọn Foundation Model: Hiểu sự khác biệt giữa các mô hình Claude, Llama, và Titan Claude: Khả năng lý luận và trò chuyện mạnh mẽ Llama: Mô hình mã nguồn mở với hiệu suất tốt Titan: Mô hình do AWS phát triển được tối ưu cho các use case cụ thể Kỹ Thuật Prompt Engineering: Chain-of-Thought reasoning cho giải quyết vấn đề phức tạp Few-shot learning với ví dụ Quản lý ngữ cảnh và tối ưu hóa prompt Kiến Trúc RAG: Kết hợp retrieval với generation cho phản hồi chính xác, nhận biết ngữ cảnh Tích hợp knowledge base Vector embeddings và similarity search Chiến lược chunking tài liệu Bedrock Agents: Tác nhân tự động có thể thực hiện các tác vụ multi-step Tích hợp công cụ và gọi API Orchestration workflow Khả năng ra quyết định Guardrails cho An Toàn AI: Lọc nội dung và kiểm soát an toàn Phát hiện nội dung có hại Cấu hình policy tùy chỉnh Tuân thủ và quản trị Thị Trường AI/ML tại Việt Nam Xu hướng và cơ hội áp dụng hiện tại Use cases cụ thể cho thị trường Việt Nam Thách thức và giải pháp cho doanh nghiệp địa phương Câu chuyện thành công và case studies Những Gì Học Được Best Practices Machine Learning Cách Tiếp Cận Nền Tảng End-to-end: Sử dụng SageMaker cho quản lý vòng đời ML hoàn chỉnh Chất Lượng Dữ Liệu Trước Tiên: Đầu tư vào chuẩn bị và gắn nhãn dữ liệu để cải thiện hiệu suất mô hình Tích Hợp MLOps: Triển khai giám sát và automated workflows ngay từ đầu Chiến Lược Lựa Chọn Mô Hình: Chọn mô hình phù hợp dựa trên use case, không chỉ metrics hiệu suất Triển Khai Generative AI Lựa Chọn Foundation Model: Hiểu điểm mạnh của từng mô hình (Claude, Llama, Titan) cho các scenario khác nhau Thành Thạo Prompt Engineering: Chain-of-Thought và Few-shot learning cải thiện đáng kể kết quả RAG cho Độ Chính Xác: Sử dụng kiến trúc RAG khi độ chính xác thực tế là quan trọng Thiết Kế Agent: Xây dựng agent có thể xử lý multi-step workflows với tích hợp công cụ phù hợp An Toàn Trước Tiên: Luôn triển khai guardrails cho lọc nội dung và tuân thủ Sẵn Sàng Sản Xuất Bắt Đầu Nhỏ, Mở Rộng Dần: Bắt đầu với dự án thí điểm trước khi triển khai đầy đủ Tối Ưu Chi Phí: Giám sát và tối ưu chi phí inference với các tùy chọn serverless Bảo Mật \u0026amp; Tuân Thủ: Triển khai kiểm soát truy cập và biện pháp bảo mật dữ liệu phù hợp Cải Thiện Liên Tục: Giám sát hiệu suất mô hình và lặp lại dựa trên phản hồi thực tế Ứng Dụng Vào Công Việc Khám Phá SageMaker: Bắt đầu với SageMaker Studio cho thử nghiệm ML và phát triển mô hình Triển Khai Giải Pháp RAG: Xây dựng knowledge base cho ứng dụng domain-specific sử dụng kiến trúc RAG Phát Triển Bedrock Agents: Tạo tác nhân tự động cho dịch vụ khách hàng hoặc tự động hóa workflow Thực Hành Prompt Engineering: Áp dụng kỹ thuật Chain-of-Thought và Few-shot để cải thiện phản hồi AI Triển Khai Guardrails: Triển khai lọc nội dung và kiểm soát an toàn cho ứng dụng GenAI sản xuất Thiết Lập MLOps: Thiết lập giám sát mô hình và automated deployment pipelines sử dụng khả năng SageMaker Trải nghiệm trong event Tham gia workshop \u0026ldquo;AI/ML/GenAI on AWS\u0026rdquo; là một trải nghiệm học tập đặc biệt cung cấp hiểu biết toàn diện về khả năng AI và machine learning của AWS. Sự kiện kết hợp kiến thức lý thuyết với các trình diễn thực tế, giúp em hiểu rõ cách triển khai giải pháp AI/ML trên AWS.\nHọc từ chương trình toàn diện Chương trình có cấu trúc bao phủ mọi thứ từ khái niệm ML cơ bản đến triển khai Generative AI nâng cao. Bắt đầu với tổng quan nền tảng SageMaker giúp em hiểu vòng đời ML hoàn chỉnh trước khi đi sâu vào chi tiết GenAI. Sự tiến triển từ ML truyền thống đến Generative AI cho thấy sự tiến hóa và tính bổ sung của các công nghệ này. Trải nghiệm kỹ thuật thực hành Hướng dẫn SageMaker Studio minh họa quy trình thực tế xây dựng mô hình ML, từ chuẩn bị dữ liệu đến triển khai. Em học về các công cụ gắn nhãn dữ liệu và cách chúng có thể cải thiện đáng kể độ chính xác mô hình với chất lượng dữ liệu phù hợp. Khả năng MLOps cho em thấy cách triển khai continuous integration và giám sát cho mô hình ML trong sản xuất. Tìm hiểu sâu về Generative AI Phiên Amazon Bedrock rất mở mang tầm mắt, cho em thấy cách tận dụng foundation models mà không cần huấn luyện từ đầu. Kỹ thuật Prompt Engineering như Chain-of-Thought reasoning và Few-shot learning được minh họa với các ví dụ thực tế. Học về kiến trúc RAG giúp em hiểu cách xây dựng ứng dụng AI chính xác kết hợp retrieval với generation. Demo Bedrock Agents cho thấy cách xây dựng hệ thống AI tự động có thể thực hiện các tác vụ multi-step phức tạp. Trình diễn thực tế Demo trực tiếp xây dựng chatbot Generative AI sử dụng Bedrock cho em bức tranh hoàn chỉnh về triển khai từ đầu đến cuối. Xem Guardrails hoạt động minh chứng tầm quan trọng của an toàn và lọc nội dung trong ứng dụng GenAI sản xuất. So sánh giữa các mô hình Claude, Llama, và Titan giúp em hiểu khi nào sử dụng mỗi mô hình. Kết nối và thảo luận Workshop cung cấp cơ hội networking tuyệt vời với các người đam mê và thực hành AI/ML khác tại Việt Nam. Thảo luận về thị trường AI/ML tại Việt Nam cho em hiểu biết theo ngữ cảnh về cơ hội và thách thức thị trường địa phương. Chia sẻ kinh nghiệm với đồng nghiệp giúp em hiểu các thách thức và giải pháp triển khai thực tế. Bài học rút ra SageMaker cung cấp một nền tảng hoàn chỉnh đơn giản hóa toàn bộ vòng đời ML, từ chuẩn bị dữ liệu đến triển khai. Foundation models trong Bedrock loại bỏ nhu cầu huấn luyện mô hình lớn từ đầu, giảm đáng kể thời gian và chi phí. Kiến trúc RAG là quan trọng cho xây dựng ứng dụng GenAI chính xác cần tham chiếu knowledge base cụ thể. Prompt engineering là một kỹ năng đòi hỏi thực hành và hiểu biết các kỹ thuật khác nhau để có kết quả tối ưu. Guardrails là cần thiết cho ứng dụng GenAI sản xuất để đảm bảo an toàn và tuân thủ. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop này cung cấp cho em cả kiến thức nền tảng và kỹ năng thực tế cần thiết để triển khai giải pháp AI/ML và Generative AI trên AWS. Sự kết hợp giữa tổng quan nền tảng toàn diện, khả năng GenAI chi tiết, và các trình diễn thực hành cho em tự tin bắt đầu xây dựng các ứng dụng được hỗ trợ bởi AI.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;DevOps on AWS\u0026rdquo; Mục Đích Của Sự Kiện Giới thiệu văn hóa, nguyên tắc và các metrics chính của DevOps Trình diễn các dịch vụ AWS DevOps cho tự động hóa CI/CD pipeline Khám phá Infrastructure as Code (IaC) với CloudFormation và CDK Bao phủ các dịch vụ container và chiến lược triển khai microservices Cung cấp best practices về monitoring và observability Chia sẻ case studies DevOps thực tế và best practices Chi Tiết Sự Kiện Ngày: Thứ Hai, 17 tháng 11 năm 2025 Thời gian: 08:30 – 17:00 Địa điểm: Tòa nhà Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh Thời lượng: Cả ngày (8.5 giờ với các giờ nghỉ) Chương Trình Buổi Sáng (8:30 AM – 12:00 PM) 8:30 – 9:00 | Đón tiếp \u0026amp; DevOps Mindset\nTóm tắt lại phiên AI/ML Văn hóa và nguyên tắc DevOps Lợi ích và các metrics chính (DORA, MTTR, tần suất deployment) 9:00 – 10:30 | Dịch vụ AWS DevOps – CI/CD Pipeline\nSource Control: AWS CodeCommit, Git strategies (GitFlow, Trunk-based) Build \u0026amp; Test: Cấu hình CodeBuild, testing pipelines Deployment: CodeDeploy với Blue/Green, Canary, và Rolling updates Orchestration: Tự động hóa CodePipeline Demo: Hướng dẫn CI/CD pipeline đầy đủ 10:30 – 10:45 | Nghỉ giải lao\n10:45 – 12:00 | Infrastructure as Code (IaC)\nAWS CloudFormation: Templates, stacks, và drift detection AWS CDK (Cloud Development Kit): Constructs, reusable patterns, và language support Demo: Triển khai với CloudFormation và CDK Thảo luận: Lựa chọn giữa các công cụ IaC Nghỉ Trưa (12:00 – 13:00) Buổi Chiều (13:00 – 17:00) 13:00 – 14:30 | Dịch Vụ Container trên AWS\nDocker Fundamentals: Microservices và containerization Amazon ECR: Lưu trữ image, scanning, lifecycle policies Amazon ECS \u0026amp; EKS: Chiến lược deployment, scaling, và orchestration AWS App Runner: Triển khai container đơn giản Demo \u0026amp; Case Study: So sánh triển khai microservices 14:30 – 14:45 | Nghỉ giải lao\n14:45 – 16:00 | Monitoring \u0026amp; Observability\nCloudWatch: Metrics, logs, alarms, và dashboards AWS X-Ray: Distributed tracing và performance insights Demo: Thiết lập full-stack observability Best Practices: Alerting, dashboards, và quy trình on-call 16:00 – 16:45 | DevOps Best Practices \u0026amp; Case Studies\nChiến lược deployment: Feature flags, A/B testing Automated testing và tích hợp CI/CD Quản lý incident và postmortems Case Studies: Chuyển đổi DevOps của startups và enterprise 16:45 – 17:00 | Q\u0026amp;A \u0026amp; Tổng kết\nCon đường nghề nghiệp DevOps Lộ trình chứng chỉ AWS Nội Dung Nổi Bật Văn Hóa và Nguyên Tắc DevOps DevOps Mindset: Hợp tác giữa các team development và operations Chuyển Đổi Văn Hóa: Phá vỡ silos và thúc đẩy trách nhiệm chia sẻ Metrics Chính (DORA): Đo lường hiệu suất DevOps Deployment Frequency: Tần suất triển khai xảy ra Lead Time: Thời gian từ code commit đến production MTTR (Mean Time To Recovery): Thời gian khôi phục sau lỗi Change Failure Rate: Tỷ lệ phần trăm các deployment gây lỗi Lợi Ích: Giao hàng nhanh hơn, độ tin cậy cải thiện, hợp tác tốt hơn Dịch Vụ AWS CI/CD Pipeline AWS CodeCommit:\nDịch vụ source control được quản lý đầy đủ Version control dựa trên Git Tích hợp với các dịch vụ AWS khác Git strategies: GitFlow, Trunk-based development, feature branches AWS CodeBuild:\nDịch vụ build được quản lý đầy đủ Môi trường build có thể mở rộng Hỗ trợ nhiều ngôn ngữ lập trình và công cụ build Build artifacts và test reports Tích hợp với testing frameworks AWS CodeDeploy:\nDịch vụ deployment tự động Chiến lược deployment: Blue/Green: Triển khai zero-downtime với rollback tức thì Canary: Rollout dần dần với rollback tự động khi có lỗi Rolling: Cập nhật rolling với kích thước batch có thể cấu hình Triển khai ứng dụng trên EC2, Lambda, và on-premises AWS CodePipeline:\nDịch vụ continuous delivery được quản lý đầy đủ Trình tạo workflow trực quan Tích hợp với công cụ bên thứ ba Orchestration pipeline tự động Approval gates và điểm can thiệp thủ công Infrastructure as Code (IaC) AWS CloudFormation:\nDịch vụ IaC khai báo Cú pháp template JSON/YAML Quản lý stack và cung cấp tài nguyên Drift detection và cập nhật stack Change sets để xem trước thay đổi Nested stacks cho hạ tầng modular AWS CDK (Cloud Development Kit):\nIaC lập trình sử dụng ngôn ngữ lập trình quen thuộc Hỗ trợ TypeScript, Python, Java, C#, và Go Constructs cho các pattern hạ tầng có thể tái sử dụng Abstractions cấp cao hơn và best practices Tích hợp với CloudFormation CLI tools cho deployment và quản lý Lựa Chọn Giữa Các Công Cụ IaC:\nCloudFormation: Khai báo, dựa trên template, AWS-native CDK: Lập trình, type-safe, thân thiện với developer Use cases và khi nào chọn mỗi cách tiếp cận Dịch Vụ Container trên AWS Docker Fundamentals:\nLợi ích containerization và use cases Kiến trúc microservices với containers Tạo và tối ưu Docker image Multi-stage builds và best practices Amazon ECR (Elastic Container Registry):\nDocker container registry được quản lý đầy đủ Lưu trữ và versioning image Scanning image để tìm lỗ hổng Lifecycle policies cho cleanup tự động Tích hợp với ECS và EKS Amazon ECS (Elastic Container Service):\nContainer orchestration được quản lý đầy đủ Fargate (serverless) và EC2 launch types Task definitions và service configurations Auto-scaling và load balancing Service discovery và networking Amazon EKS (Elastic Kubernetes Service):\nDịch vụ Kubernetes được quản lý Kubernetes-native orchestration Quản lý worker nodes Add-ons và tích hợp ecosystem Multi-tenant và namespace isolation AWS App Runner:\nTriển khai container đơn giản Auto-scaling và load balancing tự động Triển khai source code hoặc container image Tích hợp CI/CD tích hợp sẵn Mô hình định giá pay-per-use Monitoring \u0026amp; Observability Amazon CloudWatch:\nMetrics: Metrics ứng dụng và hạ tầng Logs: Quản lý và phân tích log tập trung Alarms: Alerting và thông báo tự động Dashboards: Trực quan hóa tùy chỉnh metrics và logs Insights: Phát hiện bất thường tự động Composite Alarms: Logic cảnh báo phức tạp AWS X-Ray:\nDistributed tracing cho microservices Trực quan hóa luồng request Xác định bottleneck hiệu suất Tạo service map Tích hợp với Lambda, ECS, và API Gateway Phân tích và lọc trace Best Practices:\nThiết lập chiến lược alerting hiệu quả Tạo dashboards có ý nghĩa Quy trình on-call và incident response Tổng hợp và phân tích log Thu thập metrics và retention policies DevOps Best Practices Chiến Lược Deployment:\nFeature Flags: Rollout tính năng dần dần A/B Testing: So sánh các phiên bản khác nhau Canary Deployments: Giảm thiểu rủi ro thông qua rollout dần dần Blue/Green Deployments: Cập nhật zero-downtime Automated Testing:\nUnit, integration, và end-to-end testing Test automation trong CI/CD pipelines Quality gates và test coverage Performance và load testing Quản Lý Incident:\nTạo và bảo trì runbook Quy trình incident response Phân tích postmortem và học hỏi Quy trình cải thiện liên tục Những Gì Học Được Chuyển Đổi Văn Hóa DevOps Thay Đổi Văn Hóa Là Căn Bản: Chỉ công cụ không tạo ra DevOps—văn hóa và hợp tác là chìa khóa Đo Lường Những Gì Quan Trọng: Sử dụng DORA metrics để theo dõi mức độ trưởng thành DevOps Cải Thiện Liên Tục: DevOps là một hành trình, không phải đích đến Tự Động Hóa Trước Tiên: Tự động hóa các tác vụ lặp đi lặp lại để tập trung vào công việc có giá trị cao Best Practices CI/CD Bắt Đầu Đơn Giản, Mở Rộng Dần: Bắt đầu với pipeline cơ bản và thêm phức tạp theo thời gian Git Strategy Quan Trọng: Chọn GitFlow hoặc Trunk-based dựa trên kích thước team và nhịp độ release Testing Là Quan Trọng: Tích hợp automated testing ở mọi giai đoạn Chiến Lược Deployment: Sử dụng chiến lược deployment phù hợp dựa trên mức độ chấp nhận rủi ro Infrastructure as Code: Luôn sử dụng IaC cho hạ tầng có thể tái tạo và được version control Container Orchestration Chọn Thông Minh: ECS cho đơn giản, EKS cho ecosystem Kubernetes Bắt Đầu Với Serverless: Fargate loại bỏ overhead quản lý node Tối Ưu Images: Image nhỏ hơn có nghĩa là deployment nhanh hơn và chi phí thấp hơn Bảo Mật Trước Tiên: Scan images và sử dụng IAM policies least-privilege Chiến Lược Observability Triển Khai Full-Stack Observability: Metrics, logs, và traces cùng nhau Monitoring Chủ Động: Thiết lập alarms trước khi incident xảy ra Dashboards Có Ý Nghĩa: Tạo dashboards cung cấp insights có thể hành động Distributed Tracing: Cần thiết cho debug kiến trúc microservices Ứng Dụng Vào Công Việc Triển Khai CI/CD Pipelines: Thiết lập CodePipeline cho deployments tự động Áp Dụng Infrastructure as Code: Sử dụng CloudFormation hoặc CDK cho tất cả hạ tầng Containerize Applications: Bắt đầu containerize ứng dụng để portability tốt hơn Thiết Lập Monitoring: Triển khai CloudWatch và X-Ray cho observability Thiết Lập DevOps Practices: Tạo runbooks, quy trình incident response, và templates postmortem Đo Lường DevOps Metrics: Theo dõi DORA metrics để đo lường cải thiện Trải nghiệm trong event Tham gia workshop \u0026ldquo;DevOps on AWS\u0026rdquo; cả ngày là một trải nghiệm học tập chuyên sâu và toàn diện bao phủ toàn bộ phạm vi DevOps từ văn hóa đến triển khai. Sự kiện cung cấp cả kiến thức lý thuyết và trình diễn thực tế, giúp em hiểu hoàn chỉnh về triển khai DevOps practices trên AWS.\nHọc các nguyên tắc cơ bản DevOps Phiên bắt đầu với DevOps mindset và văn hóa, nhấn mạnh rằng DevOps không chỉ là công cụ—đó là về hợp tác và trách nhiệm chia sẻ. Em học về DORA metrics (Deployment Frequency, Lead Time, MTTR, Change Failure Rate) và cách đo lường mức độ trưởng thành DevOps. Hiểu lợi ích của DevOps giúp em thấy bức tranh lớn hơn ngoài triển khai kỹ thuật. Tìm hiểu sâu về AWS CI/CD pipeline Hướng dẫn CodeCommit, CodeBuild, CodeDeploy, và CodePipeline cho em thấy cách xây dựng CI/CD pipeline hoàn chỉnh. Học về các Git strategies khác nhau (GitFlow vs Trunk-based) giúp em hiểu khi nào sử dụng mỗi cách tiếp cận. Demo chiến lược deployment (Blue/Green, Canary, Rolling) rất mở mang tầm mắt, cho thấy cách giảm thiểu rủi ro và downtime. Demo CI/CD pipeline trực tiếp minh họa toàn bộ workflow từ code commit đến production deployment. Thành thạo Infrastructure as Code CloudFormation minh họa cách quản lý hạ tầng khai báo với templates. AWS CDK cho em thấy cách viết code hạ tầng bằng ngôn ngữ lập trình quen thuộc, làm cho nó dễ bảo trì hơn. So sánh giữa CloudFormation và CDK giúp em hiểu khi nào sử dụng mỗi công cụ. Học về drift detection và change sets cho em tự tin quản lý hạ tầng an toàn. Khám phá dịch vụ container Docker fundamentals làm mới hiểu biết của em về containerization và lợi ích của nó. Amazon ECR cho thấy cách quản lý container images an toàn với scanning và lifecycle policies. So sánh ECS và EKS giúp em hiểu trade-offs giữa dịch vụ được quản lý và tính linh hoạt Kubernetes. AWS App Runner giới thiệu cách triển khai container đơn giản hơn mà không cần quản lý hạ tầng. Case study triển khai microservices cung cấp insights thực tế về lựa chọn dịch vụ container phù hợp. Thiết lập monitoring và observability CloudWatch bao phủ toàn diện cho em thấy cách thu thập metrics, logs, và thiết lập alarms. AWS X-Ray distributed tracing minh họa cách debug kiến trúc microservices phức tạp. Demo full-stack observability cho thấy cách kết nối tất cả các phần monitoring lại với nhau. Học về best practices alerting và quy trình on-call cung cấp kiến thức vận hành thực tế. Best practices và case studies Chiến lược deployment như feature flags và A/B testing cho thấy kỹ thuật nâng cao cho deployments an toàn. Tích hợp automated testing minh họa cách xây dựng quality gates vào CI/CD pipelines. Quản lý incident practices và templates postmortem cung cấp cấu trúc cho xử lý các vấn đề production. Case studies từ startups và enterprises cho thấy chuyển đổi DevOps thực tế và bài học học được. Hướng dẫn nghề nghiệp và chứng chỉ Thảo luận con đường nghề nghiệp DevOps giúp em hiểu các vai trò và yêu cầu kỹ năng khác nhau. Lộ trình chứng chỉ AWS cung cấp hướng dẫn rõ ràng về các chứng chỉ liên quan đến DevOps. Hiểu sự tiến triển nghề nghiệp cho em lộ trình phát triển chuyên nghiệp. Trình diễn thực tế Mọi phiên đều bao gồm demo trực tiếp cho thấy triển khai thực tế, không chỉ slides. Hướng dẫn CI/CD pipeline đầy đủ minh họa tự động hóa end-to-end. Demo CloudFormation và CDK cho thấy cả hai cách tiếp cận quản lý hạ tầng. So sánh triển khai container giúp em hình dung các cách tiếp cận khác nhau cạnh nhau. Kết nối và thảo luận Định dạng cả ngày cho phép networking mở rộng với các DevOps practitioners khác. Phiên Q\u0026amp;A cung cấp cơ hội nhận câu trả lời cho các câu hỏi cụ thể. Thảo luận thách thức thực tế với đồng nghiệp giúp em hiểu các pitfalls và giải pháp phổ biến. Bài học rút ra DevOps là chuyển đổi văn hóa đòi hỏi sự đồng thuận từ cả team development và operations. Tự động hóa là cần thiết nhưng phải được triển khai cẩn thận để tránh tạo technical debt. Infrastructure as Code là không thể thương lượng cho DevOps practices hiện đại. Monitoring và observability là quan trọng cho duy trì hệ thống production. Bắt đầu đơn giản và lặp lại thay vì cố gắng triển khai mọi thứ cùng một lúc. Đo lường mọi thứ sử dụng DORA metrics để theo dõi cải thiện theo thời gian. Một số hình ảnh khi tham gia sự kiện Tổng thể, workshop cả ngày này cung cấp cho em kiến thức toàn diện về dịch vụ AWS DevOps và best practices. Sự kết hợp giữa nguyên tắc chuyển đổi văn hóa, trình diễn công cụ thực tế, và case studies thực tế cho em tự tin triển khai DevOps practices trong các dự án của em. Độ sâu và phạm vi nội dung bao phủ mọi thứ từ CI/CD pipelines đến container orchestration và observability, cung cấp nền tảng hoàn chỉnh cho xây dựng khả năng DevOps trên AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tổng quan Worklog này ghi lại hành trình của tôi trong chương trình thực tập AWS Cloud Journey, nơi tôi hoàn thành trải nghiệm học tập và dự án thực hành toàn diện trong 12 tuần. Chương trình được cấu trúc để xây dựng kiến thức từ các khái niệm AWS cơ bản đến triển khai một kiến trúc web application hoàn chỉnh, sẵn sàng cho production trên AWS.\nThời gian: 12 tuần (khoảng 3 tháng)\nNgày hoàn thành: Tháng 11 năm 2025\nDự án cuối cùng: AWS web application production-ready với CI/CD, monitoring, và security\nTiến độ theo tuần Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS - Giới thiệu về hệ sinh thái AWS, điều hướng console, và các dịch vụ cơ bản.\nTuần 2: Khám phá các dịch vụ AWS cơ bản - Đi sâu vào các dịch vụ AWS cốt lõi và use cases của chúng.\nTuần 3: Các khái niệm AWS nâng cao - Khám phá các tính năng nâng cao và tích hợp dịch vụ.\nTuần 4: Thực hành labs và bài tập - Các bài tập thực hành và phiên lab để củng cố kiến thức.\nTuần 5: Labs và workshops nâng cao - Các kịch bản phức tạp và tích hợp đa dịch vụ.\nTuần 6: Dịch vụ Database trên AWS - Amazon RDS, Aurora, Redshift, ElastiCache, và các công cụ migration database (DMS, SCT).\nTuần 7: Dịch vụ Analytics và Data Lake - Amazon DynamoDB, AWS Glue, Amazon Athena, Amazon QuickSight, và xây dựng data lakes trên AWS.\nTuần 8: Edge Layer và Frontend Infrastructure - Route 53, S3 static hosting, CloudFront CDN, AWS WAF, và thiết lập ACM Certificate.\nTuần 9: VPC và Networking Core - Tạo VPC, subnets, Internet Gateway, NAT Gateway, Security Groups, IAM roles, và VPC Flow Logs.\nTuần 10: Triển khai Backend và Database - Thiết lập EC2 backend, cấu hình RDS database, API Gateway, Cognito authentication, và Auto Scaling Group.\nTuần 11: CI/CD Pipeline và Monitoring - Tích hợp GitLab, CodePipeline, CodeBuild, SSH-less deployment, CloudWatch monitoring, CloudTrail, và SNS alerts.\nTuần 12: Hoàn thiện dự án và tài liệu - Kiểm tra cuối cùng, tài liệu, và bàn giao dự án.\nKhó khăn và Giải pháp Trong suốt 12 tuần của chương trình, tôi đã gặp phải nhiều thách thức kỹ thuật đòi hỏi giải quyết vấn đề và hiểu biết sâu hơn:\nKhó khăn 1: Cấu hình CloudFront Origin Access Control (OAC) Vấn đề: Ban đầu bị nhầm lẫn giữa Origin Access Identity (OAI) và Origin Access Control (OAC) mới hơn. Phương pháp OAI đã bị deprecated, và tôi cần sử dụng OAC cho truy cập S3 bucket.\nGiải pháp: Nghiên cứu tài liệu AWS và học được rằng OAC là phương pháp được khuyến nghị. Cập nhật S3 bucket policies để hoạt động với OAC và cấu hình CloudFront distribution tương ứng. Điều này yêu cầu hiểu sự khác biệt trong mô hình permissions giữa OAI và OAC.\nKhó khăn 2: Thiết lập API Gateway VPC Link cho Private Resources Vấn đề: Kết nối API Gateway với EC2 instances trong private subnet là thách thức. Ban đầu thử HTTP integration trực tiếp, nhưng private subnet resources không thể truy cập trực tiếp.\nGiải pháp: Triển khai API Gateway VPC Link để thiết lập kết nối giữa API Gateway và VPC. Điều này yêu cầu tạo Network Load Balancer (NLB) trong private subnet và cấu hình VPC Link trỏ đến NLB. Học được tầm quan trọng của VPC endpoints và các mẫu kết nối private.\nKhó khăn 3: Kết nối RDS từ EC2 trong Private Subnet Vấn đề: EC2 instance trong private subnet ban đầu không thể kết nối với RDS database. Security group rules không được cấu hình đúng, và tôi không sử dụng RDS endpoint chính xác.\nGiải pháp:\nXác minh Security Group rules: RDS Security Group phải cho phép inbound từ EC2 Security Group trên database port (3306/5432). Sử dụng AWS Secrets Manager để retrieve database credentials an toàn thay vì hardcode. Kiểm tra kết nối sử dụng AWS Systems Manager Session Manager để truy cập EC2 mà không cần SSH. Khó khăn 4: CodeBuild và CloudFront Cache Invalidation Vấn đề: Sau khi deploy frontend updates qua CodeBuild lên S3, các thay đổi không được phản ánh ngay lập tức do CloudFront caching. Manual cache invalidation tốn thời gian.\nGiải pháp: Tự động hóa CloudFront cache invalidation trong file buildspec.yml của CodeBuild. Thêm AWS CLI command để tạo invalidation sau khi upload S3, đảm bảo người dùng thấy nội dung cập nhật ngay sau deployment.\nKhó khăn 5: SSH-less Deployment cho Backend Vấn đề: Deployment dựa trên SSH truyền thống không an toàn và không hoạt động tốt với Auto Scaling Group (instances là ephemeral). Cần một cách tiếp cận tốt hơn cho automated backend deployments.\nGiải pháp: Triển khai SSH-less deployment sử dụng AWS Systems Manager (SSM) Run Command. Điều này cho phép CodeBuild thực thi deployment scripts trên EC2 instances mà không cần SSH keys. Cách tiếp cận thay thế sử dụng CodeDeploy cũng được khám phá cho các kịch bản deployment phức tạp hơn.\nKhó khăn 6: CloudWatch Alarms Không Kích Hoạt Vấn đề: Tạo CloudWatch alarms nhưng không nhận được notifications. Ban đầu, alarm threshold quá cao, và SNS topic subscriptions không được cấu hình đúng.\nGiải pháp:\nĐiều chỉnh alarm thresholds dựa trên metrics thực tế của application (CPU \u0026gt;80% trong 5 phút, RDS connections \u0026gt;80% của max). Xác minh SNS topic subscriptions (email confirmation là bắt buộc). Kiểm tra alarms bằng cách manually trigger conditions để đảm bảo notification flow hoạt động đúng. Khó khăn 7: Xác thực Cognito JWT Token trong API Gateway Vấn đề: Sau khi thiết lập Cognito User Pool và Authorizer trong API Gateway, các API calls với JWT tokens bị từ chối với lỗi 401 Unauthorized.\nGiải pháp:\nXác minh JWT token format và expiration. Kiểm tra Cognito User Pool App Client settings (allowed OAuth flows, callback URLs). Đảm bảo API Gateway Authorizer được cấu hình đúng với Cognito User Pool ARN. Kiểm tra token generation và validation flow từng bước. Khó khăn 8: Vấn đề Launch Template của Auto Scaling Group Vấn đề: Auto Scaling Group không thể launch instances. Launch Template tham chiếu đến AMI không có sẵn trong target Availability Zone.\nGiải pháp:\nTạo base AMI trong cùng region và Availability Zone với Auto Scaling Group. Xác minh cấu hình Launch Template (instance type, security groups, IAM role, user data). Kiểm tra Launch Template manually trước khi sử dụng trong Auto Scaling Group. Đảm bảo tất cả resources cần thiết (Security Groups, IAM roles) tồn tại trước khi tạo ASG. Khó khăn 9: Tối ưu hóa Chi phí VPC Flow Logs Vấn đề: VPC Flow Logs tạo ra lượng dữ liệu lớn, dẫn đến chi phí CloudWatch Logs cao.\nGiải pháp:\nCấu hình log retention policies (7 ngày cho detailed logs, 30 ngày cho aggregated logs). Sử dụng S3 làm destination cho long-term log storage (hiệu quả về chi phí hơn CloudWatch Logs). Triển khai log filtering để capture chỉ các traffic patterns liên quan. Thiết lập lifecycle policies trên S3 để chuyển logs sang storage classes rẻ hơn. Khó khăn 10: Độ phức tạp của End-to-End Testing Vấn đề: Kiểm tra luồng hoàn chỉnh từ Route 53 → CloudFront → WAF → API Gateway → EC2 → RDS là phức tạp, và các vấn đề khó cô lập.\nGiải pháp:\nTriển khai comprehensive logging ở mỗi layer (CloudFront access logs, API Gateway logs, EC2 application logs, RDS slow query logs). Sử dụng CloudWatch dashboards để visualize toàn bộ request flow. Tạo test scripts để validate từng component độc lập trước khi end-to-end testing. Tài liệu hóa troubleshooting procedures cho các vấn đề phổ biến ở mỗi layer. Những bài học quan trọng Infrastructure as Code (IaC): Học được tầm quan trọng của việc sử dụng CloudFormation cho reproducible infrastructure deployments.\nSecurity Best Practices: Triển khai least-privilege IAM policies, network segmentation, và secure credential management với Secrets Manager.\nMonitoring và Observability: Thiết lập monitoring toàn diện với CloudWatch, CloudTrail, và VPC Flow Logs cho security và performance insights.\nCI/CD Automation: Automated deployment pipelines giảm lỗi thủ công và cải thiện tốc độ deployment.\nCost Optimization: Học cách cân bằng performance, security, và chi phí thông qua proper resource sizing, caching strategies, và log retention policies.\nKết luận Hành trình 12 tuần này cung cấp kinh nghiệm thực hành với nhiều AWS services và best practices. Dự án cuối cùng thể hiện một kiến trúc production-ready với security, monitoring, automation, và scalability phù hợp. Các thách thức gặp phải và giải quyết trong giai đoạn này đã tăng cường đáng kể hiểu biết của tôi về cloud architecture và AWS services.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Hiểu rõ khái niệm và cấu trúc của VPC (CIDR, Subnet, Route Table, ENI). Nắm được cách cấu hình tường lửa trong VPC (NACL, Security Group). Làm quen với các dịch vụ kết nối mạng: VPN, Direct Connect. Tìm hiểu và thực hành Load Balancer. Triển khai thực hành các thành phần cơ bản: VPC, Subnet, Route Table, IGW, EBS, Elastic IP. Biết cách kết nối và remote vào EC2 bằng SSH. Làm quen với Hybrid DNS bằng Route 53 Resolver. Thực hành kết nối nhiều VPC với nhau bằng VPC Peering. Triển khai AWS Transit Gateway để quản lý kết nối giữa nhiều VPC. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học lý thuyết\n- Thế nào là VPC, cách tối ưu hóa thuê các dịch vụ cloud 15/09/2025 15/09/2025 AWS VPC Documentation 3 - Tìm hiểu về VPC\n+ Subnet, CIDR + Route table + ENI (Elastic Network Interface) 16/09/2025 16/09/2025 YouTube - AWS VPC 4 - Cấu hình tường lửa VPC: NACL, Security Group\n- VPN, Direct Connect\n- Load Balancer\n- Extra Resources 17/09/2025 17/09/2025 YouTube - AWS Security 5 - Thực hành: + VPC + Subnet\n+ Route Table\n+ IGW\n+ EBS\n+ \u0026hellip;\n- Các cách remote SSH vào EC2\n- Tìm hiểu Elastic IP 18/09/2025 18/09/2025 AWS Study Group - 000003 6 - Thực hành: + Set up Hybrid DNS với Route 53 Resolver 19/09/2025 19/09/2025 AWS Study Group - 000010 7 - Thực hành: + Set up VPC Peering 19/09/2025 19/09/2025 AWS Study Group - 000019 8 - Thực hành: + Set up AWS Transit Gateway 19/09/2025 19/09/2025 AWS Study Group - 000020 Kết quả đạt được tuần 2: Hiểu rõ kiến trúc Amazon VPC, cách các thành phần như Subnet, CIDR, Route Table và ENI kết hợp với nhau để tạo nên một mạng bảo mật và có khả năng mở rộng. Biết cách thiết kế và áp dụng chính sách bảo mật mạng thông qua Security Group và Network ACL, nắm được tình huống thực tế khi nên dùng từng loại. Tìm hiểu các dịch vụ mạng của AWS như VPN và Direct Connect, từ đó nắm được giải pháp kết nối hybrid cloud trong môi trường doanh nghiệp. Thực hành triển khai các thành phần cốt lõi: tạo VPC, Subnet, cấu hình Route Table, Internet Gateway, gắn EBS và cấp phát Elastic IP. Củng cố kỹ năng thao tác với EC2 thông qua SSH, hiểu rõ hơn về key pair và quản lý truy cập an toàn. Thực hành các kịch bản nâng cao như Hybrid DNS với Route 53 Resolver để mở rộng khả năng phân giải tên trong môi trường hybrid. Thiết lập kết nối giữa các VPC thông qua VPC Peering và kiểm thử giao tiếp giữa tài nguyên thuộc các mạng khác nhau. Triển khai AWS Transit Gateway để tập trung và đơn giản hóa quản lý kết nối mạng nhiều VPC, củng cố kiến thức về kiến trúc mạng có khả năng mở rộng. Kết luận: Sau tuần 2, tôi không chỉ nắm vững lý thuyết về VPC và các dịch vụ mạng mà còn có nhiều trải nghiệm thực hành, đủ tự tin thiết kế và quản lý hạ tầng mạng trên AWS.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console Chọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo Đi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box Click vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes. Click Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: 📝 Note\nBạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này. Trong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":"Bài thu hoạch \u0026ldquo;Kick-off AWS First Cloud Journey Workforce OJT FALL 2025\u0026rdquo; Mục Đích Của Sự Kiện Chào mừng và khai mạc chương trình AWS First Cloud Journey Workforce OJT FALL 2025 Giới thiệu về chương trình và định hướng tương lai trong lĩnh vực Cloud Computing Chia sẻ kinh nghiệm từ các alumni và chuyên gia trong ngành Kết nối sinh viên với cộng đồng AWS và các doanh nghiệp đối tác Truyền cảm hứng và động lực cho hành trình học tập và phát triển sự nghiệp Chi Tiết Sự Kiện Ngày: Thứ Bảy, 06 tháng 9 năm 2025 Thời gian: 8:30 – 12:00 Địa điểm: Tầng 26, Tòa nhà Bitexco Financial Tower, số 2 Hải Triều, P. Bến Nghé, Quận 1, TP.HCM Thời lượng: 3.5 giờ (bao gồm tea break và networking) Về Chương trình AWS First Cloud Journey Workforce Khởi động từ năm 2021, chương trình đã đồng hành cùng hơn 2,000 sinh viên trên khắp cả nước.\nHơn 150 học viên đã được đào tạo chuyên sâu và hiện đang làm việc tại các công ty công nghệ hàng đầu Việt Nam và quốc tế.\nMục tiêu chính:\nXây dựng thế hệ AWS Builders chất lượng cao cho Việt Nam Trang bị kỹ năng thực chiến về Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics Kết nối sinh viên với cộng đồng AWS Study Group 47,000+ thành viên và các doanh nghiệp đối tác AWS Chương trình không chỉ là đào tạo công nghệ, mà còn là cầu nối quan trọng giữa tri thức – công nghệ – sự nghiệp, giúp sinh viên tự tin hòa nhập vào thế giới công nghệ hiện đại và hội nhập quốc tế.\nChương Trình 8:30 – 9:00 | Đón tiếp \u0026amp; Check-in Networking \u0026amp; chụp hình lưu niệm Đăng ký và nhận tài liệu Gặp gỡ các bạn sinh viên cùng khóa 9:00 – 9:15 | Khai mạc \u0026amp; Chào mừng Đại diện Nhà trường: Thầy Nguyễn Trần Phước Bảo – Trưởng phòng Quan hệ Doanh nghiệp (QHDN)\nPhát biểu khai mạc chương trình Giới thiệu về AWS First Cloud Journey Workforce Định hướng và kỳ vọng cho khóa học Tham dự cùng 2–3 anh/chị thuộc Phòng QHDN Keynote \u0026amp; Industry Sharing 9:15 – 9:40 | AWS First Cloud Journey \u0026amp; Định hướng Tương lai (25 phút) Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam\nGiới thiệu về AWS First Cloud Journey Tầm nhìn và định hướng tương lai của chương trình Cơ hội nghề nghiệp trong lĩnh vực Cloud Computing Lộ trình phát triển sự nghiệp với AWS Q\u0026amp;A 9:40 – 10:05 | DevOps \u0026amp; Sự nghiệp tương lai (25 phút) Đỗ Huy Thắng – DevOps Lead, VNG\nDevOps là gì và tại sao quan trọng Sự nghiệp trong lĩnh vực DevOps Kỹ năng cần thiết và cách phát triển Kinh nghiệm thực tế từ VNG Q\u0026amp;A 10:05 – 10:20 | Tea Break \u0026amp; Networking (15 phút) Nghỉ giải lao Networking với các speakers và participants Chụp ảnh lưu niệm Alumni \u0026amp; Career Sharing 10:20 – 10:40 | Từ First Cloud Journey đến GenAI Engineer (20 phút) Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova\nHành trình từ First Cloud Journey đến GenAI Engineer Kinh nghiệm học tập và phát triển Cơ hội trong lĩnh vực AI/ML Lời khuyên cho các bạn sinh viên mới Q\u0026amp;A 10:40 – 11:00 | She in Tech \u0026amp; Hành trình cùng First Cloud Journey (20 phút) Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne\nHành trình của phụ nữ trong công nghệ Kinh nghiệm tham gia First Cloud Journey Thách thức và cơ hội Lời khuyên cho các bạn nữ muốn theo đuổi sự nghiệp tech Q\u0026amp;A 11:00 – 11:20 | Một ngày làm Cloud Engineer (20 phút) Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific\nMột ngày làm việc của Cloud Engineer Công việc thực tế và trách nhiệm Kỹ năng và công cụ sử dụng hàng ngày Challenges và cách giải quyết Q\u0026amp;A 11:20 – 11:40 | Hành trình đến với First Cloud Journey (20 phút) Nguyễn Đồng Thanh Hiệp – Principal Cloud Engineer, G-Asia Pacific\nHành trình cá nhân đến với First Cloud Journey Bài học và kinh nghiệm quý giá Lộ trình phát triển từ junior đến principal engineer Lời khuyên cho các bạn mới bắt đầu Q\u0026amp;A 11:40 – 12:00 | Q\u0026amp;A \u0026amp; Tổng kết (20 phút) Giải đáp thắc mắc từ speakers \u0026amp; mentors Tổng kết nội dung chính của sự kiện Thông tin về các bước tiếp theo trong chương trình Chụp ảnh lưu niệm 📸 Meet Our Speakers Nguyễn Gia Hưng Head of Solutions Architect, AWS Vietnam\nChuyên gia hàng đầu về AWS architecture và solutions Kinh nghiệm sâu rộng trong việc tư vấn và triển khai giải pháp cloud Người dẫn dắt chương trình AWS First Cloud Journey tại Việt Nam Đỗ Huy Thắng DevOps Lead, VNG\nChuyên gia về DevOps practices và automation Kinh nghiệm trong việc xây dựng và vận hành hệ thống quy mô lớn Mentor cho nhiều thế hệ DevOps engineers Danh Hoàng Hiếu Nghị GenAI Engineer, Renova\nAlumni của chương trình First Cloud Journey Chuyên gia về Generative AI và Machine Learning Kinh nghiệm trong việc phát triển AI solutions Bùi Hồ Linh Nhi AI Engineer, SoftwareOne\nAlumni của chương trình First Cloud Journey Chuyên gia về AI/ML engineering Người truyền cảm hứng cho phụ nữ trong công nghệ Phạm Nguyễn Hải Anh Cloud Engineer, G-Asia Pacific\nChuyên gia về cloud infrastructure và operations Kinh nghiệm thực tế trong việc quản lý và vận hành cloud systems Mentor cho các cloud engineers mới vào nghề Nguyễn Đồng Thanh Hiệp Principal Cloud Engineer, G-Asia Pacific\nAlumni của chương trình First Cloud Journey Chuyên gia về cloud architecture và best practices Kinh nghiệm từ junior đến principal level Nội Dung Nổi Bật AWS First Cloud Journey Program Giới thiệu chương trình:\nChương trình đào tạo thực hành (OJT) về AWS Cloud Computing Đã đồng hành cùng hơn 2,000 sinh viên từ năm 2021 Hơn 150 học viên đã được đào tạo chuyên sâu và làm việc tại các công ty hàng đầu Mục tiêu:\nXây dựng thế hệ AWS Builders chất lượng cao Trang bị kỹ năng thực chiến về Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics Kết nối với cộng đồng AWS Study Group 47,000+ thành viên Lợi ích:\nĐào tạo chuyên sâu với các chuyên gia AWS Cơ hội thực hành với môi trường AWS thực tế Kết nối với các doanh nghiệp đối tác Hỗ trợ phát triển sự nghiệp Career Pathways in Cloud Computing DevOps Career:\nDevOps là gì và vai trò trong tổ chức Kỹ năng cần thiết: CI/CD, Infrastructure as Code, Monitoring Lộ trình phát triển: Junior → Mid → Senior → Lead Cơ hội nghề nghiệp và mức lương Cloud Engineer Career:\nCông việc hàng ngày của Cloud Engineer Kỹ năng technical và soft skills Challenges và cách giải quyết Growth opportunities AI/ML Engineer Career:\nTừ Cloud Engineer đến AI/ML Engineer Kỹ năng cần thiết cho AI/ML Cơ hội trong lĩnh vực Generative AI Future trends và opportunities Alumni Success Stories Từ First Cloud Journey đến thành công:\nHành trình của các alumni Bài học và kinh nghiệm quý giá Challenges và cách vượt qua Lời khuyên cho các bạn mới Diversity in Tech:\nHành trình của phụ nữ trong công nghệ Thách thức và cơ hội Support và resources available Inspiration và motivation Những Gì Học Được Hiểu về AWS First Cloud Journey Chương trình là gì: OJT program về AWS Cloud Computing Mục tiêu và lợi ích: Xây dựng kỹ năng thực chiến và kết nối với cộng đồng Lộ trình học tập: Các giai đoạn và milestones trong chương trình Cơ hội nghề nghiệp: Kết nối với các doanh nghiệp đối tác Career Pathways DevOps: Hiểu về sự nghiệp DevOps và kỹ năng cần thiết Cloud Engineer: Công việc thực tế và trách nhiệm AI/ML Engineer: Lộ trình phát triển trong lĩnh vực AI/ML Career progression: Từ junior đến senior và principal level Real-world Insights Alumni experiences: Hành trình và bài học từ các alumni Day-to-day work: Công việc thực tế của các roles khác nhau Challenges: Thách thức và cách giải quyết Best practices: Lời khuyên và tips từ experts Networking and Community AWS Study Group: Cộng đồng 47,000+ thành viên Mentorship: Cơ hội được mentor từ các chuyên gia Peer learning: Học hỏi từ các bạn cùng khóa Industry connections: Kết nối với các doanh nghiệp Ứng Dụng Vào Công Việc Đặt mục tiêu rõ ràng: Xác định career path muốn theo đuổi Xây dựng kỹ năng: Focus vào các kỹ năng cần thiết cho career path đã chọn Thực hành thường xuyên: Tận dụng môi trường AWS để practice Kết nối và networking: Tham gia cộng đồng và kết nối với mentors Học từ alumni: Áp dụng lessons learned từ các alumni thành công Phát triển soft skills: Không chỉ technical skills mà còn communication, teamwork Trải nghiệm trong event Tham gia sự kiện Kick-off AWS First Cloud Journey Workforce OJT FALL 2025 là một trải nghiệm đầy cảm hứng và động lực. Sự kiện không chỉ cung cấp thông tin về chương trình mà còn truyền cảm hứng cho hành trình học tập và phát triển sự nghiệp trong lĩnh vực Cloud Computing.\nKhai mạc và chào mừng Phát biểu khai mạc của Thầy Nguyễn Trần Phước Bảo tạo không khí trang trọng và chuyên nghiệp. Em hiểu rõ về mục tiêu và kỳ vọng của chương trình. Giới thiệu về First Cloud Journey giúp em hình dung rõ về hành trình sắp tới. Keynote từ AWS Session của Nguyễn Gia Hưng cung cấp tầm nhìn tổng thể về AWS First Cloud Journey. Hiểu về định hướng tương lai và cơ hội nghề nghiệp trong Cloud Computing. Lộ trình phát triển sự nghiệp cho em roadmap rõ ràng để follow. Industry Insights DevOps session của Đỗ Huy Thắng cho em hiểu về sự nghiệp DevOps. Học về kỹ năng cần thiết và cách phát triển trong lĩnh vực này. Real-world examples từ VNG giúp em hình dung công việc thực tế. Alumni Success Stories Hành trình của Danh Hoàng Hiếu Nghị từ First Cloud Journey đến GenAI Engineer rất inspiring. Em học được về persistence và continuous learning. Session của Bùi Hồ Linh Nhi về She in Tech rất empowering. Hiểu về challenges và opportunities cho phụ nữ trong tech. Day-to-day Work Insights Session của Phạm Nguyễn Hải Anh về một ngày làm Cloud Engineer rất practical. Em hiểu về công việc thực tế và trách nhiệm của Cloud Engineer. Hành trình của Nguyễn Đồng Thanh Hiệp từ junior đến principal rất motivating. Học được về career progression và growth mindset. Networking và kết nối Networking sessions cho phép em kết nối với các speakers và participants. Chia sẻ experiences và learnings với các bạn cùng khóa. Q\u0026amp;A sessions cung cấp cơ hội để hỏi specific questions. Gặp gỡ các alumni và nhận advice về career development. Bài học rút ra First Cloud Journey là cơ hội tuyệt vời: Chương trình cung cấp foundation vững chắc cho sự nghiệp cloud. Career paths đa dạng: Có nhiều con đường phát triển trong cloud computing. Continuous learning là key: Cần học hỏi liên tục để phát triển. Networking matters: Kết nối với cộng đồng và mentors rất quan trọng. Diversity và inclusion: Tech industry đang trở nên inclusive hơn. Set clear goals: Cần có mục tiêu rõ ràng và plan để achieve. Một số hình ảnh khi tham gia sự kiện Tổng thể, sự kiện Kick-off này là một khởi đầu tuyệt vời cho hành trình AWS First Cloud Journey. Sự kết hợp giữa thông tin về chương trình, career insights, và alumni success stories cho em động lực và định hướng rõ ràng. Đặc biệt, networking với các speakers, alumni, và participants cung cấp connections và support có giá trị cho hành trình học tập và phát triển sự nghiệp của em trong lĩnh vực Cloud Computing.\nLời kết Sự kiện Kick-off hôm nay chính là bước khởi đầu cho hành trình AWS Builders – nơi các bạn sinh viên không chỉ tiếp cận công nghệ điện toán đám mây tiên tiến nhất, mà còn được truyền cảm hứng, kết nối cùng chuyên gia và mở rộng cơ hội nghề nghiệp.\nMột lần nữa, xin chúc mừng các bạn sinh viên đã chính thức trở thành một phần của AWS First Cloud Journey Workforce OJT FALL 2025. Hãy cùng nhau khởi động hành trình mới – hành trình của sự học hỏi, xây dựng và phát triển, để đưa công nghệ điện toán đám mây tại Việt Nam vươn xa! 🚀\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Tại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nIoT Weather Platform for Lab Research Giải pháp AWS Serverless hợp nhất cho giám sát thời tiết thời gian thực 1. Tóm tắt điều hành IoT Weather Platform được thiết kế dành cho nhóm ITea Lab tại TP. Hồ Chí Minh nhằm nâng cao khả năng thu thập và phân tích dữ liệu thời tiết. Nền tảng hỗ trợ tối đa 5 trạm thời tiết, có khả năng mở rộng lên 10–15 trạm, sử dụng thiết bị biên Raspberry Pi kết hợp cảm biến ESP32 để truyền dữ liệu qua MQTT. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian thực, phân tích dự đoán và tiết kiệm chi phí, với quyền truy cập giới hạn cho 5 thành viên phòng lab thông qua Amazon Cognito.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trạm thời tiết hiện tại yêu cầu thu thập dữ liệu thủ công, khó quản lý khi có nhiều trạm. Không có hệ thống tập trung cho dữ liệu hoặc phân tích thời gian thực, và các nền tảng bên thứ ba thường tốn kém và quá phức tạp.\nGiải pháp\nNền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT, AWS Lambda và API Gateway để xử lý, Amazon S3 để lưu trữ (bao gồm data lake), và AWS Glue Crawlers cùng các tác vụ ETL để trích xuất, chuyển đổi, tải dữ liệu từ S3 data lake sang một S3 bucket khác để phân tích. AWS Amplify với Next.js cung cấp giao diện web, và Amazon Cognito đảm bảo quyền truy cập an toàn. Tương tự như Thingsboard và CoreIoT, người dùng có thể đăng ký thiết bị mới và quản lý kết nối, nhưng nền tảng này hoạt động ở quy mô nhỏ hơn và phục vụ mục đích sử dụng nội bộ. Các tính năng chính bao gồm bảng điều khiển thời gian thực, phân tích xu hướng và chi phí vận hành thấp.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp tạo nền tảng cơ bản để các thành viên phòng lab phát triển một nền tảng IoT lớn hơn, đồng thời cung cấp nguồn dữ liệu cho những người nghiên cứu AI phục vụ huấn luyện mô hình hoặc phân tích. Nền tảng giảm bớt báo cáo thủ công cho từng trạm thông qua hệ thống tập trung, đơn giản hóa quản lý và bảo trì, đồng thời cải thiện độ tin cậy dữ liệu. Chi phí hàng tháng ước tính 0,66 USD (theo AWS Pricing Calculator), tổng cộng 7,92 USD cho 12 tháng. Tất cả thiết bị IoT đã được trang bị từ hệ thống trạm thời tiết hiện tại, không phát sinh chi phí phát triển thêm. Thời gian hoàn vốn 6–12 tháng nhờ tiết kiệm đáng kể thời gian thao tác thủ công.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH. First cloud journey Lab để hiểu sâu hơn về Session manager. Trong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. ℹ️ Info\nPhiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe). Session Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint. Trong Create endpoint console: Đặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. ⚠️ Warning\nĐảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo; Mở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Thực nghiệm ML nhanh cho doanh nghiệp với Amazon SageMaker AI và Comet Blog này giới thiệu cách tích hợp Amazon SageMaker AI với Comet để tăng tốc thực nghiệm machine learning cho doanh nghiệp. Bạn sẽ học cách quản lý các thực nghiệm ML, theo dõi dòng kế thừa mô hình (model lineage), và đảm bảo khả năng tái tạo kết quả (reproducibility) trong môi trường sản xuất. Bài viết minh họa một workflow phát hiện gian lận (fraud detection) hoàn chỉnh sử dụng SageMaker AI + Comet, thể hiện việc theo dõi thực nghiệm, so sánh mô hình, và logging sẵn sàng audit mà các doanh nghiệp hiện đại yêu cầu. Bài viết bao gồm cả hành trình của administrator và user, từ việc thiết lập Comet Partner AI App đến chạy các thực nghiệm và so sánh kết quả trong Comet UI.\nBlog 2 - Sử dụng workflow Apache Airflow để điều phối xử lý dữ liệu trên Amazon SageMaker Unified Studio Blog này minh họa cách sử dụng workflow Apache Airflow để điều phối các pipeline xử lý dữ liệu trên Amazon SageMaker Unified Studio. Bạn sẽ học cách xây dựng, kiểm thử và chạy các pipeline ML end-to-end sử dụng workflow của SageMaker thông qua giao diện Unified Studio. Bài viết đi qua một ví dụ thực tế bao gồm việc ingest dữ liệu thời tiết và taxi, chuyển đổi và gộp các dataset, sau đó sử dụng ML để dự đoán giá cước taxi - tất cả được điều phối thông qua workflow của SageMaker Unified Studio được hỗ trợ bởi Amazon Managed Workflows for Apache Airflow (Amazon MWAA). Bài viết tập trung vào cách tiếp cận dựa trên code sử dụng Python DAGs để quản lý workflow.\nBlog 3 - Di chuyển tìm kiếm toàn văn từ SQL Server sang Amazon Aurora PostgreSQL-Compatible Edition hoặc Amazon RDS for PostgreSQL Blog này hướng dẫn bạn cách di chuyển tìm kiếm toàn văn (full-text search) từ SQL Server sang Amazon Aurora PostgreSQL hoặc Amazon RDS for PostgreSQL. Bạn sẽ học cách di chuyển các truy vấn FTS và cấu trúc schema, vì cách triển khai khác nhau giữa hai hệ thống. Bài viết minh họa cách sử dụng các kiểu dữ liệu tsvector và tsquery của PostgreSQL để đạt được chức năng FTS tương tự, và cũng chỉ cách triển khai FTS bằng các extension pg_trgm và pg_bigm. Bài viết bao gồm các trường hợp sử dụng khác nhau như vị ngữ CONTAINS, truy vấn FREETEXT, xếp hạng với RANK, và các kỹ thuật tối ưu hiệu suất sử dụng chỉ mục GIN và các cột được tạo đã lưu trữ.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints. Click tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau. Kết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm Click Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $ Đi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file tên testfile2.xyz fallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong thời gian thực tập, em đã tham gia sáu sự kiện. Mỗi sự kiện đều là một trải nghiệm đáng nhớ, cung cấp kiến thức mới, thú vị và hữu ích, cùng với quà tặng và những khoảnh khắc tuyệt vời.\nEvent 1 Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Văn phòng AWS Vietnam\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học được về hệ sinh thái AWS AI/ML đầy đủ, từ Amazon SageMaker cho ML truyền thống đến Amazon Bedrock cho Generative AI. Em có được hiểu biết sâu sắc về kỹ thuật prompt engineering như Chain-of-Thought reasoning và Few-shot learning. Em cũng học về kiến trúc RAG (Retrieval-Augmented Generation) và cách nó quan trọng để xây dựng ứng dụng GenAI chính xác. Tầm quan trọng của guardrails cho an toàn AI và lọc nội dung trong ứng dụng sản xuất cũng được nhấn mạnh. Kỹ năng mới: Em phát triển kỹ năng sử dụng Amazon SageMaker Studio cho phát triển và triển khai mô hình ML. Em học cách triển khai kiến trúc RAG cho tích hợp knowledge base. Em có được kiến thức thực tế về prompt engineering và cách xây dựng Bedrock Agents cho multi-step workflows. Em cũng học về các foundation models khác nhau (Claude, Llama, Titan) và khi nào sử dụng từng loại. Đóng góp cho nhóm/dự án: Em chia sẻ ghi chú toàn diện về khả năng SageMaker và tính năng Bedrock với nhóm. Em xác định cơ hội triển khai giải pháp RAG cho ứng dụng domain-specific của chúng em. Em đề xuất dự án thí điểm sử dụng Bedrock Agents cho tự động hóa dịch vụ khách hàng. Em cũng tạo hướng dẫn cho best practices prompt engineering và triển khai guardrail cho các dự án GenAI của chúng em. Event 2 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: AWS Event Hall, Tầng 26, Tòa nhà Bitexco, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em có được hiểu biết sâu sắc về cách generative AI đang thay đổi phát triển phần mềm. Sự kiện cho em thấy cách AI có thể giúp ích trong toàn bộ vòng đời phát triển, từ lập kế hoạch đến bảo trì. Em học được rằng mặc dù công cụ AI rất mạnh mẽ, nhưng phán đoán của con người vẫn rất quan trọng. Em cũng hiểu rằng chúng ta nên áp dụng công cụ AI dần dần và đảm bảo toàn bộ nhóm đồng nhất. Kỹ năng mới: Em học cách sử dụng Amazon Q Developer cho tạo mã, gỡ lỗi, và tài liệu hóa. Em cũng khám phá Kiro và phát hiện cách nó có thể nâng cao năng suất của em. Em phát triển kỹ năng xác định tác vụ nào có thể hưởng lợi từ tự động hóa AI và học cách cân bằng hỗ trợ AI với xem xét của con người để duy trì chất lượng mã. Đóng góp cho nhóm/dự án: Em đã tài liệu hóa những điểm chính từ sự kiện và chia sẻ với nhóm. Em xác định các dự án cụ thể nơi chúng em có thể pilot công cụ AI, điều này có thể cải thiện tốc độ phát triển của chúng em lên 20-30% cho các tác vụ lặp đi lặp lại. Em tạo ra các hướng dẫn để sử dụng công cụ AI trong workflow của nhóm và lập kế hoạch tổ chức các phiên đào tạo nội bộ. Kiến thức em có được giúp nhóm chúng em duy trì tính cạnh tranh bằng cách sử dụng các công cụ phát triển AI tiên tiến. Event 3 Tên sự kiện: DevOps on AWS\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tòa nhà Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về văn hóa và nguyên tắc DevOps, bao gồm DORA metrics (Deployment Frequency, Lead Time, MTTR, Change Failure Rate) để đo lường mức độ trưởng thành DevOps. Em có được hiểu biết sâu sắc về dịch vụ AWS CI/CD (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) và các chiến lược deployment khác nhau (Blue/Green, Canary, Rolling). Em cũng học về Infrastructure as Code với CloudFormation và CDK, và khi nào sử dụng mỗi cách tiếp cận. Kỹ năng mới: Em phát triển kỹ năng xây dựng CI/CD pipeline hoàn chỉnh sử dụng dịch vụ AWS DevOps. Em học cách triển khai Infrastructure as Code với cả CloudFormation và CDK. Em có được kiến thức thực tế về dịch vụ container (ECR, ECS, EKS, App Runner) và khi nào sử dụng từng loại. Em cũng học cách thiết lập monitoring và observability sử dụng CloudWatch và X-Ray. Đóng góp cho nhóm/dự án: Em chia sẻ ghi chú toàn diện về dịch vụ AWS DevOps và best practices với nhóm. Em đề xuất triển khai CI/CD pipelines sử dụng CodePipeline cho deployments tự động. Em đề xuất áp dụng Infrastructure as Code cho tất cả hạ tầng của chúng em sử dụng CloudFormation hoặc CDK. Em cũng tạo hướng dẫn cho chiến lược containerization và best practices monitoring. Kiến thức có được giúp nhóm chúng em triển khai DevOps practices hiện đại và cải thiện tần suất deployment và độ tin cậy. Event 4 Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: AWS Vietnam Office, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về AWS Well-Architected Framework Security Pillar và năm pillars cốt lõi: Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection, và Incident Response. Em có được hiểu biết sâu sắc về các nguyên tắc bảo mật cốt lõi bao gồm Least Privilege, Zero Trust, và Defense in Depth. Em cũng học về Shared Responsibility Model và các mối đe dọa bảo mật hàng đầu trong môi trường cloud tại Việt Nam. Tầm quan trọng của việc xây dựng bảo mật vào kiến trúc ngay từ đầu, không phải như một add-on sau, được nhấn mạnh. Kỹ năng mới: Em phát triển kỹ năng trong kiến trúc IAM hiện đại sử dụng IAM Identity Center, Service Control Policies, và permission boundaries. Em học cách triển khai detection và monitoring toàn diện sử dụng CloudTrail, GuardDuty, và Security Hub. Em có được kiến thức thực tế về bảo mật mạng với VPC segmentation, Security Groups, NACLs, WAF, và Shield. Em cũng học về mã hóa at rest và in transit, quản lý khóa KMS, và quản lý secrets với Secrets Manager và Parameter Store. Đóng góp cho nhóm/dự án: Em chia sẻ best practices bảo mật toàn diện và framework năm pillars với nhóm. Em đề xuất triển khai các patterns IAM hiện đại với IAM Identity Center cho SSO. Em đề xuất thiết lập monitoring toàn diện sử dụng CloudTrail, GuardDuty, và Security Hub. Em tạo incident response playbooks cho các scenarios phổ biến như compromised IAM keys, S3 public exposure, và EC2 malware detection. Em cũng phát triển hướng dẫn cho chiến lược mã hóa và quản lý secrets. Kiến thức có được giúp nhóm chúng em xây dựng kiến trúc cloud an toàn theo AWS Well-Architected best practices. Event 5 Tên sự kiện: Building Agentic AI: Context Optimization with Amazon Bedrock\nThời gian: 09:00 ngày 05/12/2025\nĐịa điểm: Tầng 26, Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về Building Agentic AI và Context Optimization với Amazon Bedrock. Em có được hiểu biết sâu sắc về cách xây dựng autonomous AI agents với Amazon Bedrock thông qua hands-on techniques. Em học về agentic orchestration patterns và context optimization techniques nâng cao. Em cũng hiểu về tầm quan trọng của context optimization trong việc giảm costs và improve performance. Workshop nhấn mạnh rằng agentic AI là tương lai của AI applications và context optimization là key để scale effectively. Kỹ năng mới: Em phát triển kỹ năng xây dựng Bedrock Agents từ đầu với guidance từ experts. Em học về context optimization techniques như compression, summarization, và relevant information extraction. Em có được kiến thức thực tế về agentic orchestration patterns và cách coordinate nhiều agents. Em cũng học về CloudThinker platform và cách nó simplify việc xây dựng agentic systems. Hands-on workshop cho em cơ hội practice với real AWS environments. Đóng góp cho nhóm/dự án: Em chia sẻ comprehensive notes về Building Agentic AI và Context Optimization với nhóm. Em đề xuất pilot projects sử dụng Bedrock Agents cho automation tasks. Em tạo guidelines cho context optimization best practices để reduce costs và improve performance. Em cũng document CloudThinker platform capabilities và integration patterns. Kiến thức có được giúp nhóm chúng em explore agentic AI solutions và optimize costs trong AI/ML projects. Event 6 Tên sự kiện: Kick-off AWS First Cloud Journey Workforce OJT FALL 2025\nThời gian: 08:30 ngày 06/09/2025\nĐịa điểm: Tầng 26, Bitexco Financial Tower, 2 Hải Triều, P. Bến Nghé, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nKết quả hoặc giá trị đạt được:\nBài học rút ra: Em học về chương trình AWS First Cloud Journey Workforce, đã đào tạo hơn 2,000 sinh viên từ năm 2021, với hơn 150 học viên đang làm việc tại các công ty công nghệ hàng đầu. Em có được insights về các career pathways khác nhau trong cloud computing bao gồm DevOps, Cloud Engineer, và AI/ML Engineer roles. Em học về tầm quan trọng của continuous learning, networking, và setting clear career goals. Sự kiện nhấn mạnh rằng cloud computing offers diverse career paths và security, DevOps, và AI/ML đều là các hướng viable và rewarding. Kỹ năng mới: Em phát triển hiểu biết tốt hơn về career development trong cloud computing và học về các kỹ năng cần thiết cho các roles khác nhau. Em có được insights về cách xây dựng career path từ junior đến principal level. Em cũng học về tầm quan trọng của soft skills cùng với technical skills, và cách leverage community và mentorship cho career growth. Đóng góp cho nhóm/dự án: Em chia sẻ thông tin chương trình và career insights với nhóm. Em document các career pathways khác nhau và skill requirements cho các cloud roles. Em tạo personal development plan dựa trên roadmap được chia sẻ bởi speakers. Em cũng identify networking opportunities và connections có thể benefit nhóm. Kiến thức có được giúp em hiểu broader cloud computing ecosystem và plan career development accordingly. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái Trong giao diện Inbound endpoint, Chọn ID của Inbound endpoint. Sao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com 📝 Note\nCác địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud. Truy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại First Cloud Journey (FCJ) từ tháng 9 năm 2025 đến tháng 11 năm 2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức về cloud computing vào môi trường AWS thực tế.\nTôi đã tham gia chương trình thực tập AWS Cloud Journey, nơi tôi hoàn thành hành trình học tập 12 tuần và triển khai một kiến trúc web application production-ready trên AWS. Qua dự án này, tôi đã cải thiện kỹ năng về thiết kế cloud architecture, AWS services, Infrastructure as Code (CloudFormation), CI/CD pipelines, monitoring và observability, security best practices, và giải quyết vấn đề trong môi trường cloud.\nDự án chính bao gồm thiết kế và triển khai một kiến trúc AWS web application hoàn chỉnh gồm:\nEdge Layer: Route 53, CloudFront CDN, AWS WAF, ACM Certificate, S3 static hosting Networking: VPC, subnets, Internet Gateway, NAT Gateway, Security Groups, VPC Flow Logs Compute \u0026amp; Database: EC2 với Auto Scaling, RDS, API Gateway, Amazon Cognito CI/CD: GitLab, CodePipeline, CodeBuild với automated deployments Monitoring \u0026amp; Security: CloudWatch, CloudTrail, SNS alerts, IAM, Secrets Manager Về tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với mentors và đồng nghiệp để nâng cao hiệu quả công việc. Tôi đã duy trì worklogs chi tiết ghi lại tiến độ, các thách thức gặp phải, và các giải pháp đã triển khai trong suốt 12 tuần.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ☐ ✅ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ☐ ✅ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ☐ ✅ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Điểm mạnh Khả năng học hỏi mạnh: Tôi đã thể hiện khả năng thích ứng nhanh với các AWS services và khái niệm mới. Khi gặp các services chưa quen như API Gateway VPC Link hoặc CloudFront OAC, tôi chủ động nghiên cứu tài liệu và triển khai giải pháp hiệu quả.\nTính chủ động: Tôi đã chủ động khám phá các tính năng nâng cao vượt quá yêu cầu cơ bản, chẳng hạn như triển khai SSH-less deployment sử dụng AWS Systems Manager và tự động hóa CloudFront cache invalidation trong CI/CD pipelines.\nTài liệu kỹ thuật: Tôi đã duy trì worklogs toàn diện với tài liệu chi tiết về các quyết định kiến trúc, thách thức gặp phải, và giải pháp đã triển khai, điều này sẽ có giá trị cho tham khảo tương lai và chia sẻ kiến thức.\nTrách nhiệm và chất lượng: Tôi đã hoàn thành nhất quán các nhiệm vụ hàng tuần đúng lịch trình và đảm bảo chất lượng bằng cách kiểm tra kỹ lưỡng ở mỗi giai đoạn của dự án, từ thiết lập edge layer đến kiểm tra end-to-end cuối cùng.\nCần cải thiện Quản lý thời gian và kỷ luật: Mặc dù tôi đã hoàn thành tất cả các nhiệm vụ, đôi khi tôi gặp khó khăn với quản lý thời gian khi xử lý các vấn đề phức tạp như cấu hình API Gateway VPC Link hoặc troubleshooting CloudWatch alarms. Tôi cần cải thiện khả năng ước tính thời gian thực hiện nhiệm vụ chính xác hơn và phân bổ thời gian hiệu quả hơn.\nHiệu quả giải quyết vấn đề: Khi đối mặt với các thách thức kỹ thuật (như vấn đề kết nối RDS hoặc xác thực Cognito JWT token), đôi khi tôi dành quá nhiều thời gian troubleshooting trước khi tìm kiếm sự giúp đỡ hoặc tham khảo tài liệu. Tôi nên phát triển một cách tiếp cận có hệ thống hơn để giải quyết vấn đề: đầu tiên kiểm tra tài liệu, sau đó kiểm tra có hệ thống, và cuối cùng tìm kiếm hướng dẫn khi cần thiết.\nKỹ năng giao tiếp: Tôi cần cải thiện khả năng giao tiếp các vấn đề kỹ thuật và giải pháp rõ ràng hơn, đặc biệt là khi trình bày các quyết định kiến trúc hoặc giải thích các cấu hình phức tạp cho các thành viên trong nhóm. Điều này bao gồm tài liệu hóa tốt hơn các bước troubleshooting và giao tiếp bằng lời nói hiệu quả hơn trong các cuộc thảo luận nhóm.\nNhận thức về tối ưu hóa chi phí: Ban đầu, tôi tập trung nhiều hơn vào chức năng hơn là tối ưu hóa chi phí. Ví dụ, VPC Flow Logs tạo ra chi phí CloudWatch cao trước khi tôi triển khai retention policies và S3 storage. Tôi nên xem xét các tác động chi phí sớm hơn trong giai đoạn thiết kế.\nSuy ngẫm Kỳ thực tập này đã cung cấp kinh nghiệm thực hành vô giá với AWS cloud services và best practices. Các thách thức tôi gặp phải, chẳng hạn như cấu hình API Gateway VPC Links, triển khai SSH-less deployments, và troubleshooting CloudWatch alarms, đã tăng cường đáng kể kỹ năng giải quyết vấn đề và kiến thức kỹ thuật của tôi.\nDự án đã dạy tôi tầm quan trọng của:\nInfrastructure as Code: Sử dụng CloudFormation cho reproducible deployments Security First: Triển khai least-privilege IAM policies và network segmentation Monitoring và Observability: Thiết lập logging và alerting toàn diện Automation: Giảm lỗi thủ công thông qua CI/CD pipelines Documentation: Duy trì hồ sơ chi tiết cho troubleshooting và knowledge transfer Tôi biết ơn vì cơ hội được làm việc trên dự án AWS toàn diện này và mong muốn áp dụng những kỹ năng này trong các vai trò cloud architecture và DevOps trong tương lai.\n"},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://Fatnotfatt.github.io/learning-aws/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]